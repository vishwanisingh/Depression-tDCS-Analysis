{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RQA -- in between - raw quality assessment (amplitude * power frequency ratio * alpha band psd ratio)\n",
    "# Extract file ---> collective data ---> Bad channel removal ----- Not needed [sampling rate correction (500Hz)] -----\n",
    "# filtering (butterworth bandpass - tune coefficient)  ----- rereferencing ----- epoching ----- ERP ----- baseline removal ---- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALINGS = 4e-4\n",
    "SFREQ = 500\n",
    "WINDOW_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack\n",
    "from scipy.fft import fft\n",
    "import time\n",
    "import mne\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import kurtosis, zscore\n",
    "from mne.preprocessing import create_ecg_epochs, create_eog_epochs, read_ica\n",
    "from mne.time_frequency import tfr_morlet, tfr_array_morlet, morlet, AverageTFR\n",
    "from itertools import product\n",
    "import pywt\n",
    "\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = os.getcwd()+'\\\\Depression-Sample-dataset-AIIMS\\\\'\n",
    "items = os.listdir(folder_path)\n",
    "active_or_sham_list = [item for item in items if os.path.isdir(os.path.join(folder_path, item))]\n",
    "for active_or_sham in active_or_sham_list:\n",
    "    patient_folder_path = os.path.join(folder_path, active_or_sham)\n",
    "    items = os.listdir(patient_folder_path)\n",
    "    patients_list = [item for item in items if os.path.isdir(os.path.join(patient_folder_path, item))]\n",
    "    # patients_list = ['Hemlata', 'PreetiSingh', 'VinodKumarSharma']\n",
    "    for patient in patients_list:\n",
    "        pre_post_int_folder_path = os.path.join(patient_folder_path, patient)\n",
    "        items = os.listdir(pre_post_int_folder_path)\n",
    "        pre_post_int_list = [item for item in items if os.path.isdir(os.path.join(pre_post_int_folder_path, item))]\n",
    "        for var in pre_post_int_list:\n",
    "            if var=='Pre':\n",
    "                pre_path = os.path.join(pre_post_int_folder_path, var)\n",
    "                ao_files_list = ['20230831110419_Hemlata_05.10.23_01_AO', '20230718202004_Preeti singh_22.08.23-01_AO', \n",
    "                                 '20230829195917_VinodKumarSharma_25.9.23_01_AO', '20230825020604_JitenderKumar_29.08.23_01_AO',\n",
    "                                  '20230827074250_SeemaKumari_11.09.23_01_AO']\n",
    "                file_path = pre_path + '\\\\' + ao_files_list[0] + '.easy'\n",
    "                break # Remove for all pre, post and intervention for a patient\n",
    "        break # Remove for all patients in active or sham\n",
    "    break # Remove for both active and sham\n",
    "\n",
    "# Manual file_path\n",
    "# sham_or_active = 'Sham\\\\' \n",
    "# patient = 'SeemaKumari'\n",
    "# pre_post_intervention = '\\\\pre\\\\'\n",
    "# directory = folder_path + sham_or_active + patient + pre_post_intervention\n",
    "# file_path = directory + '20230827074800_SeemaKumari_11.09.23_01_GNG' + '.easy'\n",
    "\n",
    "# TODO: Remove ?\n",
    "# OBSERVED: Active: pre all spike (AO/GNG/Eye close) ---- post except 17 and 25 all spike (AO/GNG/Eye close)\n",
    "# OBSERVED: Sham: pre all spike in Eye close only ------ post reduced spikes in Eye close only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P8</th>\n",
       "      <th>T8</th>\n",
       "      <th>CP6</th>\n",
       "      <th>FC6</th>\n",
       "      <th>F8</th>\n",
       "      <th>F4</th>\n",
       "      <th>C4</th>\n",
       "      <th>P4</th>\n",
       "      <th>AF4</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>...</th>\n",
       "      <th>F7</th>\n",
       "      <th>FC5</th>\n",
       "      <th>CP5</th>\n",
       "      <th>T7</th>\n",
       "      <th>P7</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "      <th>trigger</th>\n",
       "      <th>timestamp(ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25379810</td>\n",
       "      <td>29103155</td>\n",
       "      <td>28599472</td>\n",
       "      <td>15288889</td>\n",
       "      <td>40199265</td>\n",
       "      <td>28470199</td>\n",
       "      <td>29530134</td>\n",
       "      <td>28225105</td>\n",
       "      <td>12977421</td>\n",
       "      <td>10060115</td>\n",
       "      <td>...</td>\n",
       "      <td>27105488</td>\n",
       "      <td>28082879</td>\n",
       "      <td>26403810</td>\n",
       "      <td>22191074</td>\n",
       "      <td>25382844</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1693460058992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25378626</td>\n",
       "      <td>29099195</td>\n",
       "      <td>28596399</td>\n",
       "      <td>15280034</td>\n",
       "      <td>40182550</td>\n",
       "      <td>28472527</td>\n",
       "      <td>29529559</td>\n",
       "      <td>28223555</td>\n",
       "      <td>12977802</td>\n",
       "      <td>10054182</td>\n",
       "      <td>...</td>\n",
       "      <td>27097417</td>\n",
       "      <td>28086114</td>\n",
       "      <td>26406471</td>\n",
       "      <td>22194416</td>\n",
       "      <td>25384645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1693460058994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25376580</td>\n",
       "      <td>29093544</td>\n",
       "      <td>28595577</td>\n",
       "      <td>15272144</td>\n",
       "      <td>40165525</td>\n",
       "      <td>28474566</td>\n",
       "      <td>29528571</td>\n",
       "      <td>28223016</td>\n",
       "      <td>12979022</td>\n",
       "      <td>10046370</td>\n",
       "      <td>...</td>\n",
       "      <td>27087846</td>\n",
       "      <td>28086630</td>\n",
       "      <td>26409398</td>\n",
       "      <td>22195833</td>\n",
       "      <td>25387344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1693460058996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25373540</td>\n",
       "      <td>29087155</td>\n",
       "      <td>28593108</td>\n",
       "      <td>15264796</td>\n",
       "      <td>40151809</td>\n",
       "      <td>28470077</td>\n",
       "      <td>29524346</td>\n",
       "      <td>28219665</td>\n",
       "      <td>12975505</td>\n",
       "      <td>10034833</td>\n",
       "      <td>...</td>\n",
       "      <td>27078459</td>\n",
       "      <td>28081278</td>\n",
       "      <td>26408405</td>\n",
       "      <td>22191979</td>\n",
       "      <td>25386476</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1693460058998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25367807</td>\n",
       "      <td>29077171</td>\n",
       "      <td>28587184</td>\n",
       "      <td>15255541</td>\n",
       "      <td>40138599</td>\n",
       "      <td>28466434</td>\n",
       "      <td>29519236</td>\n",
       "      <td>28214265</td>\n",
       "      <td>12972645</td>\n",
       "      <td>10021083</td>\n",
       "      <td>...</td>\n",
       "      <td>27069769</td>\n",
       "      <td>28078585</td>\n",
       "      <td>26403375</td>\n",
       "      <td>22186997</td>\n",
       "      <td>25382070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1693460059000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         P8        T8       CP6       FC6        F8        F4        C4  \\\n",
       "0  25379810  29103155  28599472  15288889  40199265  28470199  29530134   \n",
       "1  25378626  29099195  28596399  15280034  40182550  28472527  29529559   \n",
       "2  25376580  29093544  28595577  15272144  40165525  28474566  29528571   \n",
       "3  25373540  29087155  28593108  15264796  40151809  28470077  29524346   \n",
       "4  25367807  29077171  28587184  15255541  40138599  28466434  29519236   \n",
       "\n",
       "         P4       AF4       Fp2  ...        F7       FC5       CP5        T7  \\\n",
       "0  28225105  12977421  10060115  ...  27105488  28082879  26403810  22191074   \n",
       "1  28223555  12977802  10054182  ...  27097417  28086114  26406471  22194416   \n",
       "2  28223016  12979022  10046370  ...  27087846  28086630  26409398  22195833   \n",
       "3  28219665  12975505  10034833  ...  27078459  28081278  26408405  22191979   \n",
       "4  28214265  12972645  10021083  ...  27069769  28078585  26403375  22186997   \n",
       "\n",
       "         P7  ax  ay  az  trigger  timestamp(ms)  \n",
       "0  25382844   0   0   0        0  1693460058992  \n",
       "1  25384645   0   0   0        0  1693460058994  \n",
       "2  25387344   0   0   0        0  1693460058996  \n",
       "3  25386476   0   0   0        0  1693460058998  \n",
       "4  25382070   0   0   0        0  1693460059000  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "channel_str='Channel 1:P8\\\n",
    "\tChannel 2:T8\\\n",
    "\tChannel 3:CP6\\\n",
    "\tChannel 4:FC6\\\n",
    "\tChannel 5:F8\\\n",
    "\tChannel 6:F4\\\n",
    "\tChannel 7:C4\\\n",
    "\tChannel 8:P4\\\n",
    "\tChannel 9:AF4\\\n",
    "\tChannel 10:Fp2\\\n",
    "\tChannel 11:Fp1\\\n",
    "\tChannel 12:AF3\\\n",
    "\tChannel 13:Fz\\\n",
    "\tChannel 14:FC2\\\n",
    "\tChannel 15:Cz\\\n",
    "\tChannel 16:CP2\\\n",
    "\tChannel 17:PO3\\\n",
    "\tChannel 18:O1\\\n",
    "\tChannel 19:Oz\\\n",
    "\tChannel 20:O2\\\n",
    "\tChannel 21:PO4\\\n",
    "\tChannel 22:Pz\\\n",
    "\tChannel 23:CP1\\\n",
    "\tChannel 24:FC1\\\n",
    "\tChannel 25:P3\\\n",
    "\tChannel 26:C3\\\n",
    "\tChannel 27:F3\\\n",
    "\tChannel 28:F7\\\n",
    "\tChannel 29:FC5\\\n",
    "\tChannel 30:CP5\\\n",
    "\tChannel 31:T7\\\n",
    "\tChannel 32:P7'\n",
    "\n",
    "string_channels = channel_str.replace('\\t', ':').split(':')\n",
    "channel_names = [string_channels[i] for i in range(len(string_channels)) if i % 2 != 0]\n",
    "channel_names.append('ax')\n",
    "channel_names.append('ay')\n",
    "channel_names.append('az')\n",
    "channel_names.append('trigger')\n",
    "channel_names.append('timestamp(ms)')\n",
    "all_channels = np.array(channel_names[:-5])\n",
    "df.columns=channel_names\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=32, n_times=149999\n",
      "    Range : 0 ... 149998 =      0.000 ...   299.996 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of channels: 32\n",
      "Shape of the data: (32, 149999)\n"
     ]
    }
   ],
   "source": [
    "transposed_data=df.T\n",
    "\n",
    "# Create a MNE-Python info object and specifying sampling rate of data\n",
    "ch_names = df.columns.tolist()[:-5]\n",
    "ch_types = ['eeg' for i in range(32)]\n",
    "info = mne.create_info(ch_names=ch_names,ch_types=ch_types, sfreq=500)\n",
    "\n",
    "# Convert all EEG units to nV\n",
    "raw = mne.io.RawArray(transposed_data.values[:-5,:]/1e9, info)\n",
    "\n",
    "print(f\"num of channels: {raw.info.get('nchan')}\")\n",
    "print(f'Shape of the data: {raw.get_data().shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting custom Montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x640 with 1 Axes>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mne.channels\n",
    "mont1020 = mne.channels.make_standard_montage('standard_1020')\n",
    "mont1005 = mne.channels.make_standard_montage('standard_1005')\n",
    "\n",
    "ind = [i for (i, channel) in enumerate(mont1020.ch_names) if channel in all_channels]\n",
    "mont1020_new = mont1020.copy()\n",
    "\n",
    "mont1020_new.ch_names = [mont1020.ch_names[x] for x in ind]\n",
    "kept_channel_info = [mont1020.dig[x+3] for x in ind]\n",
    "\n",
    "# Keeping the first three rows as they are the fiducial points information\n",
    "mont1020_new.dig = mont1020.dig[0:3]+kept_channel_info\n",
    "\n",
    "raw.set_montage(mont1020_new)\n",
    "mont1020_new.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time amplitude plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_amplitude(raw, title):\n",
    "    fig = raw.plot(\n",
    "        n_channels=32, \n",
    "        scalings=SCALINGS\n",
    "        )\n",
    "    fig.savefig(f'MNE-graphs/time-amplitude/{title}-EEG.png')\n",
    "\n",
    "    print(raw.info)\n",
    "    # TODO: Extract statistical features from time domain such as mean, median, variance, skewness, kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power spectral density plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psd(raw, title):\n",
    "    fig = raw.plot_psd(picks=raw.info['ch_names'])\n",
    "    fig.savefig(f'MNE-graphs/psd-frequency/{title}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wavelet plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = scale2frequency(wavelet, scale)/sampling_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wavelet(raw, title):\n",
    "#     signal = raw.get_data()[0]\n",
    "#     t = np.linspace(0, 299, len(signal))\n",
    "#     coefficients, frequencies = pywt.cwt(signal, scales=np.arange(1, 128), wavelet='cmor')  \n",
    "\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.imshow(np.abs(coefficients), aspect='auto', cmap='jet', extent=[0, 299, 1, 128])\n",
    "#     plt.colorbar(label=\"Magnitude\")\n",
    "#     plt.ylabel(\"Scale\")\n",
    "#     plt.xlabel(\"Time\")\n",
    "#     plt.title(\"CWT\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG Quality Assessment Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eqi_metrics(eeg_data_window):\n",
    "    average_amplitude_spectrum = []\n",
    "    rms_amplitude = []\n",
    "    max_gradient = []\n",
    "    zcr = []\n",
    "    kurt = []\n",
    "    num_channels = len(eeg_data_window.info['ch_names'])\n",
    "\n",
    "    for i in range(num_channels):\n",
    "        amplitude=eeg_data_window.get_data()[i]\n",
    "\n",
    "        # Metric 1: Average Single-Sided Amplitude Spectrum (0.01-45Hz range)\n",
    "        average_amplitude_spectrum.append(np.mean(np.abs(np.fft.fft(amplitude))))\n",
    "\n",
    "        # Metric 2: RMS Amplitude\n",
    "        rms_amplitude.append(np.sqrt(np.mean(amplitude ** 2)))\n",
    "\n",
    "        # Metric 3: Maximum Gradient\n",
    "        max_gradient.append(np.max(np.abs(np.diff(amplitude))))\n",
    "\n",
    "        # Metric 4: Zero-Crossing Rate (ZCR)\n",
    "        zcr.append(np.mean(np.abs(np.diff(np.sign(amplitude))))) # TODO: Amplitude all in positive why ?\n",
    "\n",
    "        # Metric 5: Kurtosis\n",
    "        kurt.append(kurtosis(amplitude, axis=0))\n",
    "    \n",
    "    return average_amplitude_spectrum, rms_amplitude, max_gradient, zcr, kurt\n",
    "\n",
    "def calculate_eqi(eeg_data):\n",
    "    num_samples = len(eeg_data)\n",
    "    num_windows = int(num_samples / (SFREQ * WINDOW_SIZE))\n",
    "    num_channels = len(eeg_data.info['ch_names'])\n",
    "\n",
    "    eqi_scores = [[0 for col in range(num_windows)] for row in range(num_channels)]\n",
    "    average_eqi_score_per_channel = [0 for i in range(num_channels)]\n",
    "    clean_data_percentage_per_channel = [0 for i in range(num_channels)]\n",
    "\n",
    "    for i in range(num_windows):\n",
    "        # In seconds\n",
    "        start_idx = int(i * WINDOW_SIZE)\n",
    "        end_idx = int((i + 1) * WINDOW_SIZE)\n",
    "        eeg_data_window = eeg_data.copy().crop(tmin=start_idx, tmax=end_idx)\n",
    "\n",
    "        eqi_metrics = calculate_eqi_metrics(eeg_data_window)\n",
    "        # Z-score normalization\n",
    "        for chan in range(num_channels):\n",
    "            # 5 X 32\n",
    "            eqi_metrics_channel = eqi_metrics[0][chan], eqi_metrics[1][chan], eqi_metrics[2][chan], eqi_metrics[3][chan], eqi_metrics[4][chan] \n",
    "            feature_vector_normalized = zscore(eqi_metrics_channel)\n",
    "            eqi_score = np.sum(np.abs(feature_vector_normalized) > 1, axis=0)\n",
    "            eqi_scores[chan][i]=eqi_score\n",
    "    average_eqi_score_per_channel = np.mean(eqi_scores, axis=1)\n",
    "    clean_data_percentage_per_channel = np.mean(np.array(eqi_scores) < 2, axis=1) * 100\n",
    "\n",
    "    return (np.mean(average_eqi_score_per_channel), np.mean(clean_data_percentage_per_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_score(eeg_data):\n",
    "    average_eqi_score, clean_data_percentage = calculate_eqi(eeg_data)\n",
    "    print(average_eqi_score, clean_data_percentage)\n",
    "    return (average_eqi_score, clean_data_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw graph plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 8 non-empty values\n",
      " bads: []\n",
      " ch_names: P8, T8, CP6, FC6, F8, F4, C4, P4, AF4, Fp2, Fp1, AF3, Fz, FC2, ...\n",
      " chs: 32 EEG\n",
      " custom_ref_applied: False\n",
      " dig: 35 items (3 Cardinal, 32 EEG)\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 250.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 32\n",
      " projs: []\n",
      " sfreq: 500.0 Hz\n",
      ">\n",
      "NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().\n",
      "Effective window size : 4.096 (s)\n",
      "<Info | 8 non-empty values\n",
      " bads: []\n",
      " ch_names: P8, T8, CP6, FC6, F8, F4, C4, P4, AF4, Fp2, Fp1, AF3, Fz, FC2, ...\n",
      " chs: 32 EEG\n",
      " custom_ref_applied: False\n",
      " dig: 35 items (3 Cardinal, 32 EEG)\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 250.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 32\n",
      " projs: []\n",
      " sfreq: 500.0 Hz\n",
      ">\n",
      "1.0840301003344481 95.48494983277592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0840301003344481, 95.48494983277592)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "title = \"0--Raw graph with line filter\"\n",
    "time_amplitude(raw, title)\n",
    "psd(raw, title)\n",
    "# wavelet(raw, title)\n",
    "print(raw.info)\n",
    "find_score(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Bad channels removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Amplitude, flatlined, standard, kurtosis threshold channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['Oz'] 111111\n",
      "0 [] 22222\n",
      "4 ['Cz', 'Oz', 'CP5', 'P7'] 3333\n",
      "1 ['Oz'] 4444\n"
     ]
    }
   ],
   "source": [
    "# # Thresholds - https://ieeexplore.ieee.org/abstract/document/6346834?casa_token=zFQWJXGAa80AAAAA:A84Ep-dTINstXMDRX12vpvBuDb2TLLvRR5jMK9wSuAUdTx4nZWvxH_bpzSqCKCigwsHwEmpqaw\n",
    "# # Amplitude thresholds\n",
    "# # TODO: Set all and observe all for different patients, can apply hyperparameter tuning\n",
    "# amplitude_threshold = 1.5e-3\n",
    "# flatline_threshold = 1e-4\n",
    "# std_threshold = 1e-3\n",
    "# kurtosis_threshold = 5.0\n",
    "\n",
    "# bad_channels_amplitude = [raw.ch_names[i] for i in range(raw.info['nchan']) if (max(raw._data[i, :]) > amplitude_threshold and min(raw._data[i, :]) < -amplitude_threshold )]\n",
    "# print(len(bad_channels_amplitude), bad_channels_amplitude, \"111111\")\n",
    "# bad_channels_flatline = [raw.ch_names[i] for i in range(raw.info['nchan']) if (np.all(np.abs(raw._data[i, :]) < flatline_threshold))]\n",
    "# print(len(bad_channels_flatline), bad_channels_flatline, \"22222\")\n",
    "# bad_channels_std = [raw.ch_names[i] for i in range(raw.info['nchan']) if (np.std(raw._data[i, :]) > std_threshold )]\n",
    "# print(len(bad_channels_std), bad_channels_std, \"3333\")\n",
    "# bad_channels_kurtosis = [raw.ch_names[i] for i in range(raw.info['nchan']) if (kurtosis(raw._data[i, :]) > kurtosis_threshold)]\n",
    "# print(len(bad_channels_kurtosis), bad_channels_kurtosis, \"4444\")\n",
    "\n",
    "# all_bad_channels = list(set(bad_channels_amplitude + bad_channels_flatline + bad_channels_std + bad_channels_kurtosis))\n",
    "#                     # + bad_channels_power_spectrum + bad_channels_frequency_range)\n",
    "# raw_cleaned = raw.copy()\n",
    "# raw_cleaned.info['bads'] = list(set(raw_cleaned.info['bads']+(all_bad_channels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation required to estimate missing or bad channel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = '1--Interpolated bad channels graph'\n",
    "# Dropping bad channels\n",
    "\n",
    "# raw_deleted = raw_cleaned.copy() \n",
    "# raw_deleted.drop_channels(all_bad_channels)\n",
    "# time_amplitude(raw_deleted, title)\n",
    "# psd(raw_interpolated, title)\n",
    "# find_score(raw_deleted)\n",
    "\n",
    "#Interpolating bad channels\n",
    "\n",
    "# raw_cleaned.interpolate_bads(reset_bads = True)\n",
    "# time_amplitude(raw_cleaned, title)\n",
    "# psd(raw_cleaned, title)\n",
    "# find_score(raw_cleaned)\n",
    "\n",
    "raw_cleaned = raw.copy()\n",
    "# time_amplitude(raw_cleaned, title)\n",
    "# psd(raw_cleaned, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Band pass filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting configurations to minimize EQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # applied band pass filter of 0.01-45 Hz for depression detection \n",
    "# l_freq = 0.01\n",
    "# h_freq = 45\n",
    "# fir_phase = ['zero', 'minimum']\n",
    "# fir_window = ['hamming', 'hann']\n",
    "# iir_phase = ['zero', 'zero-double', 'forward']\n",
    "# fir_combinations = list(product(fir_phase, fir_window))\n",
    "\n",
    "# method = 'fir'\n",
    "# eqi = 1000\n",
    "# clean = 0\n",
    "# for index, combination in enumerate(fir_combinations, start=1):\n",
    "#     raw_filter = raw_cleaned.copy()\n",
    "#     raw_filter.filter(method= method,\n",
    "#     phase= combination[0],\n",
    "#     fir_window= combination[1],\n",
    "#     l_freq= l_freq,\n",
    "#     h_freq= h_freq)\n",
    "#     eqi_1, clean_1 = find_score(raw_filter)\n",
    "#     if eqi_1 < eqi or clean_1 > clean:\n",
    "#         eqi, clean = eqi_1, clean_1\n",
    "#         combination = combination\n",
    "\n",
    "# method = 'iir'\n",
    "# for phase in iir_phase:\n",
    "#     raw_filter = raw_cleaned.copy()\n",
    "#     raw_filter.filter(method= method,\n",
    "#         phase= phase,\n",
    "#         l_freq= l_freq,\n",
    "#         h_freq= h_freq)\n",
    "#     eqi_1, clean_1 = find_score(raw_filter)\n",
    "#     if eqi_1 < eqi or clean_1 > clean:\n",
    "#         eqi, clean = eqi_1, clean_1\n",
    "#         combination = phase\n",
    "\n",
    "# print(\"Band pass filter configurations: \", eqi, clean, combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering data with optimal band pass configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, non-linear phase, causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hann window with 0.0546 passband ripple and 44 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.01 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz\n",
      "- Filter length: 155001 samples (310.002 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_18336\\2810513046.py:16: RuntimeWarning: filter_length (155001) is longer than the signal (149999), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  raw_cleaned.filter(method= 'fir',\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 9 non-empty values\n",
      " bads: 4 items (CP5, P7, Cz, Oz)\n",
      " ch_names: P8, T8, CP6, FC6, F8, F4, C4, P4, AF4, Fp2, Fp1, AF3, Fz, FC2, ...\n",
      " chs: 32 EEG\n",
      " custom_ref_applied: False\n",
      " dig: 35 items (3 Cardinal, 32 EEG)\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 45.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 32\n",
      " projs: []\n",
      " sfreq: 500.0 Hz\n",
      ">\n",
      "NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().\n",
      "Effective window size : 4.096 (s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "['CP5', 'P7', 'Cz', 'Oz']\n"
     ]
    }
   ],
   "source": [
    "# title = \"2--Band pass filtered graph\"\n",
    "# if len(combination) == 2:\n",
    "#     raw_cleaned.filter(method= 'fir',\n",
    "#     phase= combination[0],\n",
    "#     fir_window= combination[1],\n",
    "#     l_freq= l_freq,\n",
    "#     h_freq= h_freq)\n",
    "# elif len(combination) == 1:\n",
    "#     raw_cleaned.filter(method= 'iir',\n",
    "#         phase= combination,\n",
    "#         l_freq= l_freq,\n",
    "#         h_freq= h_freq)\n",
    "\n",
    "l_freq = 0.01\n",
    "h_freq = 45\n",
    "raw_cleaned.filter(method= 'fir',\n",
    "    phase= 'minimum',\n",
    "    fir_window= 'hann',\n",
    "    l_freq= l_freq,\n",
    "    h_freq= h_freq)\n",
    "\n",
    "time_amplitude(raw_cleaned, title)\n",
    "psd(raw_cleaned, title)\n",
    "# print(\"Band pass filter configurations: \", eqi, clean, combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Rereferencing\n",
    "\n",
    "Calculates the mean voltage from all electrodes at each time point and subtracts this mean from the voltage at each individual electrode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eqi = 1000\n",
    "# clean = 0\n",
    "# raw_referenced = raw_cleaned.copy()\n",
    "# raw_referenced.set_eeg_reference('average', projection=True).apply_proj() \n",
    "# eqi_1, clean_1 = find_score(raw_referenced)\n",
    "# if eqi_1 < eqi or clean_1 > clean:\n",
    "#     eqi, clean = eqi_1, clean_1\n",
    "#     reference = 'average'\n",
    "\n",
    "# ref_channels = ['Cz']\n",
    "# raw_referenced = raw_cleaned.copy()\n",
    "# raw_referenced.set_eeg_reference(ref_channels=ref_channels)\n",
    "# eqi_1, clean_1 = find_score(raw_referenced)\n",
    "# if eqi_1 < eqi or clean_1 > clean:\n",
    "#     eqi, clean = eqi_1, clean_1\n",
    "#     reference = ref_channels\n",
    "# print(\"Rereference configurations: \", eqi, clean, reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "SSP projectors applied...\n",
      "<Info | 10 non-empty values\n",
      " bads: 4 items (CP5, P7, Cz, Oz)\n",
      " ch_names: P8, T8, CP6, FC6, F8, F4, C4, P4, AF4, Fp2, Fp1, AF3, Fz, FC2, ...\n",
      " chs: 32 EEG\n",
      " custom_ref_applied: False\n",
      " dig: 35 items (3 Cardinal, 32 EEG)\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 45.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 32\n",
      " projs: Average EEG reference: on\n",
      " sfreq: 500.0 Hz\n",
      ">\n",
      "NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().\n",
      "Effective window size : 4.096 (s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "['CP5', 'P7', 'Cz', 'Oz', 'C4']\n"
     ]
    }
   ],
   "source": [
    "title = \"3---Rereferenced\"\n",
    "# if reference == 'average':\n",
    "raw_cleaned.set_eeg_reference('average', projection=True).apply_proj() \n",
    "# else:\n",
    "    # raw_cleaned.set_eeg_reference(ref_channels=reference)\n",
    "\n",
    "time_amplitude(raw_cleaned, title)\n",
    "psd(raw_cleaned, title)\n",
    "# print(\"Rereference configurations: \", eqi, clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- 4. ECG/EOG Correction using ICA on Raw data\n",
    "\n",
    "ICA decomposes data into different components each representing a spatial pattern. Excluding a component means discarding that specific spatial pattern and its contribution to original data -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ica = mne.preprocessing.ICA(\n",
    "#     n_components=20, random_state=0)\n",
    "# ica.fit(raw_cleaned)\n",
    "# ica.plot_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Automatically : Find bad ECG and EOG for all channels and plotting epochs data without Removal of ICA components\n",
    "# bad_indices_eog = []\n",
    "# channels_eog = []\n",
    "# bad_indices_ecg = []\n",
    "# channels_ecg = []\n",
    "\n",
    "# for channel in raw_cleaned.info['ch_names']:\n",
    "#     eog, scores_eog = ica.find_bads_eog(raw_cleaned, channel, threshold='auto')\n",
    "#     if len(eog):\n",
    "#         bad_indices_eog.append(eog)\n",
    "#         channels_eog.append(channel)\n",
    "    \n",
    "#     ecg = ica.find_bads_ecg(raw_cleaned, channel, threshold='auto')\n",
    "#     if len(ecg[0]):\n",
    "#         bad_indices_ecg.append(ecg[0])\n",
    "    \n",
    "# print(\"EOG Bad indices\", bad_indices_eog, channels_eog)\n",
    "# print(\"ECG Bad indices\", bad_indices_ecg, channels_ecg)\n",
    "\n",
    "# excluded_components = []\n",
    "# for i in bad_indices_eog:\n",
    "#     for j in i:\n",
    "#         excluded_components.append(j)\n",
    "# for i in bad_indices_ecg:\n",
    "#     for j in i:\n",
    "#         excluded_components.append(j)\n",
    "# excluded_components = list(set(excluded_components))\n",
    "# print(\"Excluded components\", excluded_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Manually : Observe bad ECG and EOG from ICA components\n",
    "# # excluded_components = []\n",
    "# print(\"Excluded components\", excluded_components)\n",
    "# print(bad_indices_ecg, bad_indices_eog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply removed ICA components for both ECG and EOG for each channel and plot epoched data with removal of ICA componetns\n",
    "# raw_corrected = ica.apply(raw_cleaned, exclude=excluded_components) # ICA algo identifies spatially independent components in EEG \n",
    "# raw_corrected.plot(n_channels=len(raw_cleaned.info['ch_names']), scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate EQI score\n",
    "# find_score(raw_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet denoising: \n",
    "signal = raw_cleaned.get_data()\n",
    "t = np.linspace(0, 299, len(signal))\n",
    "# Perform a multi-level wavelet decomposition\n",
    "coeffs = pywt.wavedec(signal, 'db1', level=4)\n",
    "\n",
    "# Set a threshold to nullify smaller coefficients (assumed to be noise)\n",
    "threshold = 0.5\n",
    "coeffs_thresholded = [pywt.threshold(c, threshold, mode='soft') for c in coeffs]\n",
    "\n",
    "# Reconstruct the signal from the thresholded coefficients\n",
    "denoised_signal = pywt.waverec(coeffs_thresholded, 'db1')\n",
    "\n",
    "# Plotting the noisy and denoised signals\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(t, raw_cleaned.get_data())\n",
    "plt.title(\"Noisy Signal\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(t, denoised_signal)\n",
    "plt.title(\"Denoised Signal\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Epoching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 Function which converts Epoch to raw data for Signal Quality Assessment purpose only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_epoch_to_raw(epochs):\n",
    "    def map_indices(i, j, k):\n",
    "        # Assuming i ranges from 0 to 149, j ranges from 0 to 31, and k ranges from 0 to 400\n",
    "        # Mapping to the reshaped_data indices\n",
    "        reshaped_i = j\n",
    "        reshaped_j = i * len(epochs.get_data()[0][0])  + k  # Assuming 401 is the size of the second dimension in the original data\n",
    "\n",
    "        return reshaped_i, reshaped_j\n",
    "\n",
    "    reshaped_data = np.random.rand(32, 60150)\n",
    "    for i in range(len(epochs.get_data())):\n",
    "        for j in range(len(epochs.get_data()[0])):\n",
    "            for k in range(len(epochs.get_data()[0][0])):\n",
    "                reshaped_i, reshaped_j = map_indices(i, j, k)\n",
    "\n",
    "                reshaped_data[reshaped_i, reshaped_j] = epochs.get_data()[i][j][k]\n",
    "    return reshaped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 Adding trigger channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_col = df.values[:, -2]\n",
    "trigger_times = []\n",
    "event_id = {}\n",
    "event_list = []\n",
    "\n",
    "for i in range(len(trigger_col)):\n",
    "    if trigger_col[i]!=0:\n",
    "        trigger_times.append(i+2)\n",
    "        event_id[str(trigger_col[i])] = trigger_col[i]\n",
    "        event_list.append(trigger_col[i])\n",
    "\n",
    "# Create an events array (trigger value, previous, sample number)\n",
    "events = np.column_stack((trigger_times, np.zeros_like(trigger_times), event_list))\n",
    "# fig = raw_cleaned.plot(n_channels=len(raw_cleaned.info['ch_names']), events=events, event_id=event_id, event_color={1:'r', 2:'g', 3:'b'}, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 Remove corrupted events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove corrupted event\n",
    "# From event_id\n",
    "if '3' in event_id:\n",
    "    del event_id['3']\n",
    "\n",
    "# From events\n",
    "indexes=[]\n",
    "for i in range(len(events)):\n",
    "    if events[i][2] == 3:\n",
    "        indexes.append(i)\n",
    "events = np.delete(events, indexes, 0)\n",
    "\n",
    "fig = raw_cleaned.plot(n_channels=len(raw_cleaned.info['ch_names']), events=events, event_id=event_id, event_color={1:'r', 2:'g'}, scalings=SCALINGS)\n",
    "fig.savefig(f'MNE-graphs/time-amplitude/4---Trigger channels added.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4 Defining and segmenting Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying baseline correction (mode: mean) - baseline=(tmin, 0)\n",
    "# gonogo - 200 msec around stimulus\n",
    "tmin = -0.1\n",
    "tmax = 0.7\n",
    "epochs = mne.Epochs(raw_cleaned, events=events, event_id=None, tmin=tmin, tmax=tmax, baseline=(tmin, 0), detrend=1, preload=True, picks=['eeg'])\n",
    "# epochs.drop_bad() # TODO\n",
    "fig = epochs.plot(n_channels=len(raw_cleaned.info['ch_names']), event_color={1:'r', 2:'g'}, events=events, scalings=SCALINGS)\n",
    "\n",
    "# Calculate EQI score\n",
    "# reshaped_data = convert_epoch_to_raw(epochs)\n",
    "# epoch_to_raw_data = mne.io.RawArray(reshaped_data, info)\n",
    "# find_score(epoch_to_raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment baseline periods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the baseline period relative to the event onset\n",
    "# baseline = (-0.05, 0.2) \n",
    "# epochs.apply_baseline(baseline=baseline)\n",
    "\n",
    "# Calculate EQI score\n",
    "# reshaped_data = convert_epoch_to_raw(epochs)\n",
    "# epoch_to_raw_data = mne.io.RawArray(reshaped_data, info)\n",
    "# find_score(epoch_to_raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Artifact Rejection (EOG/ECG) using ICA on Epoched data\n",
    "\n",
    "Doing ICA detection after epoching because ICA decomposition needs strong signals which we will get in our epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = mne.preprocessing.ICA(\n",
    "    n_components=20, random_state=0)\n",
    "ica.fit(epochs)\n",
    "ica.plot_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find bad ECG and EOG for all channels and plotting epochs data without Removal of ICA cmponents\n",
    "bad_indices_eog = []\n",
    "channels_eog = []\n",
    "bad_indices_ecg = []\n",
    "channels_ecg = []\n",
    "\n",
    "for channel in raw_cleaned.info['ch_names']:\n",
    "    eog, scores_eog = ica.find_bads_eog(epochs, channel, threshold='auto')\n",
    "    if len(eog):\n",
    "        bad_indices_eog.append(eog)\n",
    "        channels_eog.append(channel)\n",
    "    \n",
    "    ecg, scores_ecg = ica.find_bads_ecg(epochs, channel, threshold='auto')\n",
    "    if len(ecg):\n",
    "        bad_indices_ecg.append(ecg)\n",
    "        channels_ecg.append(channel)\n",
    "    \n",
    "print(\"EOG Bad indices\", bad_indices_eog, channels_eog)\n",
    "print(\"ECG Bad indices\", bad_indices_ecg, channels_ecg)\n",
    "\n",
    "excluded_components = []\n",
    "for i in bad_indices_eog:\n",
    "    for j in i:\n",
    "        excluded_components.append(j)\n",
    "for i in bad_indices_ecg:\n",
    "    for j in i:\n",
    "        excluded_components.append(j)\n",
    "excluded_components = list(set(excluded_components))\n",
    "print(\"Excluded components\", excluded_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply removed ICA components for both ECG and EOG for each channel and plot epoched data with removal of ICA componetns\n",
    "cleaned_epochs = ica.apply(epochs, exclude=excluded_components) # ICA algo identifies spatially independent components in EEG \n",
    "cleaned_epochs.plot(n_channels=len(raw_cleaned.info['ch_names']), event_color={1:'r', 2:'g'}, events=events, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EQI score\n",
    "reshaped_data = convert_epoch_to_raw(cleaned_epochs)\n",
    "epoch_to_raw_data = mne.io.RawArray(reshaped_data, info)\n",
    "find_score(epoch_to_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet denoising: \n",
    "signal = raw_cleaned.get_data()\n",
    "t = np.linspace(0, 299, len(signal))\n",
    "# Perform a multi-level wavelet decomposition\n",
    "coeffs = pywt.wavedec(signal, 'db1', level=4)\n",
    "\n",
    "# Set a threshold to nullify smaller coefficients (assumed to be noise)\n",
    "threshold = 0.5\n",
    "coeffs_thresholded = [pywt.threshold(c, threshold, mode='soft') for c in coeffs]\n",
    "\n",
    "# Reconstruct the signal from the thresholded coefficients\n",
    "denoised_signal = pywt.waverec(coeffs_thresholded, 'db1')\n",
    "\n",
    "# Plotting the noisy and denoised signals\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(t, raw_cleaned)\n",
    "plt.title(\"Noisy Signal\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(t, denoised_signal)\n",
    "plt.title(\"Denoised Signal\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Averaging and estimating evoked responses\n",
    "\n",
    "This reduces noise and enhances signal to noise ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = cleaned_epochs # Uncomment if applying EOG/ECG correction on epoched data\n",
    "individual_nogo_epoch_plots = []\n",
    "individual_go_epoch_plots = []\n",
    "nogo = epochs['1'].average()\n",
    "go = epochs['2'].average()\n",
    "# discarded = epochs['3'].average()\n",
    "evokeds = dict(go=go, nogo=nogo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot overlay of individual epochs for each channel: Uncomment below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# nogo_data = nogo.get_data()\n",
    "# go_data = go.get_data()\n",
    "\n",
    "# # Convert to msec\n",
    "# times = epochs.times *1000 # For each epoch -- Sampling frequency (500 samples/sec) * duration of each epoch (800 msec) \n",
    "\n",
    "# for channel_index, channel_name in enumerate(channel_names[:32]):\n",
    "\n",
    "#     # 'F8', 'F4', 'C4', 'P4' - Frontal channels\n",
    "#     # 'Cz', 'C3', 'CP1' - central channels\n",
    "#     # 'Pz', 'F3' - Parietal channels\n",
    "#     gonogo_channels = ['F8', 'F4', 'C4', 'P4', 'Cz', 'C3', 'CP1', 'Pz', 'F3']\n",
    "\n",
    "#     if channel_name in gonogo_channels:\n",
    "\n",
    "#         # Plot Nogo overlay of Individual epochs for each channel\n",
    "#         plt.figure(figsize=(21, 10))\n",
    "#         for ind_epoch, epoch in enumerate(epochs):\n",
    "#             if next(iter(list(epochs[ind_epoch].event_id.values()))) == 1:\n",
    "#                 plt.plot(times, epoch[channel_index], label=f'Epoch {ind_epoch}')\n",
    "#         plt.xlabel('Time (ms)')\n",
    "#         plt.ylabel('Amplitude (V)')\n",
    "#         plt.title(f'NOGO - Overlay of Individual Epochs for channel {channel_name}')\n",
    "#         plt.plot(times, nogo_data[channel_index], linewidth='5')\n",
    "#         plt.show()\n",
    "        \n",
    "#         # Plot Go overlay of Individual epochs for each channel\n",
    "#         plt.figure(figsize=(21, 10))\n",
    "#         for ind_epoch, epoch in enumerate(epochs):\n",
    "#             # print(type(epochs[ind_epoch]), type(epoch)) # <class 'mne.epochs.Epochs'> <class 'numpy.ndarray'> 32X401\n",
    "#             if next(iter(list(epochs[ind_epoch].event_id.values()))) == 2:\n",
    "#                 plt.plot(times, epoch[channel_index], label=f'Epoch {ind_epoch+1}')\n",
    "#         plt.xlabel('Time (ms)')\n",
    "#         plt.ylabel('Amplitude (V)')\n",
    "#         plt.title(f'GO - Overlay of Individual Epochs for channel {channel_name}')\n",
    "#         plt.plot(times, go_data[channel_index], linewidth='5')\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot dropped epochs\n",
    "# epochs.plot_drop_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look for individual go and nogo plots for all 9 channels ( normal and 10X scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for channel_index, channel_name in enumerate(channel_names[:32]):\n",
    "\n",
    "#     # 'F8', 'F4', 'C4', 'P4' - Frontal channels\n",
    "#     # 'Cz', 'C3', 'CP1' - central channels\n",
    "#     # 'Pz', 'F3' - Parietal channels\n",
    "#     gonogo_channels = ['F8', 'F4', 'C4', 'P4', 'Cz', 'C3', 'CP1', 'Pz', 'F3']\n",
    "#     lis = []\n",
    "#     lis.append(channel_name)\n",
    "#     if channel_name in gonogo_channels:\n",
    "#         nogo.plot(picks=lis, titles='Nogo', ylim = dict(eeg=[-5e1, 4e1]), time_unit = 'ms')\n",
    "#         nogo.plot(picks=lis, titles='Nogo 10X scaled', ylim = dict(eeg=[-4e1, 3e1]),  time_unit = 'ms')\n",
    "\n",
    "#         go.plot(picks=lis, titles='Go', ylim = dict(eeg=[-4e1, 3e1]),  time_unit = 'ms')\n",
    "#         go.plot(picks=lis, titles='Go 10X scaled', ylim = dict(eeg=[-4e1, 3e1]), time_unit = 'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. ERP Components analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bads in Go\", go.info['bads'])\n",
    "print(\"Bads in nogo\", nogo.info['bads'])\n",
    "evokeds = dict(go=go, nogo=nogo)\n",
    "fig = go.plot(time_unit='ms', titles='Go-average epoch plot for all channels')\n",
    "fig = nogo.plot(time_unit='ms', titles='NoGo-average epoch plot for all channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go.info['bads'] = []\n",
    "# nogo.info['bads'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evokeds = dict(go=go, nogo=nogo)\n",
    "# fig = go.plot(time_unit='ms', titles='Go-average epoch plot for all channels')\n",
    "# fig.savefig(f'MNE-graphs/go-nogo/go-plot-32channels.png')\n",
    "# fig = nogo.plot(time_unit='ms', titles='NoGo-average epoch plot for all channels')\n",
    "# fig.savefig(f'MNE-graphs/go-nogo/nogo-plot-32channels.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gonogo_channels = ['F8', 'F4', 'C4', 'P4', 'Cz', 'C3', 'CP1', 'Pz', 'F3']\n",
    "erp_components = {'P300': [0, 250, 400], 'N2': [0, 180, 390] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in erp_components.items():\n",
    "    for channel_name in gonogo_channels:\n",
    "        fig = mne.viz.plot_compare_evokeds(evokeds, picks=channel_name, vlines=value, time_unit='ms', title=f'{key} for channel {channel_name}')\n",
    "        # fig[0].savefig(f'MNE-graphs/go-nogo/{channel_name}.png')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
