{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['Hemlata', 'Malti', 'Preeti', 'Sharifa', 'Vinita', 'VKS'] ['Geeta', 'Jitendra', 'Jyoti', 'Kuldeep', 'Seema', 'VijayLaxmi']\n",
    "# ACTIVE_SHAM = 'Active'\n",
    "# SAMPLE = 'Preeti'\n",
    "# ELECTRODES = '32electrodes' # '32electrodes' \n",
    "GROUP1 = 'Pre'\n",
    "GROUP2 = 'Post' # generally GROUP1+1\n",
    "mapping = {0: 'delta', 1: 'theta', 2: 'alpha1', 3:'alpha2', 4:'beta1', 5:'beta2', 6: 'beta3', 7: 'gamma'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import ttest_rel\n",
    "from mne_connectivity import spectral_connectivity_epochs\n",
    "import networkx as nx\n",
    "import numpy as np \n",
    "import glob\n",
    "\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2Pre-TDCS : .easy, # 3TDCS : .easy, # 4Post-TDCS : .easy\n",
    "# import glob\n",
    "# folder_path = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', ELECTRODES, ACTIVE_SHAM)\n",
    "# # folders = ['1Pre-BML', '2Pre-TDCS', '3TDCS', '4Post-TDCS', '5Post-BML']\n",
    "# # folders = ['2Pre-TDCS', '3TDCS', '4Post-TDCS']\n",
    "# all_files = []\n",
    "# # for folder in folders:\n",
    "# #     ext = '.eeg' if folder[0] in ['1', '5'] else 'Close.easy'\n",
    "# #     is_even = 1\n",
    "# #     for _ in glob.glob(os.path.join(folder_path, folder, SAMPLE) + '/*' + ext):\n",
    "# #         if (folder[0] == '3' and is_even%2==1) or folder[0] in ['2', '4']: #TODO: add for both 1 and 5 also \n",
    "# #             all_files.append(_)\n",
    "# #         is_even += 1\n",
    "\n",
    "# #     sorted_files = sorted(all_files, key=lambda x: os.path.getmtime(os.path.join(folder_path, folder, SAMPLE, x)))\n",
    "# # print(len(sorted_files), sorted_files)\n",
    "# folders = ['2Pre-TDCS', '4Post-TDCS']\n",
    "# for folder in folders:\n",
    "#     ext = 'Close.easy'\n",
    "#     for _ in glob.glob(os.path.join(folder_path, folder, SAMPLE) + '/*' + ext):\n",
    "#         all_files.append(_)\n",
    "\n",
    "# print(len(all_files), all_files)\n",
    "\n",
    "# # TODO: ADD iterator that changes Groups value and iterates (len(sorted_files) - 1 times)\n",
    "# raw_1 = data_transformation_easy(all_files[0])\n",
    "# raw_1 = g1_preprocess(raw_1)\n",
    "# raw_2 = data_transformation_easy(all_files[1])\n",
    "# raw_2 = g1_preprocess(raw_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=32, n_times=74999\n",
      "    Range : 0 ... 74998 =      0.000 ...   149.996 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, non-linear phase, causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hann window with 0.0546 passband ripple and 44 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.01 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz\n",
      "- Filter length: 155001 samples (310.002 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwani/Downloads/IITD/Depression-IITD/common.ipynb:256: RuntimeWarning: filter_length (155001) is longer than the signal (50001), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "SSP projectors applied...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=32, n_times=74999\n",
      "    Range : 0 ... 74998 =      0.000 ...   149.996 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, non-linear phase, causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hann window with 0.0546 passband ripple and 44 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.01 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz\n",
      "- Filter length: 155001 samples (310.002 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwani/Downloads/IITD/Depression-IITD/common.ipynb:256: RuntimeWarning: filter_length (155001) is longer than the signal (50001), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "SSP projectors applied...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    }
   ],
   "source": [
    "folder_path = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', ELECTRODES, ACTIVE_SHAM)\n",
    "all_files = []\n",
    "\n",
    "folders = ['2Pre-TDCS', '4Post-TDCS']\n",
    "for folder in folders:\n",
    "    ext = 'Close.easy' if ELECTRODES == '32electrodes' else 'EEG.easy'\n",
    "    for _ in glob.glob(os.path.join(folder_path, folder, SAMPLE) + '/*' + ext):\n",
    "        all_files.append(_)\n",
    "\n",
    "# TODO: ADD iterator that changes Groups value and iterates (len(sorted_files) - 1 times)\n",
    "raw_1 = data_transformation_easy(all_files[0])\n",
    "# SHOW=True\n",
    "# fig = raw_1.plot(\n",
    "#         n_channels=32, \n",
    "#         scalings=SCALINGS,\n",
    "#         show=SHOW\n",
    "#         )\n",
    "# info = raw_1.info\n",
    "\n",
    "# from scipy.io import loadmat\n",
    "# matfiles = glob.glob(os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Preeti_PRE_clean.mat'))\n",
    "# data = {}\n",
    "# print(matfiles)\n",
    "# dat = loadmat(matfiles[0])\n",
    "# raw_2 = np.array(dat['EEG']['data'][0][0])\n",
    "# raw_2 = mne.io.RawArray(raw_2, info)\n",
    "# fig = raw_2.plot(\n",
    "#         n_channels=32, \n",
    "#         scalings=2e2,\n",
    "#         show=SHOW\n",
    "#         )\n",
    "\n",
    "raw_1 = g1_preprocess(raw_1)\n",
    "raw_2 = data_transformation_easy(all_files[1])\n",
    "raw_2 = g1_preprocess(raw_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_file = f\"comparison-results/result-{ACTIVE_SHAM}.xlsx\"\n",
    "df = pd.read_excel(existing_file, header=[0,1])\n",
    "\n",
    "# main_column_names = ['index', 'swi', 'links', 'asymmetry', 'regions']\n",
    "# subcols = ('delta-g1', 'delta-g2', 'theta-g1', 'theta-g2', 'alpha1-g1', 'alpha1-g2', 'alpha2-g1', 'alpha2-g2', \n",
    "#            'beta1-g1', 'beta1-g2', 'beta2-g1', 'beta2-g2', 'beta3-g1', 'beta3-g2', 'gamma-g1', 'gamma-g2')\n",
    "\n",
    "# subcolumn_names = {\n",
    "#     'index' : ['index'],\n",
    "#     'swi': subcols,\n",
    "#     'links': subcols,\n",
    "#     'asymmetry': subcols,\n",
    "#     'regions': ('delta', 'theta', 'alpha1', 'alpha2', 'beta1', 'beta2', 'beta3', 'gamma')\n",
    "# }\n",
    "\n",
    "# columns_tuples = [(main_col, sub_col) for main_col in main_column_names for sub_col in subcolumn_names[main_col]]\n",
    "# columns = pd.MultiIndex.from_tuples(columns_tuples)\n",
    "# df = pd.DataFrame(columns=columns)\n",
    "\n",
    "row_data = {('index', 'index'): f'{ACTIVE_SHAM}-{SAMPLE}-{GROUP1}vs{GROUP2}'}\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 4.0\n",
    "overlap = 2.0 \n",
    "\n",
    "samples_per_epoch = int(duration * SFREQ)\n",
    "samples_per_overlap = int(overlap * SFREQ)\n",
    "\n",
    "# Manually created events\n",
    "start, stop = 0, samples_per_epoch\n",
    "events = []\n",
    "while stop <= len(raw_1):\n",
    "    events.append([start, 0, 1]) \n",
    "    start += samples_per_overlap\n",
    "    stop += samples_per_overlap\n",
    "\n",
    "events = np.array(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Segmenting epochs for Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "49 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Using data from preloaded Raw for 49 events and 2001 original time points ...\n",
      "5 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs_1 = mne.Epochs(raw_1, events, tmin=0, tmax=duration, baseline=None, detrend=1,\n",
    "                    picks=None, preload=True, reject=None)\n",
    "# raw_1.plot(n_channels=len(raw_1.info['ch_names']), events=events, event_color={1:'r'}, scalings=SCALINGS)\n",
    "# epochs_1.plot(n_channels=len(raw_1.info['ch_names']), event_color={1:'r'}, events=events, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib as 2D backend.\n",
      "Fitting ICA to data using 32 channels (please be patient, this may take a while)\n",
      "    Applying projection operator with 1 vector (pre-whitener computation)\n",
      "    Applying projection operator with 1 vector (pre-whitener application)\n",
      "Selecting by number: 20 components\n",
      "    Applying projection operator with 1 vector (pre-whitener application)\n",
      "Fitting ICA took 75.9s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwani/.local/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:128: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# raw_1.plot()\n",
    "# ica = ICA(n_components=20, method='fastica', random_state=23).fit(raw_1)\n",
    "# # ica.exclude = [1]\n",
    "# # raw_clean = ica.apply(raw.copy())\n",
    "# ica.plot_components()\n",
    "# ica.plot_properties(raw_1, picks=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_2 = mne.Epochs(raw_2, events, tmin=0, tmax=duration, baseline=None, detrend=1,\n",
    "                    picks=None, preload=True, reject=None)\n",
    "# raw_2.plot(n_channels=len(raw_1.info['ch_names']), events=events, event_color={1:'r'}, scalings=SCALINGS)\n",
    "# epochs_2.plot(n_channels=len(raw_1.info['ch_names']), event_color={1:'r'}, events=events, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. PSD graph plot between MDD and Control group\n",
    "\n",
    "For resting state EEG channel, analyzing the overall average power across channels provides a holistic view of the brain's activity without emphasizing the specificity of individual channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amplitude plots between both groups\n",
    "epochs_1_avg = epochs_1['1'].average()\n",
    "epochs_2_avg = epochs_2['1'].average()\n",
    "# evokeds = dict(epochs_1=epochs_1)\n",
    "# fig_MDD = epochs_1_avg.plot(titles=GROUP1, time_unit = 'ms')\n",
    "# fig_control = epochs_2_avg.plot(titles=GROUP2, time_unit = 'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 PSD using plot_psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_1.info['ch_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "#plot_psd uses welch method for continuous data\n",
    "raw_1.plot_psd(picks=raw_1.info['ch_names'], average=True, fmin=FMIN, fmax=FMAX, ax=ax, show=True, color='blue', dB=False)\n",
    "raw_2.plot_psd(picks=raw_2.info['ch_names'], average=True, fmin=FMIN, fmax=FMAX, ax=ax, show=True, color='red', dB=False)\n",
    "\n",
    "# dB = True plots PSD in decibels (logarithmic)\n",
    "# different n_fft compared to psd_array_welch\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Power/Frequency (microV^2/Hz)')\n",
    "ax.set_title('Power Spectral Density Comparison')\n",
    "\n",
    "ax.text(0.8, 0.9, GROUP1, color='blue', transform=ax.transAxes)\n",
    "ax.text(0.8, 0.85, GROUP2, color='red', transform=ax.transAxes)\n",
    "\n",
    "plt.ylim(0, 8)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(f'comparison-results/PSD - {SAMPLE} - {GROUP1} vs {GROUP2}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If p value < 0.005, we reject the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PLI and construction of brain function matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pli method always gives positive correlations\n",
    "connectivity = {}\n",
    "def connectivity_matrix(epochs, i):\n",
    "    return spectral_connectivity_epochs(\n",
    "    epochs, method='pli', mode='multitaper', sfreq=SFREQ,\n",
    "    fmin=FREQ_BANDS[mapping[i]][0], fmax=FREQ_BANDS[mapping[i]][1], faverage=True, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = len(raw_1.info['ch_names'])\n",
    "for i in mapping:\n",
    "    con = connectivity_matrix(epochs_1, i)\n",
    "    connectivity[f'{GROUP1}-{mapping[i]}'] = con.get_data().reshape((n_channels, n_channels))\n",
    "\n",
    "    con = connectivity_matrix(epochs_2, i)\n",
    "    connectivity[f'{GROUP2}-{mapping[i]}'] = con.get_data().reshape((n_channels, n_channels))\n",
    "\n",
    "    # Make matrix symmetric\n",
    "    for row in range(n_channels):\n",
    "        for col in range(n_channels):\n",
    "            connectivity[f'{GROUP1}-{mapping[i]}'][row][col] = connectivity[f'{GROUP1}-{mapping[i]}'][col][row]\n",
    "            connectivity[f'{GROUP2}-{mapping[i]}'][row][col] = connectivity[f'{GROUP2}-{mapping[i]}'][col][row]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connectivity[f'{GROUP1}-{mapping[0]}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Thresholding - M1 -  Small World Index\n",
    "\n",
    "Preserves small-world properties in both groups to ensure that any observed differences in connectivity are not biased by the thresholding method.\n",
    "Preserving these properties ensures that information can be transmitted quickly and effectively across the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold = {}\n",
    "edges_1 = {}\n",
    "edges_2 = {}\n",
    "# Generating 50 random networks with same number of vertices and edges \n",
    "random_networks = [nx.gnm_random_graph(n_channels, 496) for _ in range(50)]\n",
    "thresholds = np.arange(0.1, 0.9, 0.002)\n",
    "\n",
    "for i in mapping:\n",
    "    edges_1[mapping[i]] = []\n",
    "    edges_2[mapping[i]] = []\n",
    "    ratios = []\n",
    "    for threshold in thresholds:\n",
    "        g1 = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] > threshold))\n",
    "        Lw_1_binarized, CC_1_binarized = g1[0], g1[3]\n",
    "\n",
    "        g2 = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP2}-{mapping[i]}'] > threshold))\n",
    "        Lw_2_binarized, CC_2_binarized = g2[0], g2[3]\n",
    "\n",
    "        swi_ratio_binarized =  (CC_1_binarized*Lw_2_binarized)/(Lw_1_binarized*CC_2_binarized) if Lw_1_binarized and CC_2_binarized else 0\n",
    "        ratios.append(swi_ratio_binarized)\n",
    "        \n",
    "    optimal_threshold[mapping[i]] = thresholds[np.argmax(np.abs(ratios))]\n",
    "    t_stat, p_value = ttest_rel(connectivity[f'{GROUP1}-{mapping[i]}'].flatten(), connectivity[f'{GROUP2}-{mapping[i]}'].flatten())\n",
    "    if p_value < 0.01: # Reject the null hypotheses\n",
    "        Crand = np.mean([calculate_avergae_components(nx.from_numpy_array((nx.to_numpy_array(G) > optimal_threshold[mapping[i]])))[3] for G in random_networks])\n",
    "        Lrand = np.mean([calculate_avergae_components(nx.from_numpy_array((nx.to_numpy_array(G) > optimal_threshold[mapping[i]])))[0] for G in random_networks])\n",
    "\n",
    "        graph1 = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] > optimal_threshold[mapping[i]]))\n",
    "        Lw_1_binarized, CC_1_binarized = graph1[0], graph1[3]\n",
    "\n",
    "        graph2 = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP2}-{mapping[i]}'] > optimal_threshold[mapping[i]]))\n",
    "        Lw_2_binarized, CC_2_binarized = graph2[0], graph2[3]\n",
    "\n",
    "        swi_binarized_1 =  (CC_1_binarized/Crand)/(Lw_1_binarized/Lrand)\n",
    "        swi_binarized_2 = (CC_2_binarized/Crand)/(Lw_2_binarized/Lrand)\n",
    "        print(swi_binarized_1, \"Cc1 \", CC_1_binarized, \"Lw1 \", Lw_1_binarized)\n",
    "        print(swi_binarized_2, \"Cc2 \", CC_2_binarized, \"Lw2 \", Lw_2_binarized)  \n",
    "\n",
    "        edges_1[mapping[i]].append(nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] > optimal_threshold[mapping[i]]).number_of_edges())\n",
    "        edges_2[mapping[i]].append(nx.from_numpy_array(connectivity[f'{GROUP2}-{mapping[i]}'] > optimal_threshold[mapping[i]]).number_of_edges())\n",
    "\n",
    "        print(f\"{mapping[i]} - Optimal Threshold: {optimal_threshold[mapping[i]]} (Significant)\", p_value)\n",
    "        row_data[('swi', f'{mapping[i]}-g1')] = swi_binarized_1\n",
    "        row_data[('swi', f'{mapping[i]}-g2')] = swi_binarized_2\n",
    "    else:\n",
    "        row_data[('swi', f'{mapping[i]}-g1')] = None\n",
    "        row_data[('swi', f'{mapping[i]}-g2')] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Binarization of functional connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_matrix = {}\n",
    "for i in mapping:\n",
    "    binarized_matrix[f'{GROUP1}-{mapping[i]}'] = connectivity[f'{GROUP1}-{mapping[i]}'] > optimal_threshold[mapping[i]]\n",
    "    binarized_matrix[f'{GROUP2}-{mapping[i]}'] = connectivity[f'{GROUP2}-{mapping[i]}'] > optimal_threshold[mapping[i]]\n",
    "print(binarized_matrix.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find number of links in each graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mapping:\n",
    "    links_1 = 0\n",
    "    links_2 = 0\n",
    "\n",
    "    for row in range(n_channels):\n",
    "        for col in range(row+1):\n",
    "            if binarized_matrix[f'{GROUP1}-{mapping[i]}'][row][col] == 1:\n",
    "                links_1+=1\n",
    "            if binarized_matrix[f'{GROUP2}-{mapping[i]}'][row][col] == 1:\n",
    "                links_2+=1\n",
    "\n",
    "    print(f'{GROUP1}-{mapping[i]}-number of links: K=', links_1)\n",
    "    print(f'{GROUP2}-{mapping[i]}-number of links: K=', links_2)\n",
    "\n",
    "    row_data[('links', f'{mapping[i]}-g1')] = links_1\n",
    "    row_data[('links', f'{mapping[i]}-g2')] = links_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Asymmetry in  each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_region = ['Fp1', 'AF3', 'PO3','O1', 'CP1', 'FC1', 'P3', 'C3', 'F3', 'F7', 'FC5', 'CP5', 'T7', 'P7']\n",
    "right_region = ['P8', 'T8', 'CP6', 'FC6', 'F8', 'F4', 'C4', 'P4', 'AF4', 'Fp2', 'FC2', 'CP2', 'O2', 'PO4']\n",
    "\n",
    "for i in mapping:\n",
    "    lr = 1\n",
    "    rr = 1\n",
    "    lrc = 1\n",
    "    rrc = 1\n",
    "    for row in range(n_channels):\n",
    "        for col in range(row+1):\n",
    "            if binarized_matrix[f'{GROUP1}-{mapping[i]}'][row][col] == 1:\n",
    "                if raw_1.info['ch_names'][row] in left_region or raw_1.info['ch_names'][col] in left_region:\n",
    "                    lr += 1\n",
    "                if raw_1.info['ch_names'][row] in right_region or raw_1.info['ch_names'][col] in right_region:\n",
    "                    rr += 1\n",
    "                # print(raw_1.info['ch_names'][row], raw_1.info['ch_names'][col])\n",
    "\n",
    "            if binarized_matrix[f'{GROUP2}-{mapping[i]}'][row][col] == 1:\n",
    "                if raw_1.info['ch_names'][row] in left_region or raw_1.info['ch_names'][col] in left_region:\n",
    "                    lrc += 1\n",
    "                if raw_1.info['ch_names'][row] in right_region or raw_1.info['ch_names'][col] in right_region:\n",
    "                    rrc += 1\n",
    "                # print(raw_1.info['ch_names'][row], raw_1.info['ch_names'][col])\n",
    "\n",
    "    print(f\"{GROUP1}: \",mapping[i], \"left region: \", lr, \"right region: \", rr, \"proportion: \", lr/(rr))\n",
    "    print(f\"{GROUP2}: \", mapping[i], \"left region: \", lrc, \"right region: \", rrc, \"proportion: \", lrc/(rrc))\n",
    "\n",
    "    row_data[('asymmetry', f'{mapping[i]}-g1')] = lr/rr\n",
    "    row_data[('asymmetry', f'{mapping[i]}-g2')] = lrc/rrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Difference matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_index(channels_list, raw):\n",
    "    indexes = []\n",
    "    for channel in channels_list:\n",
    "        for i in range(len(raw.info['ch_names'])):\n",
    "            if raw.info['ch_names'][i]==channel:\n",
    "                indexes.append(i)\n",
    "    return(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_channels = return_index(['Pz', 'Oz', 'Fz', 'Cz'], raw_1)\n",
    "central_channels\n",
    "raw_1.info['bads'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_matrix = {}\n",
    "for i in mapping:\n",
    "    difference_matrix[mapping[i]] = binarized_matrix[f'{GROUP2}-{mapping[i]}'].astype(int) - binarized_matrix[f'{GROUP1}-{mapping[i]}'].astype(int) \n",
    "    # difference_matrix[mapping[i]] = binarized_matrix[f'{GROUP1}-{mapping[i]}'].astype(int) - binarized_matrix[f'{GROUP2}-{mapping[i]}'].astype(int)\n",
    "    for k in range(n_channels):\n",
    "        for l in range(n_channels):\n",
    "            if difference_matrix[mapping[i]][k][l] == -1 or k in central_channels or l in central_channels:\n",
    "                difference_matrix[mapping[i]][k][l] = 0\n",
    "\n",
    "    # plot_sensors_connectivity(\n",
    "    #     raw_1.info,\n",
    "    #     difference_matrix[mapping[i]],\n",
    "    #     cbar_label=f'{mapping[i]}-Connectivity',\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels = {}\n",
    "for i in mapping:\n",
    "    selected_channels[mapping[i]] = []\n",
    "    for ch in range(32):\n",
    "        # TODO: instead of number of edges wise, we can explore other algorithm\n",
    "        if len(nx.from_numpy_array(difference_matrix[mapping[i]]).edges(ch)) > 5:\n",
    "            selected_channels[mapping[i]].append(raw_1.info['ch_names'][ch])\n",
    "print(selected_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary of Regions in brain vs channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionvschannel = {\n",
    "    'LC': ['C3', 'CP1', 'CP5', 'FC1', 'FC5'], # Left central \n",
    "    'LF': ['FP1', 'AF3', 'F3', 'F7'], # Left frontal\n",
    "    'LT': ['T7'], # Left temporal\n",
    "    'LPO': ['PO3',  'P3', 'P7', 'O1'], # Left parietal-occipital\n",
    "    'RC': ['CP6', 'FC6', 'C4', 'FC2', 'CP2',], # Right central \n",
    "    'RF': ['F8', 'F4', 'AF4', 'FP2'], # Right frontal\n",
    "    'RT': ['T8'], # Right temporal\n",
    "    'RPO': ['P8', 'P4', 'PO4', 'O2'] , # Right parietal-occipital\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_to_region = {}\n",
    "for region, region_channels in regionvschannel.items():\n",
    "    for channel in region_channels:\n",
    "        channel_to_region[channel] = region\n",
    "\n",
    "selected_regions = {}\n",
    "for band, channels in selected_channels.items():\n",
    "    regions = set()\n",
    "    for channel in channels:\n",
    "        if channel in channel_to_region:\n",
    "            regions.add(channel_to_region[channel])\n",
    "    selected_regions[band] = list(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_data = {('index', 'index'): 'Active-Preeti-0vs1',\n",
    "#  ('swi', 'delta-g1'): 0.0984126984126984,\n",
    "#  ('swi', 'delta-g2'): 0.0462557603686636,\n",
    "#  ('swi', 'theta-g1'): 0.04757092643735877,\n",
    "#  ('swi', 'theta-g2'): 0.012385844748858447,\n",
    "#  ('swi', 'alpha1-g1'): None,\n",
    "#  ('swi', 'alpha1-g2'): None,\n",
    "#  ('swi', 'alpha2-g1'): None,\n",
    "#  ('swi', 'alpha2-g2'): None,\n",
    "#  ('swi', 'beta1-g1'): None,\n",
    "#  ('swi', 'beta1-g2'): None,\n",
    "#  ('swi', 'beta2-g1'): None,\n",
    "#  ('swi', 'beta2-g2'): None,\n",
    "#  ('swi', 'beta3-g1'): None,\n",
    "#  ('swi', 'beta3-g2'): None,\n",
    "#  ('swi', 'gamma-g1'): None,\n",
    "#  ('swi', 'gamma-g2'): None,\n",
    "#  ('links', 'delta-g1'): 9,\n",
    "#  ('links', 'delta-g2'): 43,\n",
    "#  ('links', 'theta-g1'): 21,\n",
    "#  ('links', 'theta-g2'): 35,\n",
    "#  ('links', 'alpha1-g1'): 42,\n",
    "#  ('links', 'alpha1-g2'): 31,\n",
    "#  ('links', 'alpha2-g1'): 119,\n",
    "#  ('links', 'alpha2-g2'): 61,\n",
    "#  ('links', 'beta1-g1'): 126,\n",
    "#  ('links', 'beta1-g2'): 174,\n",
    "#  ('links', 'beta2-g1'): 101,\n",
    "#  ('links', 'beta2-g2'): 88,\n",
    "#  ('links', 'beta3-g1'): 57,\n",
    "#  ('links', 'beta3-g2'): 63,\n",
    "#  ('links', 'gamma-g1'): 30,\n",
    "#  ('links', 'gamma-g2'): 37,\n",
    "#  ('asymmetry', 'delta-g1'): 1.6,\n",
    "#  ('asymmetry', 'delta-g2'): 1.0357142857142858,\n",
    "#  ('asymmetry', 'theta-g1'): 1.0,\n",
    "#  ('asymmetry', 'theta-g2'): 0.8571428571428571,\n",
    "#  ('asymmetry', 'alpha1-g1'): 1.3181818181818181,\n",
    "#  ('asymmetry', 'alpha1-g2'): 1.0454545454545454,\n",
    "#  ('asymmetry', 'alpha2-g1'): 1.0266666666666666,\n",
    "#  ('asymmetry', 'alpha2-g2'): 0.8837209302325582,\n",
    "#  ('asymmetry', 'beta1-g1'): 0.9156626506024096,\n",
    "#  ('asymmetry', 'beta1-g2'): 1.0625,\n",
    "#  ('asymmetry', 'beta2-g1'): 1.1355932203389831,\n",
    "#  ('asymmetry', 'beta2-g2'): 1.4130434782608696,\n",
    "#  ('asymmetry', 'beta3-g1'): 1.5185185185185186,\n",
    "#  ('asymmetry', 'beta3-g2'): 1.2352941176470589,\n",
    "#  ('asymmetry', 'gamma-g1'): 1.1666666666666667,\n",
    "#  ('asymmetry', 'gamma-g2'): 1.0,\n",
    "#  ('regions', 'delta'): ['LC', 'RC'],\n",
    "#  ('regions', 'theta'): ['LC'],\n",
    "#  ('regions', 'alpha1'): [],\n",
    "#  ('regions', 'alpha2'): [],\n",
    "#  ('regions', 'beta1'): ['RT', 'LC', 'RF', 'LF', 'RC', 'LPO'],\n",
    "#  ('regions', 'beta2'): [],\n",
    "#  ('regions', 'beta3'): [],\n",
    "#  ('regions', 'gamma'): []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mapping:\n",
    "    row_data[('regions', mapping[i])] = selected_regions[mapping[i]]\n",
    "row_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(df.index)\n",
    "new_row = pd.Series(row_data)\n",
    "print(\"length\", len(df))\n",
    "print(\"new row\", new_row)\n",
    "df.loc[len(df)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the column index\n",
    "df.to_excel(existing_file, index=True, header=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
