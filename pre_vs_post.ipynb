{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.common import *\n",
    "# %run common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ['Hemlata', 'Malti', 'Preeti', 'Sharifa', 'Vinita', 'VKS'] ['Geeta', 'Jitendra', 'Jyoti', 'Kuldeep', 'Seema', 'VijayLaxmi']\n",
    "ACTIVE_SHAM = 'Active'\n",
    "SAMPLE = 'Hemlata'\n",
    "ELECTRODES = '32electrodes' # '32electrodes' \n",
    "GROUP1 = 'Pre'\n",
    "GROUP2 = 'Post' # generally GROUP1+1\n",
    "mapping = {0: 'theta', 1: 'alpha', 2: 'beta'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import mne\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os\n",
    "# from scipy.stats import ttest_rel\n",
    "# from mne_connectivity import spectral_connectivity_epochs\n",
    "# import networkx as nx\n",
    "# import numpy as np \n",
    "# import glob\n",
    "\n",
    "# matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2Pre-TDCS : .easy, # 3TDCS : .easy, # 4Post-TDCS : .easy\n",
    "# import glob\n",
    "# folder_path = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', ELECTRODES, ACTIVE_SHAM)\n",
    "# # folders = ['1Pre-BML', '2Pre-TDCS', '3TDCS', '4Post-TDCS', '5Post-BML']\n",
    "# # folders = ['2Pre-TDCS', '3TDCS', '4Post-TDCS']\n",
    "# all_files = []\n",
    "# # for folder in folders:\n",
    "# #     ext = '.eeg' if folder[0] in ['1', '5'] else 'Close.easy'\n",
    "# #     is_even = 1\n",
    "# #     for _ in glob.glob(os.path.join(folder_path, folder, SAMPLE) + '/*' + ext):\n",
    "# #         if (folder[0] == '3' and is_even%2==1) or folder[0] in ['2', '4']: #TODO: add for both 1 and 5 also \n",
    "# #             all_files.append(_)\n",
    "# #         is_even += 1\n",
    "\n",
    "# #     sorted_files = sorted(all_files, key=lambda x: os.path.getmtime(os.path.join(folder_path, folder, SAMPLE, x)))\n",
    "# # print(len(sorted_files), sorted_files)\n",
    "# folders = ['2Pre-TDCS', '4Post-TDCS']\n",
    "# for folder in folders:\n",
    "#     ext = 'Close.easy'\n",
    "#     for _ in glob.glob(os.path.join(folder_path, folder, SAMPLE) + '/*' + ext):\n",
    "#         all_files.append(_)\n",
    "\n",
    "# print(len(all_files), all_files)\n",
    "\n",
    "# # TODO: ADD iterator that changes Groups value and iterates (len(sorted_files) - 1 times)\n",
    "# raw_1 = data_transformation_easy(all_files[0])\n",
    "# raw_1 = g1_preprocess(raw_1)\n",
    "# raw_2 = data_transformation_easy(all_files[1])\n",
    "# raw_2 = g1_preprocess(raw_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=32, n_times=74999\n",
      "    Range : 0 ... 74998 =      0.000 ...   149.996 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "SSP projectors applied...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, non-linear phase, causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hann window with 0.0546 passband ripple and 44 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.01 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz\n",
      "- Filter length: 155001 samples (310.002 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwani/Downloads/IITD/Depression-IITD/common.ipynb:255: RuntimeWarning: filter_length (155001) is longer than the signal (74999), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  ]\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=32, n_times=74999\n",
      "    Range : 0 ... 74998 =      0.000 ...   149.996 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "SSP projectors applied...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, non-linear phase, causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hann window with 0.0546 passband ripple and 44 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.01 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz\n",
      "- Filter length: 155001 samples (310.002 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwani/Downloads/IITD/Depression-IITD/common.ipynb:255: RuntimeWarning: filter_length (155001) is longer than the signal (74999), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  ]\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
     ]
    }
   ],
   "source": [
    "folder_path = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', ELECTRODES, ACTIVE_SHAM)\n",
    "all_files = []\n",
    "\n",
    "folders = ['2Pre-TDCS', '4Post-TDCS']\n",
    "for folder in folders:\n",
    "    ext = 'Close.easy' if ELECTRODES == '32electrodes' else 'EEG.easy'\n",
    "    for _ in glob.glob(os.path.join(folder_path, folder, SAMPLE) + '/*' + ext):\n",
    "        all_files.append(_)\n",
    "\n",
    "# TODO: ADD iterator that changes Groups value and iterates (len(sorted_files) - 1 times)\n",
    "raw_1 = data_transformation_easy(all_files[0])\n",
    "# SHOW=True\n",
    "# fig = raw_1.plot(\n",
    "#         n_channels=32, \n",
    "#         scalings=SCALINGS,\n",
    "#         show=SHOW\n",
    "#         )\n",
    "# info = raw_1.info\n",
    "\n",
    "# from scipy.io import loadmat\n",
    "# matfiles = glob.glob(os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Preeti_PRE_clean.mat'))\n",
    "# data = {}\n",
    "# print(matfiles)\n",
    "# dat = loadmat(matfiles[0])\n",
    "# raw_2 = np.array(dat['EEG']['data'][0][0])\n",
    "# raw_2 = mne.io.RawArray(raw_2, info)\n",
    "# fig = raw_2.plot(\n",
    "#         n_channels=32, \n",
    "#         scalings=2e2,\n",
    "#         show=SHOW\n",
    "#         )\n",
    "\n",
    "raw_1 = g1_preprocess(raw_1)\n",
    "raw_2 = data_transformation_easy(all_files[1])\n",
    "raw_2 = g1_preprocess(raw_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th colspan=\"6\" halign=\"left\">swn</th>\n",
       "      <th colspan=\"3\" halign=\"left\">cc</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">eglo</th>\n",
       "      <th colspan=\"6\" halign=\"left\">eloc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>theta-g1</th>\n",
       "      <th>theta-g2</th>\n",
       "      <th>alpha-g1</th>\n",
       "      <th>alpha-g2</th>\n",
       "      <th>beta-g1</th>\n",
       "      <th>beta-g2</th>\n",
       "      <th>theta-g1</th>\n",
       "      <th>theta-g2</th>\n",
       "      <th>alpha-g1</th>\n",
       "      <th>...</th>\n",
       "      <th>alpha-g1</th>\n",
       "      <th>alpha-g2</th>\n",
       "      <th>beta-g1</th>\n",
       "      <th>beta-g2</th>\n",
       "      <th>theta-g1</th>\n",
       "      <th>theta-g2</th>\n",
       "      <th>alpha-g1</th>\n",
       "      <th>alpha-g2</th>\n",
       "      <th>beta-g1</th>\n",
       "      <th>beta-g2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [(index, index), (swn, theta-g1), (swn, theta-g2), (swn, alpha-g1), (swn, alpha-g2), (swn, beta-g1), (swn, beta-g2), (cc, theta-g1), (cc, theta-g2), (cc, alpha-g1), (cc, alpha-g2), (cc, beta-g1), (cc, beta-g2), (lavg, theta-g1), (lavg, theta-g2), (lavg, alpha-g1), (lavg, alpha-g2), (lavg, beta-g1), (lavg, beta-g2), (eglo, theta-g1), (eglo, theta-g2), (eglo, alpha-g1), (eglo, alpha-g2), (eglo, beta-g1), (eglo, beta-g2), (eloc, theta-g1), (eloc, theta-g2), (eloc, alpha-g1), (eloc, alpha-g2), (eloc, beta-g1), (eloc, beta-g2)]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_file = f\"comparison-results/result-active-latest.xlsx\"\n",
    "df = pd.read_excel(existing_file, header=[0,1])\n",
    "\n",
    "main_column_names = ['index', 'swn', 'cc', 'lavg', 'eglo', 'eloc']\n",
    "subcols = ('theta-g1', 'theta-g2', 'alpha-g1', 'alpha-g2', 'beta-g1', 'beta-g2')\n",
    "\n",
    "# subcolumn_names = {\n",
    "#     'index' : ['index'],\n",
    "#     # 'links': subcols,\n",
    "#     # 'asymmetry': subcols,\n",
    "#     'swn': subcols,\n",
    "#     'cc' : subcols,\n",
    "#     'lavg': subcols,\n",
    "#     'eglo': subcols,\n",
    "#     'eloc': subcols,\n",
    "#     # 'hubs': ('theta', 'alpha', 'beta'),\n",
    "#     # 'channels': ('theta', 'alpha', 'beta'),\n",
    "#     # 'regions': ('theta', 'alpha', 'beta'),\n",
    "# }\n",
    "\n",
    "# columns_tuples = [(main_col, sub_col) for main_col in main_column_names for sub_col in subcolumn_names[main_col]]\n",
    "# columns = pd.MultiIndex.from_tuples(columns_tuples)\n",
    "# df = pd.DataFrame(columns=columns)\n",
    "\n",
    "row_data = {('index', 'index'): f'{ACTIVE_SHAM}-{SAMPLE}-{GROUP1}vs{GROUP2}'}\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. PSD graph plot between MDD and Control group\n",
    "\n",
    "For resting state EEG channel, analyzing the overall average power across channels provides a holistic view of the brain's activity without emphasizing the specificity of individual channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 PSD using plot_psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().\n",
      "Effective window size : 4.096 (s)\n",
      "NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().\n",
      "Effective window size : 4.096 (s)\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "#plot_psd uses welch method for continuous data\n",
    "raw_1.plot_psd(picks=raw_1.info['ch_names'], average=True, fmin=FMIN, fmax=FMAX, ax=ax, show=False, color='blue', dB=False)\n",
    "raw_2.plot_psd(picks=raw_2.info['ch_names'], average=True, fmin=FMIN, fmax=FMAX, ax=ax, show=False, color='red', dB=False)\n",
    "\n",
    "# dB = True plots PSD in decibels (logarithmic)\n",
    "# different n_fft compared to psd_array_welch\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Power/Frequency (microV^2/Hz)')\n",
    "ax.set_title('Power Spectral Density Comparison')\n",
    "\n",
    "ax.text(0.8, 0.9, GROUP1, color='blue', transform=ax.transAxes)\n",
    "ax.text(0.8, 0.85, GROUP2, color='red', transform=ax.transAxes)\n",
    "\n",
    "plt.ylim(0, 8)\n",
    "# plt.show()\n",
    "\n",
    "fig.savefig(f'comparison-results/PSD - {SAMPLE} - {GROUP1} vs {GROUP2}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Epoching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 4.0\n",
    "overlap = 2.0 \n",
    "\n",
    "samples_per_epoch = int(duration * SFREQ)\n",
    "samples_per_overlap = int(overlap * SFREQ)\n",
    "\n",
    "# Manually created events\n",
    "start, stop = 0, samples_per_epoch\n",
    "events = []\n",
    "while stop <= len(raw_1):\n",
    "    events.append([start, 0, 1]) \n",
    "    start += samples_per_overlap\n",
    "    stop += samples_per_overlap\n",
    "\n",
    "events = np.array(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Segmenting epochs for Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "49 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Using data from preloaded Raw for 49 events and 2001 original time points ...\n",
      "5 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs_1 = mne.Epochs(raw_1, events, tmin=0, tmax=duration, baseline=None, detrend=1,\n",
    "                    picks=None, preload=True, reject=None)\n",
    "# raw_1.plot(n_channels=len(raw_1.info['ch_names']), events=events, event_color={1:'r'}, scalings=SCALINGS)\n",
    "# epochs_1.plot(n_channels=len(raw_1.info['ch_names']), event_color={1:'r'}, events=events, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_1.plot()\n",
    "# ica = ICA(n_components=20, method='fastica', random_state=23).fit(raw_1)\n",
    "# # ica.exclude = [1]\n",
    "# # raw_clean = ica.apply(raw.copy())\n",
    "# ica.plot_components()\n",
    "# ica.plot_properties(raw_1, picks=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "49 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Using data from preloaded Raw for 49 events and 2001 original time points ...\n",
      "5 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs_2 = mne.Epochs(raw_2, events, tmin=0, tmax=duration, baseline=None, detrend=1,\n",
    "                    picks=None, preload=True, reject=None)\n",
    "# raw_2.plot(n_channels=len(raw_1.info['ch_names']), events=events, event_color={1:'r'}, scalings=SCALINGS)\n",
    "# epochs_2.plot(n_channels=len(raw_1.info['ch_names']), event_color={1:'r'}, events=events, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import autoreject\n",
    "\n",
    "# ar = autoreject.AutoReject(n_interpolate=[1, 2, 3, 4], random_state=11,n_jobs=1, verbose=True)\n",
    "# ar.fit(epochs_1[:20])  # fit on a few epochs to save time\n",
    "# epochs_1, reject_log = ar.transform(epochs_1, return_log=True)\n",
    "\n",
    "\n",
    "# ar = autoreject.AutoReject(n_interpolate=[1, 2, 3, 4], random_state=11,n_jobs=1, verbose=True)\n",
    "# ar.fit(epochs_2[:20])  # fit on a few epochs to save time\n",
    "# epochs_2, reject_log = ar.transform(epochs_2, return_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amplitude plots between both groups\n",
    "epochs_1_avg = epochs_1['1'].average()\n",
    "epochs_2_avg = epochs_2['1'].average()\n",
    "# evokeds = dict(epochs_1=epochs_1)\n",
    "# fig_MDD = epochs_1_avg.plot(titles=GROUP1, time_unit = 'ms')\n",
    "# fig_control = epochs_2_avg.plot(titles=GROUP2, time_unit = 'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. PLI and construction of brain function matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pli method always gives positive correlations\n",
    "connectivity = {}\n",
    "def connectivity_matrix(epochs, i):\n",
    "    return spectral_connectivity_epochs(\n",
    "    epochs, method='pli', mode='multitaper', sfreq=SFREQ,\n",
    "    fmin=FREQ_BANDS[mapping[i]][0], fmax=FREQ_BANDS[mapping[i]][1], faverage=True, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 4.2Hz..8.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Adding metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 4.2Hz..8.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 8.2Hz..13.0Hz (20 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 8.2Hz..13.0Hz (20 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 13.2Hz..30.0Hz (68 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 13.2Hz..30.0Hz (68 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n"
     ]
    }
   ],
   "source": [
    "n_channels = len(raw_1.info['ch_names'])\n",
    "for i in mapping:\n",
    "    con = connectivity_matrix(epochs_1, i)\n",
    "    connectivity[f'{GROUP1}-{mapping[i]}'] = con.get_data().reshape((n_channels, n_channels))\n",
    "\n",
    "    con = connectivity_matrix(epochs_2, i)\n",
    "    connectivity[f'{GROUP2}-{mapping[i]}'] = con.get_data().reshape((n_channels, n_channels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Thresholding - M1 -  Small World Index\n",
    "\n",
    "Preserves small-world properties in both groups to ensure that any observed differences in connectivity are not biased by the thresholding method.\n",
    "Preserving these properties ensures that information can be transmitted quickly and effectively across the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_random_graph(n, e):\n",
    "#     adj_matrix = np.zeros((n, n))\n",
    "#     edges = [(i, j) for i in range(n) for j in range(i) if i != j]\n",
    "#     selected_edges = np.random.choice(len(edges), e, replace=False)\n",
    "#     for edge_idx in selected_edges:\n",
    "#         i, j = edges[edge_idx]\n",
    "#         adj_matrix[i, j] = 1\n",
    "#     return adj_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_symmetric(arr, n_channels):\n",
    "    for row in range(n_channels):\n",
    "        for col in range(n_channels):\n",
    "            arr[row][col] = arr[col][row]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_swn(mat, threshold):\n",
    "    tthresh = np.median(mat[mat!=0]) + threshold*np.std(mat[mat!=0])\n",
    "    print(\"*****111111******\", tthresh)\n",
    "    binmat= mat > tthresh\n",
    "    n_connections = np.count_nonzero(binmat == 1)\n",
    "    print(\"*****222222******\", n_connections)\n",
    "    binmat = make_symmetric(binmat.astype(int), n_channels)\n",
    "    g= calculate_avergae_components(nx.from_numpy_array(binmat))\n",
    "    Lw_binarized, CC_binarized = g[0], g[3]\n",
    "    return (CC_binarized/Lw_binarized if n_connections else 0), n_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WINDOW_SIZE = 5\n",
    "# def moving_average(data, window_size = WINDOW_SIZE):\n",
    "#     cumsum = np.cumsum(data, dtype=float)\n",
    "#     cumsum[window_size:] = cumsum[window_size:] - cumsum[:-window_size]\n",
    "#     return cumsum[window_size - 1:] / window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****111111****** 0.8744822485706025\n",
      "*****222222****** 66\n",
      "*****111111****** 1.1455771742137255\n",
      "*****222222****** 0\n",
      "*****111111****** 0.7666694424523433\n",
      "*****222222****** 160\n",
      "*****111111****** 0.9664022622104461\n",
      "*****222222****** 154\n",
      "*****111111****** 0.9315364699548206\n",
      "*****222222****** 32\n",
      "*****111111****** 1.2867589773164063\n",
      "*****222222****** 0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "n_perms = 1000\n",
    "n_network = n_perms//10\n",
    "# thresholds = np.linspace(0, 1.5, 200)\n",
    "swn_z_1, swn_z_2 = {}, {}\n",
    "# optimal_threshold = {}\n",
    "optimal_swn_perms, optimal_swn_real1, optimal_swn_real2 = {}, {}, {}\n",
    "# moving_avg1, moving_avg2 = {}, {}\n",
    "\n",
    "for i in mapping:\n",
    "    conmat1, conmat2 = connectivity[f'{GROUP1}-{mapping[i]}'], connectivity[f'{GROUP2}-{mapping[i]}']\n",
    "    # swn_z_1[mapping[i]], swn_z_2[mapping[i]] = 0, 0\n",
    "    # optimal_swn_perms[mapping[i]], optimal_swn_real1[mapping[i]], optimal_swn_real2[mapping[i]] = [[] for _ in range(len(thresholds))], np.zeros(len(thresholds)),  np.zeros(len(thresholds))\n",
    "    # max_diff = 0\n",
    "    if ACTIVE_SHAM == 'Active':\n",
    "        x = {'theta': 0.9422110552763826, 'alpha': 0.4824120603015075, 'beta': 1.2738693467336675}\n",
    "    else:\n",
    "        x = {'theta': 0.2788944723618091, 'alpha': 0.391959798994975, 'beta': 0.2638190954773868}\n",
    "    threshold = x[mapping[i]]\n",
    "    # for threshi, threshold in enumerate(thresholds):\n",
    "    #     print(\"00000000\", threshi, threshold)\n",
    "    \n",
    "    swn_1, n_connections1 = calculate_swn(conmat1, threshold)\n",
    "    swn_2, n_connections2 = calculate_swn(conmat2, threshold)\n",
    "\n",
    "    # Create #n_network random matrices with vertices: n_channels and edges: average of edges of thresholded binary matrix of both groups \n",
    "    # And make a list of #n_network lists of clustering coeffs and shortest avg path length\n",
    "    # Crand, Lrand = [], []\n",
    "    # swn_perms = np.zeros(n_perms)\n",
    "    # for perm in range(n_network):\n",
    "    #     random_binmat = create_random_graph(n_channels, (n_connections1+n_connections2)//2)\n",
    "    #     random_binmat = make_symmetric(random_binmat, n_channels)\n",
    "    #     grand = calculate_avergae_components(nx.from_numpy_array(random_binmat))\n",
    "    #     Crand.append(grand[3])\n",
    "    #     Lrand.append(grand[0])\n",
    "\n",
    "    # print(\"CHECK\", Crand.count(0))\n",
    "    # print(\"CHECK2\", Lrand.count(0))\n",
    "    # # choose any 2 random network from above n_networks #n_perms times \n",
    "    # for perm in range(n_perms):\n",
    "    #     whichnetworks2use = random.sample(range(n_network), 2)\n",
    "    #     if Crand[whichnetworks2use[1]] and Lrand[whichnetworks2use[0]]:\n",
    "    #         swn_perms[perm] = (Crand[whichnetworks2use[0]] / Crand[whichnetworks2use[1]]) / (Lrand[whichnetworks2use[0]] / Lrand[whichnetworks2use[1]])\n",
    "    #     else:\n",
    "    #         perm -= 1\n",
    "    \n",
    "    # swn_rand_avg = np.mean(Crand, axis=0)/np.mean(Lrand, axis=0)\n",
    "    # swn_real_1 = swn_1 / swn_rand_avg # TODO: different random avg or same ?\n",
    "    # swn_real_2 = swn_2 / swn_rand_avg\n",
    "    # val1, val2 = (swn_real_1 - np.mean(swn_perms)) / np.std(swn_perms), (swn_real_2 - np.mean(swn_perms)) / np.std(swn_perms)\n",
    "    # swn_z_1[mapping[i]] = val1\n",
    "    # swn_z_2[mapping[i]] = val2\n",
    "\n",
    "    # max_diff = 0\n",
    "    # moving_avg1[mapping[i]] = moving_average(swn_z_1[mapping[i]])\n",
    "    # moving_avg2[mapping[i]] = moving_average(swn_z_2[mapping[i]])\n",
    "    # moving_threshold = moving_average(thresholds)\n",
    "\n",
    "    # print(\"$$$$$\", optimal_swn_perms[mapping[i]])\n",
    "    # optimal_swn_perms[mapping[i]] = swn_perms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # High standardized network metric suggests that our network exhibits properties away from random networks \n",
    "# for i in mapping:\n",
    "#     plt.plot(thresholds, swn_z_1[mapping[i]], '-o', markerfacecolor='w', label=f'{GROUP1}')\n",
    "#     plt.plot(thresholds, swn_z_2[mapping[i]], '-o', markerfacecolor='w', label=f'{GROUP2}')\n",
    "#     plt.xlabel(f'Threshold (Standard deviations above median) at frequency band {mapping[i]}')\n",
    "#     plt.ylabel(f'SWN_z')\n",
    "#     plt.xlim([0, 1.5])\n",
    "#     plt.legend()\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Binarization of functional connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To maximize the statistical significance of small world networkness for both groups while \n",
    "# # maximizing the difference between the z-normalized small world networks of the two groups.\n",
    "# f, axarr = plt.subplots(1,3, figsize=(100, 5)) \n",
    "# for count, i in enumerate(mapping):\n",
    "#     max_diff = 0\n",
    "#     for mov in range(len(moving_threshold)):\n",
    "#         x = np.abs(moving_avg1[mapping[i]][mov] - moving_avg2[mapping[i]][mov])\n",
    "#         if x>max_diff:\n",
    "#             max_diff = x\n",
    "#             optimal_threshold[mapping[i]] = moving_threshold[mov]\n",
    "#             index = mov\n",
    "\n",
    "#     # TODO: save fig file\n",
    "#     p_value_1 = np.mean(optimal_swn_perms[mapping[i]][index+(WINDOW_SIZE//2)] >= optimal_swn_real1[mapping[i]][index+(WINDOW_SIZE//2)])\n",
    "#     p_value_2 = np.mean(optimal_swn_perms[mapping[i]][index+(WINDOW_SIZE//2)] >= optimal_swn_real2[mapping[i]][index+(WINDOW_SIZE//2)])\n",
    "#     print(mapping[i], \"p-value: \", p_value_1, p_value_2)\n",
    "\n",
    "\n",
    "#     axarr[count].hist(optimal_swn_perms[mapping[i]][index+(WINDOW_SIZE//2)], bins=50, color='b', alpha=0.7)\n",
    "#     axarr[count].axvline(optimal_swn_real1[mapping[i]][mov+(WINDOW_SIZE//2)], color='m', linewidth=3, label=f'{GROUP1}')\n",
    "#     axarr[count].axvline(optimal_swn_real2[mapping[i]][mov+(WINDOW_SIZE//2)], color='r', linewidth=3, label=f'{GROUP2}')\n",
    "#     axarr[count].set_xlabel(f'{mapping[i]}')\n",
    "#     axarr[count].set_xlim([0,10])\n",
    "#     # axarr[count].set_ylim([0,100])\n",
    "#     axarr[count].legend()\n",
    "# f.suptitle('Random Network distribution for both Pre and Post groups')\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2738693467336675\n",
      "0.8744822485706025 1.1455771742137255\n",
      "0.7666694424523433 0.9664022622104461\n",
      "0.9315364699548206 1.2867589773164063\n",
      "dict_keys(['Pre-theta', 'Post-theta', 'Pre-alpha', 'Post-alpha', 'Pre-beta', 'Post-beta'])\n"
     ]
    }
   ],
   "source": [
    "# Find optimal threhsold\n",
    "binarized_matrix = {}\n",
    "print(x[mapping[i]])\n",
    "for i in mapping:\n",
    "    conmat1, conmat2 = connectivity[f'{GROUP1}-{mapping[i]}'], connectivity[f'{GROUP2}-{mapping[i]}']\n",
    "    tthresh1 = np.median(conmat1[conmat1!=0]) + x[mapping[i]]*np.std(conmat1[conmat1!=0])\n",
    "    tthresh2 = np.median(conmat2[conmat2!=0]) + x[mapping[i]]*np.std(conmat2[conmat2!=0])\n",
    "    binarized_matrix[f'{GROUP1}-{mapping[i]}'] = connectivity[f'{GROUP1}-{mapping[i]}'] > tthresh1\n",
    "    binarized_matrix[f'{GROUP2}-{mapping[i]}'] = connectivity[f'{GROUP2}-{mapping[i]}'] > tthresh2\n",
    "    print(tthresh1, tthresh2)\n",
    "print(binarized_matrix.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find number of links in each graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-theta-number of links: K= 66\n",
      "Post-theta-number of links: K= 0\n",
      "Pre-alpha-number of links: K= 160\n",
      "Post-alpha-number of links: K= 154\n",
      "Pre-beta-number of links: K= 32\n",
      "Post-beta-number of links: K= 0\n"
     ]
    }
   ],
   "source": [
    "for i in mapping:\n",
    "    links_1 = 0\n",
    "    links_2 = 0\n",
    "\n",
    "    for row in range(n_channels):\n",
    "        for col in range(row+1):\n",
    "            if binarized_matrix[f'{GROUP1}-{mapping[i]}'][row][col] == 1:\n",
    "                links_1+=1\n",
    "            if binarized_matrix[f'{GROUP2}-{mapping[i]}'][row][col] == 1:\n",
    "                links_2+=1\n",
    "\n",
    "    print(f'{GROUP1}-{mapping[i]}-number of links: K=', links_1)\n",
    "    print(f'{GROUP2}-{mapping[i]}-number of links: K=', links_2)\n",
    "\n",
    "    # row_data[('links', f'{mapping[i]}-g1')] = links_1\n",
    "    # row_data[('links', f'{mapping[i]}-g2')] = links_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Asymmetry in  each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre:  theta left region:  53 right region:  30 proportion:  1.7666666666666666\n",
      "Post:  theta left region:  1 right region:  1 proportion:  1.0\n",
      "Pre:  alpha left region:  119 right region:  93 proportion:  1.2795698924731183\n",
      "Post:  alpha left region:  115 right region:  99 proportion:  1.1616161616161615\n",
      "Pre:  beta left region:  22 right region:  17 proportion:  1.2941176470588236\n",
      "Post:  beta left region:  1 right region:  1 proportion:  1.0\n"
     ]
    }
   ],
   "source": [
    "left_region = ['Fp1', 'AF3', 'PO3','O1', 'CP1', 'FC1', 'P3', 'C3', 'F3', 'F7', 'FC5', 'CP5', 'T7', 'P7']\n",
    "right_region = ['P8', 'T8', 'CP6', 'FC6', 'F8', 'F4', 'C4', 'P4', 'AF4', 'Fp2', 'FC2', 'CP2', 'O2', 'PO4']\n",
    "\n",
    "for i in mapping:\n",
    "    lr = 1\n",
    "    rr = 1\n",
    "    lrc = 1\n",
    "    rrc = 1\n",
    "    for row in range(n_channels):\n",
    "        for col in range(row+1):\n",
    "            if binarized_matrix[f'{GROUP1}-{mapping[i]}'][row][col] == 1:\n",
    "                if raw_1.info['ch_names'][row] in left_region or raw_1.info['ch_names'][col] in left_region:\n",
    "                    lr += 1\n",
    "                if raw_1.info['ch_names'][row] in right_region or raw_1.info['ch_names'][col] in right_region:\n",
    "                    rr += 1\n",
    "                # print(raw_1.info['ch_names'][row], raw_1.info['ch_names'][col])\n",
    "\n",
    "            if binarized_matrix[f'{GROUP2}-{mapping[i]}'][row][col] == 1:\n",
    "                if raw_1.info['ch_names'][row] in left_region or raw_1.info['ch_names'][col] in left_region:\n",
    "                    lrc += 1\n",
    "                if raw_1.info['ch_names'][row] in right_region or raw_1.info['ch_names'][col] in right_region:\n",
    "                    rrc += 1\n",
    "                # print(raw_1.info['ch_names'][row], raw_1.info['ch_names'][col])\n",
    "\n",
    "    print(f\"{GROUP1}: \",mapping[i], \"left region: \", lr, \"right region: \", rr, \"proportion: \", lr/rr)\n",
    "    print(f\"{GROUP2}: \", mapping[i], \"left region: \", lrc, \"right region: \", rrc, \"proportion: \", lrc/rrc)\n",
    "\n",
    "    # row_data[('asymmetry', f'{mapping[i]}-g1')] = lr/rr\n",
    "    # row_data[('asymmetry', f'{mapping[i]}-g2')] = lrc/rrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.04, 0.5, 'Y-axis label')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(1,3) \n",
    "for count, i in enumerate(mapping):\n",
    "    conmat1 = make_symmetric(connectivity[f'{GROUP1}-{mapping[i]}'], n_channels)\n",
    "    # conmat2 = make_symmetric(connectivity[f'{GROUP2}-{mapping[i]}'], n_channels)\n",
    "\n",
    "    im = axarr[count].imshow(conmat1)\n",
    "    axarr[count].set_title(f'Functional connectivity Pre {mapping[i]} in {ACTIVE_SHAM} treatment')\n",
    "    axarr[count].set_xticks([_ for _ in range(n_channels)])\n",
    "    axarr[count].set_xticklabels(raw_1.info['ch_names'], rotation='vertical')\n",
    "    axarr[count].set_yticks([_ for _ in range(n_channels)])\n",
    "    axarr[count].set_yticklabels(raw_1.info['ch_names'], rotation='horizontal')\n",
    "    axarr[count].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "f.text(0.5, 0.04, 'X-axis label', ha='center')\n",
    "f.text(0.04, 0.5, 'Y-axis label', va='center', rotation='vertical')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.04, 0.5, 'Y-axis label')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(1,3) \n",
    "for count, i in enumerate(mapping):\n",
    "    # conmat1 = make_symmetric(connectivity[f'{GROUP1}-{mapping[i]}'], n_channels)\n",
    "    conmat2 = make_symmetric(connectivity[f'{GROUP2}-{mapping[i]}'], n_channels)\n",
    "\n",
    "    im = axarr[count].imshow(conmat1)\n",
    "    axarr[count].set_title(f'Functional connectivity Post {mapping[i]} in {ACTIVE_SHAM} treatment')\n",
    "    axarr[count].set_xticks([_ for _ in range(n_channels)])\n",
    "    axarr[count].set_xticklabels(raw_1.info['ch_names'], rotation='vertical')\n",
    "    axarr[count].set_yticks([_ for _ in range(n_channels)])\n",
    "    axarr[count].set_yticklabels(raw_1.info['ch_names'], rotation='horizontal')\n",
    "    axarr[count].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "f.text(0.5, 0.04, 'X-axis label', ha='center')\n",
    "f.text(0.04, 0.5, 'Y-axis label', va='center', rotation='vertical')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Difference matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_index(channels_list, raw):\n",
    "    indexes = []\n",
    "    for channel in channels_list:\n",
    "        for i in range(len(raw.info['ch_names'])):\n",
    "            if raw.info['ch_names'][i]==channel:\n",
    "                indexes.append(i)\n",
    "    return(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_channels = return_index(['Pz', 'Oz', 'Fz', 'Cz'], raw_1)\n",
    "central_channels\n",
    "raw_1.info['bads'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_matrix = {}\n",
    "for i in mapping:\n",
    "    # TODO: both difference and excel it in in different column\n",
    "    difference_matrix[mapping[i]] = binarized_matrix[f'{GROUP2}-{mapping[i]}'].astype(int) - binarized_matrix[f'{GROUP1}-{mapping[i]}'].astype(int) \n",
    "    # difference_matrix[mapping[i]] = binarized_matrix[f'{GROUP1}-{mapping[i]}'].astype(int) - binarized_matrix[f'{GROUP2}-{mapping[i]}'].astype(int)\n",
    "    for k in range(n_channels):\n",
    "        for l in range(n_channels):\n",
    "            if difference_matrix[mapping[i]][k][l] == -1 or k in central_channels or l in central_channels:\n",
    "                difference_matrix[mapping[i]][k][l] = 0\n",
    "\n",
    "    difference_matrix[mapping[i]] = make_symmetric(difference_matrix[mapping[i]], n_channels)\n",
    "\n",
    "    # # Yellow - Higher synchronisation\n",
    "    # diff_mat = difference_matrix[mapping[i]]\n",
    "    # plt.imshow(diff_mat, interpolation='none')\n",
    "    # plt.title(f'Binary FC difference in {ACTIVE_SHAM} treatment in {mapping[i]}')\n",
    "    # plt.xticks([_ for _ in range(n_channels)], raw_1.info['ch_names'], rotation='vertical')\n",
    "    # plt.yticks([_ for _ in range(n_channels)], raw_1.info['ch_names'], rotation='horizontal')\n",
    "    # plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    # plt.show()\n",
    "\n",
    "    \n",
    "    # plot_sensors_connectivity(\n",
    "    #     raw_1.info,\n",
    "    #     difference_matrix[mapping[i]],\n",
    "    #     cbar_label=f'{mapping[i]}-Connectivity',\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_101574/3284738320.py:14: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  f.colorbar(cm.ScalarMappable(norm=colors.Normalize(0, 5), cmap=cm.get_cmap(\"Spectral\")), ax=ax)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.04, 0.5, 'Y-axis label')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import cm, colors\n",
    "f, axarr = plt.subplots(1,3) \n",
    "for count, i in enumerate(mapping):\n",
    "    conmat1 = make_symmetric((connectivity[f'{GROUP2}-{mapping[i]}'] - connectivity[f'{GROUP1}-{mapping[i]}']), n_channels)\n",
    "\n",
    "    im = axarr[count].imshow(conmat1)\n",
    "    axarr[count].set_title(f'FCdifferent maaatrix {mapping[i]} in {ACTIVE_SHAM} treatment')\n",
    "    axarr[count].set_xticks([_ for _ in range(n_channels)])\n",
    "    axarr[count].set_xticklabels(raw_1.info['ch_names'], rotation='vertical')\n",
    "    axarr[count].set_yticks([_ for _ in range(n_channels)])\n",
    "    axarr[count].set_yticklabels(raw_1.info['ch_names'], rotation='horizontal')\n",
    "    axarr[count].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "f.colorbar(cm.ScalarMappable(norm=colors.Normalize(0, 5), cmap=cm.get_cmap(\"Spectral\")), ax=ax)\n",
    "f.text(0.5, 0.04, 'X-axis label', ha='center')\n",
    "f.text(0.04, 0.5, 'Y-axis label', va='center', rotation='vertical')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hub(mat):\n",
    "        hub =[]\n",
    "        for ch, ch_name in enumerate(raw_1.info['ch_names']):\n",
    "            hub.append(np.count_nonzero(mat[ch] == 1))\n",
    "        return hub\n",
    "        # layout = find_layout(raw_1.info)\n",
    "        # plot_topomap(hub, layout.pos, names=raw_1.info['ch_names'], sphere='eeglab')\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'theta': 0.0, 'alpha': 7.485654216499529, 'beta': 0.0}\n"
     ]
    }
   ],
   "source": [
    "edges_threshold = {}\n",
    "for i in mapping:\n",
    "    hub = calculate_hub(difference_matrix[mapping[i]])\n",
    "    edges_threshold[mapping[i]] = np.median(hub) + np.std(hub)\n",
    "print(edges_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'theta': [], 'alpha': ['P8', 'T8', 'CP6', 'F8', 'P4', 'CP2', 'FC1', 'F7', 'CP5', 'P7'], 'beta': []}\n"
     ]
    }
   ],
   "source": [
    "selected_channels = {}\n",
    "for i in mapping:\n",
    "    selected_channels[mapping[i]] = []\n",
    "    for ch in range(n_channels):\n",
    "        if len(nx.from_numpy_array(difference_matrix[mapping[i]]).edges(ch)) > edges_threshold[mapping[i]]:\n",
    "            selected_channels[mapping[i]].append(raw_1.info['ch_names'][ch])\n",
    "print(selected_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary of Regions in brain vs channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionvschannel = {\n",
    "    'LC': ['C3', 'CP1', 'CP5', 'FC1', 'FC5'], # Left central \n",
    "    'LF': ['Fp1', 'AF3', 'F3', 'F7'], # Left frontal\n",
    "    'LT': ['T7'], # Left temporal\n",
    "    'LPO': ['PO3',  'P3', 'P7', 'O1'], # Left parietal-occipital\n",
    "    'RC': ['CP6', 'FC6', 'C4', 'FC2', 'CP2',], # Right central \n",
    "    'RF': ['F8', 'F4', 'AF4', 'Fp2'], # Right frontal\n",
    "    'RT': ['T8'], # Right temporal\n",
    "    'RPO': ['P8', 'P4', 'PO4', 'O2'] , # Right parietal-occipital\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_to_region = {}\n",
    "for region, region_channels in regionvschannel.items():\n",
    "    for channel in region_channels:\n",
    "        channel_to_region[channel] = region\n",
    "\n",
    "selected_regions = {}\n",
    "for band, channels in selected_channels.items():\n",
    "    regions = set()\n",
    "    for channel in channels:\n",
    "        if channel in channel_to_region:\n",
    "            regions.add(channel_to_region[channel])\n",
    "    selected_regions[band] = list(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in mapping:\n",
    "#     g1 = calculate_avergae_components(nx.from_numpy_array(connectivity_matrix[f'{GROUP1}-{mapping[i]}']))\n",
    "#     g2 = calculate_avergae_components(nx.from_numpy_array(connectivity_matrix[f'{GROUP2}-{mapping[i]}']))\n",
    "\n",
    "#     row_data[('swn', f'{mapping[i]}-g1')] = g1[3]/g1[0]\n",
    "#     row_data[('swn', f'{mapping[i]}-g2')] = g2[3]/g2[0]\n",
    "#     row_data[('cc', f'{mapping[i]}-g1')] = g1[3]\n",
    "#     row_data[('cc', f'{mapping[i]}-g2')] = g2[3]\n",
    "#     row_data[('lavg', f'{mapping[i]}-g1')] = g1[0]\n",
    "#     row_data[('lavg', f'{mapping[i]}-g2')] = g2[0]\n",
    "#     row_data[('nbc', f'{mapping[i]}-g1')] = g1[1]\n",
    "#     row_data[('nbc', f'{mapping[i]}-g2')] = g2[1]\n",
    "#     row_data[('eglo', f'{mapping[i]}-g1')] = g1[2]\n",
    "#     row_data[('eglo', f'{mapping[i]}-g2')] = g2[2]\n",
    "#     row_data[('eloc', f'{mapping[i]}-g1')] = g1[4]\n",
    "#     row_data[('eloc', f'{mapping[i]}-g2')] = g2[4]\n",
    "#     row_data[('hub', f'{mapping[i]}-g1')] = g1[5]\n",
    "#     row_data[('hub', f'{mapping[i]}-g2')] = g2[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'theta': ['LF', 'LPO'],\n",
       " 'alpha': ['RC', 'LF', 'LPO'],\n",
       " 'beta': ['RF', 'LF', 'LC']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in mapping:\n",
    "selected_regions['theta'] = ['LF', 'LPO']\n",
    "selected_regions['alpha'] = ['RC', 'LF', 'LPO']\n",
    "selected_regions['beta'] = ['RF', 'LF', 'LC']\n",
    "selected_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD EXTRAS IN EXCEL FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mapping:\n",
    "    nodes = list(itertools.chain(*[regionvschannel[region] for region in selected_regions[mapping[i]]]))\n",
    "    node_indexes = {raw_1.info['ch_names'].index(_) for _ in nodes}\n",
    "\n",
    "    if len(node_indexes):\n",
    "        g1 = calculate_avergae_components(nx.from_numpy_array(binarized_matrix[f'{GROUP1}-{mapping[i]}']).subgraph(node_indexes))\n",
    "        g2 = calculate_avergae_components(nx.from_numpy_array(binarized_matrix[f'{GROUP2}-{mapping[i]}']).subgraph(node_indexes))\n",
    "\n",
    "\n",
    "        row_data[('swn', f'{mapping[i]}-g1')] =  g1[3]/g1[0] if g1[0] and g2[0] else 0\n",
    "        row_data[('swn', f'{mapping[i]}-g2')] =  g2[3]/g2[0] if g1[0] and g2[0] else 0\n",
    "        row_data[('cc', f'{mapping[i]}-g1')] = g1[3]\n",
    "        row_data[('cc', f'{mapping[i]}-g2')] = g2[3]\n",
    "        row_data[('lavg', f'{mapping[i]}-g1')] = g1[0]\n",
    "        row_data[('lavg', f'{mapping[i]}-g2')] = g2[0]\n",
    "        row_data[('nbc', f'{mapping[i]}-g1')] = g1[1]\n",
    "        row_data[('nbc', f'{mapping[i]}-g2')] = g2[1]\n",
    "        row_data[('eglo', f'{mapping[i]}-g1')] = g1[2]\n",
    "        row_data[('eglo', f'{mapping[i]}-g2')] = g2[2]\n",
    "        row_data[('eloc', f'{mapping[i]}-g1')] = g1[4]\n",
    "        row_data[('eloc', f'{mapping[i]}-g2')] = g2[4]\n",
    "    else:\n",
    "        row_data[('swn', f'{mapping[i]}-g1')] =  0\n",
    "        row_data[('swn', f'{mapping[i]}-g2')] = 0\n",
    "        row_data[('cc', f'{mapping[i]}-g1')] = 0\n",
    "        row_data[('cc', f'{mapping[i]}-g2')] = 0\n",
    "        row_data[('lavg', f'{mapping[i]}-g1')] = 0\n",
    "        row_data[('lavg', f'{mapping[i]}-g2')] = 0\n",
    "        row_data[('nbc', f'{mapping[i]}-g1')] = 0\n",
    "        row_data[('nbc', f'{mapping[i]}-g2')] = 0\n",
    "        row_data[('eglo', f'{mapping[i]}-g1')] = 0\n",
    "        row_data[('eglo', f'{mapping[i]}-g2')] = 0\n",
    "        row_data[('eloc', f'{mapping[i]}-g1')] = 0\n",
    "        row_data[('eloc', f'{mapping[i]}-g2')] = 0\n",
    "\n",
    "    # row_data[('hubs', mapping[i])] = calculate_hub(difference_matrix[mapping[i]])\n",
    "    # row_data[('channels', mapping[i])] = selected_channels[mapping[i]]\n",
    "    # row_data[('regions', mapping[i])] = selected_regions[mapping[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('index', 'index'): 'Active-Hemlata-PrevsPost', ('swn', 'theta-g1'): 0, ('swn', 'theta-g2'): 0, ('cc', 'theta-g1'): 0.1851851851851852, ('cc', 'theta-g2'): 0.0, ('lavg', 'theta-g1'): 0.5333333333333333, ('lavg', 'theta-g2'): 0.0, ('nbc', 'theta-g1'): {10: 0.0, 11: 0.0, 16: 0.25, 17: 0.25, 24: 0.4, 26: 0.0, 27: 0.0, 31: 0.0}, ('nbc', 'theta-g2'): {10: 0.0, 11: 0.0, 16: 0.0, 17: 0.0, 24: 0.0, 26: 0.0, 27: 0.0, 31: 0.0}, ('eglo', 'theta-g1'): 0.24814814814814812, ('eglo', 'theta-g2'): 0.0, ('eloc', 'theta-g1'): 0.212962962962963, ('eloc', 'theta-g2'): 0.0, ('swn', 'alpha-g1'): 0.33052594171997157, ('swn', 'alpha-g2'): 0.16326530612244897, ('cc', 'alpha-g1'): 0.5678266178266178, ('cc', 'alpha-g2'): 0.050793650793650794, ('lavg', 'alpha-g1'): 1.7179487179487178, ('lavg', 'alpha-g2'): 0.3111111111111111, ('nbc', 'alpha-g1'): {2: 0.0, 3: 0.0404040404040404, 6: 0.0, 10: 0.0, 11: 0.0, 13: 0.0, 15: 0.0, 16: 0.3964646464646465, 17: 0.07070707070707072, 24: 0.31313131313131315, 26: 0.017676767676767676, 27: 0.0101010101010101, 31: 0.0}, ('nbc', 'alpha-g2'): {2: 0.026785714285714284, 3: 0.0, 6: 0.017857142857142856, 10: 0.0, 11: 0.05059523809523809, 13: 0.0, 15: 0.08035714285714285, 16: 0.0, 17: 0.0, 24: 0.026785714285714284, 26: 0.05059523809523809, 27: 0.05059523809523809, 31: 0.4107142857142857}, ('eglo', 'alpha-g1'): 0.658119658119658, ('eglo', 'alpha-g2'): 0.14629629629629629, ('eloc', 'alpha-g1'): 0.6419617419617419, ('eloc', 'alpha-g2'): 0.06957671957671958, ('swn', 'beta-g1'): 0, ('swn', 'beta-g2'): 0, ('cc', 'beta-g1'): 0.0, ('cc', 'beta-g2'): 0.0, ('lavg', 'beta-g1'): 0.08333333333333333, ('lavg', 'beta-g2'): 0.0, ('nbc', 'beta-g1'): {4: 0.0, 5: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 22: 0.0, 23: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0}, ('nbc', 'beta-g2'): {4: 0.0, 5: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 22: 0.0, 23: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0}, ('eglo', 'beta-g1'): 0.08333333333333333, ('eglo', 'beta-g2'): 0.0, ('eloc', 'beta-g1'): 0.0, ('eloc', 'beta-g2'): 0.0} 0\n",
      "length 0\n",
      "new row index  index                                Active-Hemlata-PrevsPost\n",
      "swn    theta-g1                                                    0\n",
      "       theta-g2                                                    0\n",
      "cc     theta-g1                                             0.185185\n",
      "       theta-g2                                                  0.0\n",
      "lavg   theta-g1                                             0.533333\n",
      "       theta-g2                                                  0.0\n",
      "nbc    theta-g1    {10: 0.0, 11: 0.0, 16: 0.25, 17: 0.25, 24: 0.4...\n",
      "       theta-g2    {10: 0.0, 11: 0.0, 16: 0.0, 17: 0.0, 24: 0.0, ...\n",
      "eglo   theta-g1                                             0.248148\n",
      "       theta-g2                                                  0.0\n",
      "eloc   theta-g1                                             0.212963\n",
      "       theta-g2                                                  0.0\n",
      "swn    alpha-g1                                             0.330526\n",
      "       alpha-g2                                             0.163265\n",
      "cc     alpha-g1                                             0.567827\n",
      "       alpha-g2                                             0.050794\n",
      "lavg   alpha-g1                                             1.717949\n",
      "       alpha-g2                                             0.311111\n",
      "nbc    alpha-g1    {2: 0.0, 3: 0.0404040404040404, 6: 0.0, 10: 0....\n",
      "       alpha-g2    {2: 0.026785714285714284, 3: 0.0, 6: 0.0178571...\n",
      "eglo   alpha-g1                                              0.65812\n",
      "       alpha-g2                                             0.146296\n",
      "eloc   alpha-g1                                             0.641962\n",
      "       alpha-g2                                             0.069577\n",
      "swn    beta-g1                                                     0\n",
      "       beta-g2                                                     0\n",
      "cc     beta-g1                                                   0.0\n",
      "       beta-g2                                                   0.0\n",
      "lavg   beta-g1                                              0.083333\n",
      "       beta-g2                                                   0.0\n",
      "nbc    beta-g1     {4: 0.0, 5: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: ...\n",
      "       beta-g2     {4: 0.0, 5: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: ...\n",
      "eglo   beta-g1                                              0.083333\n",
      "       beta-g2                                                   0.0\n",
      "eloc   beta-g1                                                   0.0\n",
      "       beta-g2                                                   0.0\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(row_data, len(df))\n",
    "# df = df.drop(df.index)\n",
    "new_row = pd.Series(row_data)\n",
    "print(\"length\", len(df))\n",
    "print(\"new row\", new_row)\n",
    "df.loc[len(df)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th colspan=\"6\" halign=\"left\">swn</th>\n",
       "      <th colspan=\"3\" halign=\"left\">cc</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">eglo</th>\n",
       "      <th colspan=\"6\" halign=\"left\">eloc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>theta-g1</th>\n",
       "      <th>theta-g2</th>\n",
       "      <th>alpha-g1</th>\n",
       "      <th>alpha-g2</th>\n",
       "      <th>beta-g1</th>\n",
       "      <th>beta-g2</th>\n",
       "      <th>theta-g1</th>\n",
       "      <th>theta-g2</th>\n",
       "      <th>alpha-g1</th>\n",
       "      <th>...</th>\n",
       "      <th>alpha-g1</th>\n",
       "      <th>alpha-g2</th>\n",
       "      <th>beta-g1</th>\n",
       "      <th>beta-g2</th>\n",
       "      <th>theta-g1</th>\n",
       "      <th>theta-g2</th>\n",
       "      <th>alpha-g1</th>\n",
       "      <th>alpha-g2</th>\n",
       "      <th>beta-g1</th>\n",
       "      <th>beta-g2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Active-Hemlata-PrevsPost</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.330526</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.567827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65812</td>\n",
       "      <td>0.146296</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641962</td>\n",
       "      <td>0.069577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index      swn                                       \\\n",
       "                      index theta-g1 theta-g2  alpha-g1  alpha-g2 beta-g1   \n",
       "0  Active-Hemlata-PrevsPost        0        0  0.330526  0.163265       0   \n",
       "\n",
       "                 cc                     ...     eglo                      \\\n",
       "  beta-g2  theta-g1 theta-g2  alpha-g1  ... alpha-g1  alpha-g2   beta-g1   \n",
       "0       0  0.185185      0.0  0.567827  ...  0.65812  0.146296  0.083333   \n",
       "\n",
       "               eloc                                               \n",
       "  beta-g2  theta-g1 theta-g2  alpha-g1  alpha-g2 beta-g1 beta-g2  \n",
       "0     0.0  0.212963      0.0  0.641962  0.069577     0.0     0.0  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Reset the column index\n",
    "df.to_excel(existing_file, index=True, header=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
