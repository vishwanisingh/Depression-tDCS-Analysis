{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.common import *\n",
    "# %run common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ['Hemlata', 'Malti', 'Preeti', 'Sharifa', 'Vinita', 'VKS'] ['Geeta', 'Jitendra', 'Jyoti', 'Kuldeep', 'Seema', 'VijayLaxmi']\n",
    "# ACTIVE_SHAM = 'Active'\n",
    "# SAMPLE = 'Hemlata'\n",
    "# ELECTRODES = '32electrodes' # '32electrodes' \n",
    "GROUP1 = 'Pre'\n",
    "GROUP2 = 'Post' # generally GROUP1+1\n",
    "mapping = {0: 'theta', 1: 'alpha', 2: 'beta'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', ELECTRODES, ACTIVE_SHAM)\n",
    "all_files = []\n",
    "\n",
    "folders = ['2Pre-TDCS', '4Post-TDCS']\n",
    "for folder in folders:\n",
    "    ext = 'Close.easy' if ELECTRODES == '32electrodes' else 'EEG.easy'\n",
    "    for _ in glob.glob(os.path.join(folder_path, folder, SAMPLE) + '/*' + ext):\n",
    "        all_files.append(_)\n",
    "\n",
    "raw_1 = data_transformation_easy(all_files[0])\n",
    "raw_1 = g1_preprocess(raw_1)\n",
    "raw_2 = data_transformation_easy(all_files[1])\n",
    "raw_2 = g1_preprocess(raw_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_file = f\"comparison-results/result-active-latest.xlsx\"\n",
    "df = pd.read_excel(existing_file, header=[0,1])\n",
    "\n",
    "main_column_names = ['index', 'swn', 'cc', 'lavg', 'eglo', 'eloc']\n",
    "subcols = ('theta-g1', 'theta-g2', 'alpha-g1', 'alpha-g2', 'beta-g1', 'beta-g2')\n",
    "\n",
    "# subcolumn_names = {\n",
    "#     'index' : ['index'],\n",
    "#     # 'links': subcols,\n",
    "#     # 'asymmetry': subcols,\n",
    "#     'swn': subcols,\n",
    "#     'cc' : subcols,\n",
    "#     'lavg': subcols,\n",
    "#     'eglo': subcols,\n",
    "#     'eloc': subcols,\n",
    "#     # 'hubs': ('theta', 'alpha', 'beta'),\n",
    "#     # 'channels': ('theta', 'alpha', 'beta'),\n",
    "#     # 'regions': ('theta', 'alpha', 'beta'),\n",
    "# }\n",
    "\n",
    "# columns_tuples = [(main_col, sub_col) for main_col in main_column_names for sub_col in subcolumn_names[main_col]]\n",
    "# columns = pd.MultiIndex.from_tuples(columns_tuples)\n",
    "# df = pd.DataFrame(columns=columns)\n",
    "\n",
    "row_data = {('index', 'index'): f'{ACTIVE_SHAM}-{SAMPLE}-{GROUP1}vs{GROUP2}'}\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. PSD graph plot between MDD and Control group\n",
    "\n",
    "For resting state EEG channel, analyzing the overall average power across channels provides a holistic view of the brain's activity without emphasizing the specificity of individual channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 PSD using plot_psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "#plot_psd uses welch method for continuous data\n",
    "raw_1.plot_psd(picks=raw_1.info['ch_names'], average=True, fmin=FMIN, fmax=FMAX, ax=ax, show=False, color='blue', dB=False)\n",
    "raw_2.plot_psd(picks=raw_2.info['ch_names'], average=True, fmin=FMIN, fmax=FMAX, ax=ax, show=False, color='red', dB=False)\n",
    "\n",
    "# dB = True plots PSD in decibels (logarithmic)\n",
    "# different n_fft compared to psd_array_welch\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Power/Frequency (microV^2/Hz)')\n",
    "ax.set_title('Power Spectral Density Comparison')\n",
    "\n",
    "ax.text(0.8, 0.9, GROUP1, color='blue', transform=ax.transAxes)\n",
    "ax.text(0.8, 0.85, GROUP2, color='red', transform=ax.transAxes)\n",
    "\n",
    "plt.ylim(0, 8)\n",
    "# plt.show()\n",
    "\n",
    "fig.savefig(f'comparison-results/PSD - {SAMPLE} - {GROUP1} vs {GROUP2}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Epoching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 4.0\n",
    "overlap = 2.0 \n",
    "\n",
    "samples_per_epoch = int(duration * SFREQ)\n",
    "samples_per_overlap = int(overlap * SFREQ)\n",
    "\n",
    "# Manually created events\n",
    "start, stop = 0, samples_per_epoch\n",
    "events = []\n",
    "while stop <= len(raw_1):\n",
    "    events.append([start, 0, 1]) \n",
    "    start += samples_per_overlap\n",
    "    stop += samples_per_overlap\n",
    "\n",
    "events = np.array(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Segmenting epochs for Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_1 = mne.Epochs(raw_1, events, tmin=0, tmax=duration, baseline=None, detrend=1,\n",
    "                    picks=None, preload=True, reject=None)\n",
    "# raw_1.plot(n_channels=len(raw_1.info['ch_names']), events=events, event_color={1:'r'}, scalings=SCALINGS)\n",
    "# epochs_1.plot(n_channels=len(raw_1.info['ch_names']), event_color={1:'r'}, events=events, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_2 = mne.Epochs(raw_2, events, tmin=0, tmax=duration, baseline=None, detrend=1,\n",
    "                    picks=None, preload=True, reject=None)\n",
    "# raw_2.plot(n_channels=len(raw_1.info['ch_names']), events=events, event_color={1:'r'}, scalings=SCALINGS)\n",
    "# epochs_2.plot(n_channels=len(raw_1.info['ch_names']), event_color={1:'r'}, events=events, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. PLI and construction of brain function matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pli method always gives positive correlations\n",
    "connectivity = {}\n",
    "def connectivity_matrix(epochs, i):\n",
    "    return spectral_connectivity_epochs(\n",
    "    epochs, method='pli', mode='multitaper', sfreq=SFREQ,\n",
    "    fmin=FREQ_BANDS[mapping[i]][0], fmax=FREQ_BANDS[mapping[i]][1], faverage=True, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = len(raw_1.info['ch_names'])\n",
    "for i in mapping:\n",
    "    con = connectivity_matrix(epochs_1, i)\n",
    "    connectivity[f'{GROUP1}-{mapping[i]}'] = con.get_data().reshape((n_channels, n_channels))\n",
    "\n",
    "    con = connectivity_matrix(epochs_2, i)\n",
    "    connectivity[f'{GROUP2}-{mapping[i]}'] = con.get_data().reshape((n_channels, n_channels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Thresholding - M1 -  Small World Index\n",
    "\n",
    "Preserves small-world properties in both groups to ensure that any observed differences in connectivity are not biased by the thresholding method.\n",
    "Preserving these properties ensures that information can be transmitted quickly and effectively across the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_symmetric(arr, n_channels):\n",
    "    for row in range(n_channels):\n",
    "        for col in range(n_channels):\n",
    "            arr[row][col] = arr[col][row]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_swn(mat, threshold):\n",
    "    tthresh = np.median(mat[mat!=0]) + threshold*np.std(mat[mat!=0])\n",
    "    binmat= mat > tthresh\n",
    "    n_connections = np.count_nonzero(binmat == 1)\n",
    "    binmat = make_symmetric(binmat.astype(int), n_channels)\n",
    "    g= calculate_avergae_components(nx.from_numpy_array(binmat))\n",
    "    Lw_binarized, CC_binarized = g[0], g[3]\n",
    "    return (CC_binarized/Lw_binarized if n_connections else 0), n_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_perms = 1000\n",
    "n_network = n_perms//10\n",
    "swn_z_1, swn_z_2 = {}, {}\n",
    "optimal_swn_perms, optimal_swn_real1, optimal_swn_real2 = {}, {}, {}\n",
    "\n",
    "for i in mapping:\n",
    "    conmat1, conmat2 = connectivity[f'{GROUP1}-{mapping[i]}'], connectivity[f'{GROUP2}-{mapping[i]}']\n",
    "    if ACTIVE_SHAM == 'Active':\n",
    "        x = {'theta': 0.9422110552763826, 'alpha': 0.4824120603015075, 'beta': 1.2738693467336675}\n",
    "    else:\n",
    "        x = {'theta': 0.2788944723618091, 'alpha': 0.391959798994975, 'beta': 0.2638190954773868}\n",
    "    threshold = x[mapping[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Binarization of functional connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal threhsold\n",
    "binarized_matrix = {}\n",
    "print(x[mapping[i]])\n",
    "for i in mapping:\n",
    "    conmat1, conmat2 = connectivity[f'{GROUP1}-{mapping[i]}'], connectivity[f'{GROUP2}-{mapping[i]}']\n",
    "    tthresh1 = np.median(conmat1[conmat1!=0]) + x[mapping[i]]*np.std(conmat1[conmat1!=0])\n",
    "    tthresh2 = np.median(conmat2[conmat2!=0]) + x[mapping[i]]*np.std(conmat2[conmat2!=0])\n",
    "    binarized_matrix[f'{GROUP1}-{mapping[i]}'] = connectivity[f'{GROUP1}-{mapping[i]}'] > tthresh1\n",
    "    binarized_matrix[f'{GROUP2}-{mapping[i]}'] = connectivity[f'{GROUP2}-{mapping[i]}'] > tthresh2\n",
    "    print(tthresh1, tthresh2)\n",
    "print(binarized_matrix.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_regions = {}\n",
    "selected_regions['theta'] = ['LF', 'RC', 'LPO']\n",
    "selected_regions['alpha'] = ['LF', 'RC', 'LPO']\n",
    "selected_regions['beta'] = ['RF', 'LF', 'LC']\n",
    "selected_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD EXTRAS IN EXCEL FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionvschannel = {\n",
    "    'LC': ['C3', 'CP1', 'CP5', 'FC1', 'FC5'], # Left central \n",
    "    'LF': ['Fp1', 'AF3', 'F3', 'F7'], # Left frontal\n",
    "    'LT': ['T7'], # Left temporal\n",
    "    'LPO': ['PO3',  'P3', 'P7', 'O1'], # Left parietal-occipital\n",
    "    'RC': ['CP6', 'FC6', 'C4', 'FC2', 'CP2',], # Right central \n",
    "    'RF': ['F8', 'F4', 'AF4', 'Fp2'], # Right frontal\n",
    "    'RT': ['T8'], # Right temporal\n",
    "    'RPO': ['P8', 'P4', 'PO4', 'O2'] , # Right parietal-occipital\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mapping:\n",
    "    nodes = list(itertools.chain(*[regionvschannel[region] for region in selected_regions[mapping[i]]]))\n",
    "    node_indexes = {raw_1.info['ch_names'].index(_) for _ in nodes}\n",
    "\n",
    "    if len(node_indexes):\n",
    "        g1 = calculate_avergae_components(nx.from_numpy_array(binarized_matrix[f'{GROUP1}-{mapping[i]}']).subgraph(node_indexes))\n",
    "        g2 = calculate_avergae_components(nx.from_numpy_array(binarized_matrix[f'{GROUP2}-{mapping[i]}']).subgraph(node_indexes))\n",
    "\n",
    "\n",
    "        row_data[('swn', f'{mapping[i]}-g1')] =  g1[3]/g1[0] if g1[0] and g2[0] else 0\n",
    "        row_data[('swn', f'{mapping[i]}-g2')] =  g2[3]/g2[0] if g1[0] and g2[0] else 0\n",
    "        row_data[('cc', f'{mapping[i]}-g1')] = g1[3]\n",
    "        row_data[('cc', f'{mapping[i]}-g2')] = g2[3]\n",
    "        row_data[('lavg', f'{mapping[i]}-g1')] = g1[0]\n",
    "        row_data[('lavg', f'{mapping[i]}-g2')] = g2[0]\n",
    "        row_data[('nbc', f'{mapping[i]}-g1')] = g1[1]\n",
    "        row_data[('nbc', f'{mapping[i]}-g2')] = g2[1]\n",
    "        row_data[('eglo', f'{mapping[i]}-g1')] = g1[2]\n",
    "        row_data[('eglo', f'{mapping[i]}-g2')] = g2[2]\n",
    "        row_data[('eloc', f'{mapping[i]}-g1')] = g1[4]\n",
    "        row_data[('eloc', f'{mapping[i]}-g2')] = g2[4]\n",
    "    else:\n",
    "        row_data[('swn', f'{mapping[i]}-g1')] =  0\n",
    "        row_data[('swn', f'{mapping[i]}-g2')] = 0\n",
    "        row_data[('cc', f'{mapping[i]}-g1')] = 0\n",
    "        row_data[('cc', f'{mapping[i]}-g2')] = 0\n",
    "        row_data[('lavg', f'{mapping[i]}-g1')] = 0\n",
    "        row_data[('lavg', f'{mapping[i]}-g2')] = 0\n",
    "        row_data[('nbc', f'{mapping[i]}-g1')] = 0\n",
    "        row_data[('nbc', f'{mapping[i]}-g2')] = 0\n",
    "        row_data[('eglo', f'{mapping[i]}-g1')] = 0\n",
    "        row_data[('eglo', f'{mapping[i]}-g2')] = 0\n",
    "        row_data[('eloc', f'{mapping[i]}-g1')] = 0\n",
    "        row_data[('eloc', f'{mapping[i]}-g2')] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = pd.Series(row_data)\n",
    "df.loc[len(df)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(existing_file, index=True, header=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
