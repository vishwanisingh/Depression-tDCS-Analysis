{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run E:\\IITD\\Depression-IITD\\common.ipynb\n",
    "# %run E:\\IITD\\Depression-IITD\\preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALINGS = 4e-4\n",
    "SFREQ = 500\n",
    "WINDOW_SIZE = 1\n",
    "SHOW = False\n",
    "FMIN = 0.01\n",
    "FMAX = 45\n",
    "FREQ_BANDS = {\n",
    "    'delta': (0.01, 4),\n",
    "    'theta': (4, 8),\n",
    "    'alpha1': (8, 10),\n",
    "    'alpha2': (10, 13),\n",
    "    'beta': (13, 30),\n",
    "    'gamma': (30, 45)\n",
    "}\n",
    "ALL_CHANNELS=[]\n",
    "GROUP1 = 'PRE-ACTIVE'\n",
    "GROUP2 = 'POST-ACTIVE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack\n",
    "from scipy.fft import fft\n",
    "import time\n",
    "import mne\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import kurtosis, zscore, ttest_ind\n",
    "from mne.preprocessing import create_ecg_epochs, create_eog_epochs, read_ica\n",
    "from mne.time_frequency import tfr_morlet, tfr_array_morlet, morlet, AverageTFR\n",
    "from itertools import product\n",
    "import pywt\n",
    "from scipy.signal import hilbert\n",
    "from mne_connectivity import spectral_connectivity_epochs\n",
    "from mne_connectivity.viz import plot_sensors_connectivity\n",
    "import networkx as nx\n",
    "import numpy as np \n",
    "import re\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from colabcode import ColabCode\n",
    "from nilearn import plotting\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from nilearn.maskers import MultiNiftiLabelsMasker\n",
    "from nilearn import datasets\n",
    "\n",
    "\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColabCode(port=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = os.getcwd()+'\\\\Depression-Sample-dataset-AIIMS\\\\'\n",
    "# items = os.listdir(folder_path)\n",
    "# active_or_sham_list = [item for item in items if os.path.isdir(os.path.join(folder_path, item))]\n",
    "# for active_or_sham in active_or_sham_list:\n",
    "#     patient_folder_path = os.path.join(folder_path, active_or_sham)\n",
    "#     items = os.listdir(patient_folder_path)\n",
    "#     patients_list = [item for item in items if os.path.isdir(os.path.join(patient_folder_path, item))]\n",
    "#     patients_list = ['PreetiSingh', 'Hemlata', 'VinodKumarSharma']\n",
    "#     for patient in patients_list:\n",
    "#         pre_post_int_folder_path = os.path.join(patient_folder_path, patient)\n",
    "#         items = os.listdir(pre_post_int_folder_path)\n",
    "#         pre_post_int_list = [item for item in items if os.path.isdir(os.path.join(pre_post_int_folder_path, item))]\n",
    "#         for var in pre_post_int_list:\n",
    "#             if var=='Pre':\n",
    "#                 pre_path = os.path.join(pre_post_int_folder_path, var)\n",
    "#                 file_path = pre_path + '\\\\' + '20230718201550_Preeti singh_22.08.23-01_Eye Close' + '.easy'\n",
    "#                 break # Remove for all pre, post and intervention for a patient\n",
    "#         break # Remove for all patients in active or sham\n",
    "#     break # Remove for both active and sham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = os.getcwd()+'\\\\Depression-Sample-dataset-AIIMS\\\\Active\\\\VinodKumarSharma\\\\pre\\\\20230829195416_VinodKumarSharma_25.9.23_01_Eye Close.easy'\n",
    "def data_transformation_easy(file_path):\n",
    "\tdf = pd.read_csv(file_path, sep='\\t')\n",
    "\tchannel_str='Channel 1:P8\\\n",
    "\t\tChannel 2:T8\\\n",
    "\t\tChannel 3:CP6\\\n",
    "\t\tChannel 4:FC6\\\n",
    "\t\tChannel 5:F8\\\n",
    "\t\tChannel 6:F4\\\n",
    "\t\tChannel 7:C4\\\n",
    "\t\tChannel 8:P4\\\n",
    "\t\tChannel 9:AF4\\\n",
    "\t\tChannel 10:Fp2\\\n",
    "\t\tChannel 11:Fp1\\\n",
    "\t\tChannel 12:AF3\\\n",
    "\t\tChannel 13:Fz\\\n",
    "\t\tChannel 14:FC2\\\n",
    "\t\tChannel 15:Cz\\\n",
    "\t\tChannel 16:CP2\\\n",
    "\t\tChannel 17:PO3\\\n",
    "\t\tChannel 18:O1\\\n",
    "\t\tChannel 19:Oz\\\n",
    "\t\tChannel 20:O2\\\n",
    "\t\tChannel 21:PO4\\\n",
    "\t\tChannel 22:Pz\\\n",
    "\t\tChannel 23:CP1\\\n",
    "\t\tChannel 24:FC1\\\n",
    "\t\tChannel 25:P3\\\n",
    "\t\tChannel 26:C3\\\n",
    "\t\tChannel 27:F3\\\n",
    "\t\tChannel 28:F7\\\n",
    "\t\tChannel 29:FC5\\\n",
    "\t\tChannel 30:CP5\\\n",
    "\t\tChannel 31:T7\\\n",
    "\t\tChannel 32:P7'\n",
    "\n",
    "\tchannel_names = re.findall(r'Channel \\d+:(\\w+)', channel_str)\n",
    "\tchannel_names.append('ax')\n",
    "\tchannel_names.append('ay')\n",
    "\tchannel_names.append('az')\n",
    "\tchannel_names.append('trigger')\n",
    "\tchannel_names.append('timestamp(ms)')\n",
    "\tglobal ALL_CHANNELS\n",
    "\tALL_CHANNELS = np.array(channel_names[:-5])\n",
    "\tdf.columns=channel_names\n",
    "\ttransposed_data=df.T\n",
    "\tch_names = df.columns.tolist()[:-5]\n",
    "\tch_types = ['eeg' for i in range(32)]\n",
    "\tinfo = mne.create_info(ch_names=ch_names,ch_types=ch_types, sfreq=500)\n",
    "\traw = mne.io.RawArray(transposed_data.values[:-5,:]/1e9, info) # Example: 33129984 nV = 0.033129984 V = 33129.984000000004 uV\n",
    "\treturn raw\n",
    "# data_transformation_easy(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_montage(raw):\n",
    "    mont1020 = mne.channels.make_standard_montage('standard_1020')\n",
    "    ind = [i for (i, channel) in enumerate(mont1020.ch_names) if channel in ALL_CHANNELS]\n",
    "    mont1020_new = mont1020.copy()\n",
    "    mont1020_new.ch_names = [mont1020.ch_names[x] for x in ind]\n",
    "    kept_channel_info = [mont1020.dig[x+3] for x in ind]\n",
    "    mont1020_new.dig = mont1020.dig[0:3]+kept_channel_info\n",
    "    raw.set_montage(mont1020_new)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate absolute power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_absolute_power(raw_data):\n",
    "    psds, freqs = mne.time_frequency.psd_array_welch(raw_data.get_data(), fmin=FMIN, fmax=FMAX, sfreq=SFREQ)\n",
    "    absolute_powers = {}\n",
    "    for band, (FMIN, FMAX) in FREQ_BANDS.items():\n",
    "        idx_band = np.logical_and(freqs >= FMIN, freqs <= FMAX)\n",
    "        absolute_power = np.trapz(psds[:, idx_band], dx=(freqs[1] - freqs[0]), axis=-1)\n",
    "        absolute_powers[band] = absolute_power\n",
    "    total_absolute_power = sum(absolute_powers.values())\n",
    "    return total_absolute_power\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time amplitude plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_amplitude(raw):\n",
    "    fig = raw.plot(\n",
    "        n_channels=32, \n",
    "        scalings=SCALINGS,\n",
    "        show=SHOW\n",
    "        )\n",
    "    # fig.savefig(f'MNE-graphs/time-amplitude/{title}-EEG.png')\n",
    "\n",
    "    print(raw.info)\n",
    "    # TODO: Extract statistical features from time domain such as mean, median, variance, skewness, kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power spectral density plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psd(raw):\n",
    "    fig = raw.plot_psd(\n",
    "        picks=raw.info['ch_names'], \n",
    "        show=SHOW)\n",
    "    # fig.savefig(f'MNE-graphs/psd-frequency/{title}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wavelet plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wavelet(raw1, raw2=None, title):\n",
    "#     raw1_avg = np.mean(raw1.get_data(), axis=0)\n",
    "#     t = np.arange(0, 150, 1/SFREQ)\n",
    "#     ts = t[:-1]\n",
    "#     wavelet = 'db13'\n",
    "#     level = 5 # level of decomposition based on your signal characteristics\n",
    "\n",
    "#     # coeffs_multi_channel = []\n",
    "#     # for i in range(32): \n",
    "#     coeffs1 = pywt.wavedec(raw1_avg, wavelet, level=level)\n",
    "#         # coeffs_multi_channel.append(coeffs)\n",
    "    \n",
    "#     plt.figure(figsize=(10, 6))\n",
    "\n",
    "#     # raw1\n",
    "#     plt.subplot(4, 1, 1)\n",
    "#     plt.plot(ts, raw1_avg, label='xyz')\n",
    "#     plt.title('Channel 1')\n",
    "#     plt.xlabel('Time')\n",
    "#     plt.ylabel('Amplitude')\n",
    "#     plt.legend()\n",
    "\n",
    "#     # raw1 coeffs\n",
    "#     plt.subplot(4, 1, 2)\n",
    "#     for i in range(level+1):\n",
    "#         plt.plot(t, pywt.upcoef('a', coeffs1[i], wavelet, level=level)[:len(t)], label=f'Level {i}')\n",
    "#     plt.title('DWT')\n",
    "#     plt.xlabel('Time')\n",
    "#     plt.ylabel('Amplitude')\n",
    "#     plt.legend()\n",
    "\n",
    "#     if raw2:\n",
    "#         raw2_avg = np.mean(raw2.get_data(), axis=0)\n",
    "#         coeffs2 = pywt.wavedec(raw2_avg, wavelet, level=level)\n",
    "\n",
    "#         # raw2\n",
    "#         plt.subplot(4, 1, 3)\n",
    "#         plt.plot(t, raw2_avg, label='ddd')\n",
    "#         plt.title('Channel 1')\n",
    "#         plt.xlabel('Time')\n",
    "#         plt.ylabel('Amplitude')\n",
    "#         plt.legend()\n",
    "\n",
    "#         # raw2 coeffs\n",
    "#         plt.subplot(4, 1, 4)\n",
    "#         for i in range(level+1):\n",
    "#             plt.plot(t, pywt.upcoef('a', coeffs2[i], wavelet, level=level)[:len(t)], label=f'Level {i}')\n",
    "#         plt.title('DWT')\n",
    "#         plt.xlabel('Time')\n",
    "#         plt.ylabel('Amplitude')\n",
    "#         plt.legend()\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Band pass filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_pass_filter(raw, l_freq=FMIN, h_freq=FMAX):\n",
    "    raw.filter(method= 'fir',\n",
    "        phase= 'minimum',\n",
    "        fir_window= 'hann',\n",
    "        l_freq= l_freq,\n",
    "        h_freq= h_freq)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rereferencing\n",
    "\n",
    "Calculates the mean voltage from all electrodes at each time point and subtracts this mean from the voltage at each individual electrode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rereferencing(raw):\n",
    "    raw.set_eeg_reference('average', projection=True).apply_proj() \n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artifact Rejection (EOG/ECG) using Wavelet decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wavelet_decompose(raw):\n",
    "#     info = raw.info\n",
    "#     coeffs = pywt.wavedec(raw.get_data(), 'db13', level=4)\n",
    "#     threshold = 0.00001 # applying a shrinkage function that smoothly brings coefficients below the threshold to zero\n",
    "#     coeffs_thresholded = [pywt.threshold(c, threshold, mode='soft') for c in coeffs] \n",
    "#     denoised_signal = pywt.waverec(coeffs_thresholded, 'db13')\n",
    "#     raw = mne.io.RawArray(denoised_signal, info)\n",
    "#     return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(raw, l, h):\n",
    "    return raw.crop(l,h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampling(raw, SFREQ=SFREQ):\n",
    "    return raw.resample(sfreq=SFREQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop channels\n",
    "\n",
    "Dropping extra channels in both groups\n",
    "TODO: Instead of dropping we can convert 10-10 64 channels montage to 10-20 32 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_channels(raw, raw_1):\n",
    "    drop = []\n",
    "    for chan in raw.info['ch_names']:\n",
    "        if chan not in raw_1.info['ch_names']:\n",
    "            drop.append(chan)\n",
    "    raw.drop_channels(drop)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 1 preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g1_preprocess(raw):\n",
    "    raw = set_montage(raw)\n",
    "    raw  = band_pass_filter(raw, l_freq = FMIN, h_freq = FMAX)\n",
    "    raw = rereferencing(raw)\n",
    "    # raw = wavelet_decompose(raw)\n",
    "    raw.info['bads'] = []\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 2 preprcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g2_preprocessing(raw, raw_1, crop=True):\n",
    "    # For epochs crop=False\n",
    "    raw = drop_channels(raw, raw_1)\n",
    "    if crop:\n",
    "        raw = set_montage(raw)\n",
    "        raw = raw.crop(50, 200)\n",
    "    raw = resampling(raw)\n",
    "    raw = band_pass_filter(raw, l_freq = 0.01, h_freq = 45)\n",
    "    # raw = wavelet_decompose(raw)\n",
    "    raw.info['bads'] = []\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate average components of a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avergae_components(G):\n",
    "    connected_components = list(nx.connected_components(G))\n",
    "    component_avg_lengths = []\n",
    "    component_nbc_values = []\n",
    "    component_eglo_values = []\n",
    "    component_cc_values = []\n",
    "    component_eloc_values = []\n",
    "\n",
    "    for component in connected_components:\n",
    "        subgraph = G.subgraph(component)\n",
    "        component_avg_lengths.append(nx.average_shortest_path_length(subgraph))\n",
    "        component_nbc_values.append(nx.betweenness_centrality(subgraph))\n",
    "        component_eglo_values.append(nx.global_efficiency(subgraph))\n",
    "        component_cc_values.append(nx.average_clustering(subgraph))\n",
    "        component_eloc_values.append(nx.local_efficiency(subgraph))\n",
    "\n",
    "    merged_nbc_values = {}\n",
    "    for dnbc in component_nbc_values:\n",
    "        merged_nbc_values.update(dnbc)\n",
    "    merged_nbc_values = dict(sorted(merged_nbc_values.items(), key=lambda item: item[0]))\n",
    " \n",
    "    overall_avg_length = sum(component_avg_lengths) / len(component_avg_lengths)\n",
    "    overall_eglo_values = sum(component_eglo_values) / len(component_eglo_values)\n",
    "    overall_cc_values = sum(component_cc_values) / len(component_cc_values)\n",
    "    overall_eloc_values = sum(component_eloc_values) / len(component_eloc_values)\n",
    "\n",
    "    return [overall_avg_length, merged_nbc_values, overall_eglo_values, overall_cc_values, overall_eloc_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PRE VS CONTROL\n",
    "# if GROUP1 == 'PRE-ALL' and GROUP2 == 'CONTROL':\n",
    "    # raw_1 = mne.io.read_raw_fif(\"loadData/rawMDDpre5.fif\")\n",
    "    # raw_2 = mne.io.read_raw_fif(\"loadData/rawControlOnline104.fif\")\n",
    "\n",
    "    # epochs_1 = mne.read_epochs(\"loadData/epochsMDDpre5.fif\", preload=False)\n",
    "    # epochs_2 = mne.read_epochs(\"loadData/epochsControlOnline104.fif\", preload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file loadData/rawMDDpre3Active.fif...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 32) active\n",
      "    Range : 0 ... 74998 =      0.000 ...   149.996 secs\n",
      "Ready.\n",
      "Opening raw data file loadData/rawMDDpost3Active.fif...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 32) active\n",
      "    Range : 0 ... 74998 =      0.000 ...   149.996 secs\n",
      "Ready.\n",
      "Reading /home/vishwani/Downloads/IITD/Depression-IITD/loadData/epochsMDDpre3Active.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 32) active\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    4000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "73 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Reading /home/vishwani/Downloads/IITD/Depression-IITD/loadData/epochsMDDpost3Active.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 32) active\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    4000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "73 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10587/1281472082.py:3: RuntimeWarning: This filename (loadData/rawMDDpre3Active.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw_1 = mne.io.read_raw_fif(\"loadData/rawMDDpre3Active.fif\")\n",
      "/tmp/ipykernel_10587/1281472082.py:4: RuntimeWarning: This filename (loadData/rawMDDpost3Active.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw_2 = mne.io.read_raw_fif(\"loadData/rawMDDpost3Active.fif\")\n",
      "/tmp/ipykernel_10587/1281472082.py:6: RuntimeWarning: This filename (loadData/epochsMDDpre3Active.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs_1 = mne.read_epochs(\"loadData/epochsMDDpre3Active.fif\", preload=False)\n",
      "/tmp/ipykernel_10587/1281472082.py:7: RuntimeWarning: This filename (loadData/epochsMDDpost3Active.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs_2 = mne.read_epochs(\"loadData/epochsMDDpost3Active.fif\", preload=False)\n"
     ]
    }
   ],
   "source": [
    "# PRE VS POST - ACTIVE\n",
    "if GROUP1 == 'PRE-ACTIVE' and GROUP2 == 'POST-ACTIVE':\n",
    "    raw_1 = mne.io.read_raw_fif(\"loadData/rawMDDpre3Active.fif\")\n",
    "    raw_2 = mne.io.read_raw_fif(\"loadData/rawMDDpost3Active.fif\")\n",
    "\n",
    "    epochs_1 = mne.read_epochs(\"loadData/epochsMDDpre3Active.fif\")\n",
    "    epochs_2 = mne.read_epochs(\"loadData/epochsMDDpost3Active.fif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # POST -Active vs Control\n",
    "# if GROUP1 == 'POST-ACTIVE' and GROUP2 == 'CONTROL':\n",
    "    # raw_1 = mne.io.read_raw_fif(\"loadData/rawMDDpost3Active.fif\")\n",
    "    # raw_2 = mne.io.read_raw_fif(\"loadData/rawControlOnline104.fif\")\n",
    "\n",
    "    # epochs_1 = mne.read_epochs(\"loadData/epochsMDDpre3Active.fif\", preload=False)\n",
    "    # epochs_2 = mne.read_epochs(\"loadData/epochsControlOnline104.fif\", preload=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELSE COMPUTE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MDD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_close_1 = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Active', 'PreetiSingh', 'Pre', '20230718201550_Preeti singh_22.08.23-01_Eye Close.easy' )\n",
    "eye_close_2 = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Active', 'Hemlata', 'Pre', '20230831105330_Hemlata_05.10.23_01_Eye Close.easy') \n",
    "eye_close_3 = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Active', 'VinodKumarSharma', 'Pre', '20230829195416_VinodKumarSharma_25.9.23_01_Eye Close.easy' ) \n",
    "# eye_close_4 = '\\\\Depression-Sample-dataset-AIIMS\\\\Sham\\\\JitenderKumar\\\\pre\\\\' + '20230825020227_JitenderKumar_29.08.23_01_Eye Close'\n",
    "# eye_close_5 = '\\\\Depression-Sample-dataset-AIIMS\\\\Sham\\\\SeemaKumari\\\\pre\\\\' + '20230827073914_SeemaKumari_11.09.23_01_Eye Close'\n",
    "# eye_close_6 = '\\\\Depression-Sample-dataset-AIIMS\\\\Active\\\\PreetiSingh\\\\post\\\\' + '20230826225729_PreetiSingh_08.09.23_20_Eye Close'\n",
    "# eye_close_7 = '\\\\Depression-Sample-dataset-AIIMS\\\\Active\\\\Hemlata\\\\post\\\\' + '20231019110530_Hemlata_19.10.23_19A_Eye Close'\n",
    "# eye_close_8 = '\\\\Depression-Sample-dataset-AIIMS\\\\Active\\\\VinodKumarSharma\\\\post\\\\' + '20230901112451_VinodKumarSharma_11.10.23_20_Eye Close'\n",
    "# eye_close_9 = '\\\\Depression-Sample-dataset-AIIMS\\\\Sham\\\\JitenderKumar\\\\post\\\\' + '20230827174115_JitenderKumar_13.09.23_20_Eye Close'\n",
    "# eye_close_10 = '\\\\Depression-Sample-dataset-AIIMS\\\\Sham\\\\SeemaKumari\\\\post\\\\' + '20230829172634_SeemaKumari_23.9.23_20_Eye Close'\n",
    "eye_close_MDD = [eye_close_1, eye_close_2, eye_close_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_1 = []\n",
    "for file_path in eye_close_MDD:\n",
    "    raw = data_transformation_easy(file_path)\n",
    "    # raw = mne.io.read_raw_edf(file, eog=None, misc=None, stim_channel='auto', exclude=(), infer_types=False, include=None, preload=True, units=None, encoding='utf8', verbose=None)\n",
    "    # By default read_raw_edf convert units to V\n",
    "    raw = g1_preprocess(raw)\n",
    "    raw_1.append(raw.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M1 : Averaging using mean:\n",
    "\n",
    "raw_1_avg = np.mean(raw_1, axis=0)\n",
    "print(raw_1_avg)\n",
    "\n",
    "del raw_1[:]\n",
    "del raw_1\n",
    "del eye_close_MDD[:]\n",
    "del eye_close_MDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = raw.info\n",
    "raw_1 = mne.io.RawArray(raw_1_avg, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control group data (Online control group data eye closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE VS POST COMPARISON\n",
    "eye_close_6 = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Active', 'PreetiSingh', 'Post', '20230826225729_PreetiSingh_08.09.23_20_Eye Close.easy' )\n",
    "eye_close_7 = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Active', 'Hemlata', 'Post', '20231019110530_Hemlata_19.10.23_19A_Eye Close.easy') \n",
    "eye_close_8 = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Active', 'VinodKumarSharma', 'Post', '20230901112451_VinodKumarSharma_11.10.23_20_Eye Close.easy' ) \n",
    "# eye_close_9 = '\\\\Depression-Sample-dataset-AIIMS\\\\Sham\\\\JitenderKumar\\\\post\\\\' + '20230827174115_JitenderKumar_13.09.23_20_Eye\\ Close'\n",
    "# eye_close_10 = '\\\\Depression-Sample-dataset-AIIMS\\\\Sham\\\\SeemaKumari\\\\post\\\\' + '20230829172634_SeemaKumari_23.9.23_20_Eye\\ Close'\n",
    "eye_close_control = [eye_close_6, eye_close_7, eye_close_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE VS POST COMPARISON\n",
    "raw_2 = []\n",
    "# folder_path = os.getcwd()+'\\\\Depression-Sample-dataset-AIIMS\\\\'\n",
    "for file_path in eye_close_control:\n",
    "    raw = data_transformation_easy(file_path)\n",
    "    # raw = mne.io.read_raw_edf(file, eog=None, misc=None, stim_channel='auto', exclude=(), infer_types=False, include=None, preload=True, units=None, encoding='utf8', verbose=None)\n",
    "    # By default read_raw_edf convert units to V\n",
    "    raw = g1_preprocess(raw)\n",
    "    raw_2.append(raw.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE VS POST COMPARISON\n",
    "# M1 : Averaging using mean:\n",
    "raw_2_avg = np.mean(raw_2, axis=0)\n",
    "print(raw_2_avg)\n",
    "\n",
    "del raw_2[:]\n",
    "del raw_2\n",
    "del eye_close_control[:]\n",
    "del eye_close_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE VS POST COMPARISON\n",
    "info = raw.info\n",
    "raw_2 = mne.io.RawArray(raw_2_avg, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find control indexes\n",
    "# file_path = os.getcwd() + '\\\\Depression-Sample-dataset-AIIMS\\\\' + 'Control\\\\' + 'derivatives\\\\cleaned_epochs\\\\'\n",
    "# control_indexes = []\n",
    "# for i in range(0, 111):\n",
    "#     eeg_file_epoch = file_path + f'sub-{i+1:03d}\\\\ses-t1\\\\eeg\\\\sub-{i+1:03d}_ses-t1_task-resteyesc_desc-epochs_eeg.set'\n",
    "#     epochs_data = mne.io.read_epochs_eeglab(eeg_file_epoch, events=None, event_id=None, eog=(), uint16_codec=None, montage_units='mm', verbose=None)\n",
    "#     if len(epochs_data.get_data()) == 55:\n",
    "#         control_indexes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = os.getcwd() + '\\\\Depression-Sample-dataset-AIIMS\\\\' + 'Control\\\\'\n",
    "# raw_2 = []\n",
    "# for i in control_indexes:\n",
    "#     eeg_file_raw = file_path + f'sub-{i+1:03d}\\\\ses-t1\\\\eeg\\\\sub-{i+1:03d}_ses-t1_task-resteyesc_eeg.edf'\n",
    "#     raw = mne.io.read_raw_edf(eeg_file_raw, eog=None, misc=None, stim_channel='auto', exclude=(), infer_types=False, include=None, preload=False, units=None, encoding='utf8', verbose=None)\n",
    "#     # By default read_raw_edf convert units to V\n",
    "#     raw = control_preprocessing(raw, raw_1)\n",
    "#     raw_2.append(raw.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del control_indexes[:]\n",
    "# del control_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_2_avg = np.mean(raw_2, axis=0)\n",
    "\n",
    "# del raw_2[:]\n",
    "# del raw_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info = raw.info\n",
    "# raw_2 = mne.io.RawArray(raw_2_avg, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Raw MDD and control data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_1.save(\"loadData/rawMDDpre3Active.fif\", overwrite=True)\n",
    "raw_2.save(\"loadData/rawMDDpost3Active.fif\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 4.0\n",
    "overlap = 2.0 \n",
    "\n",
    "samples_per_epoch = int(duration * SFREQ)\n",
    "samples_per_overlap = int(overlap * SFREQ)\n",
    "\n",
    "# Manually created events\n",
    "start, stop = 0, samples_per_epoch\n",
    "events = []\n",
    "while stop <= len(raw_1):\n",
    "    events.append([start, 0, 1]) \n",
    "    start += samples_per_overlap\n",
    "    stop += samples_per_overlap\n",
    "\n",
    "events = np.array(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Segmenting epochs for MDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_1 = mne.Epochs(raw_1, events, tmin=0, tmax=duration, baseline=None, detrend=1,\n",
    "                    picks=None, preload=True, reject=None)\n",
    "raw_1.plot(n_channels=len(raw_1.info['ch_names']), events=events, event_color={1:'r'}, scalings=SCALINGS)\n",
    "epochs_1.plot(n_channels=len(raw_1.info['ch_names']), event_color={1:'r'}, events=events, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Segmenting epochs for control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_2 = mne.Epochs(raw_2, events, tmin=0, tmax=duration, baseline=None, detrend=1,\n",
    "                    picks=None, preload=True, reject=None)\n",
    "raw_2.plot(n_channels=len(raw_1.info['ch_names']), events=events, event_color={1:'r'}, scalings=SCALINGS)\n",
    "epochs_2.plot(n_channels=len(raw_1.info['ch_names']), event_color={1:'r'}, events=events, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = os.getcwd() + '\\\\Depression-Sample-dataset-AIIMS\\\\' + 'Control\\\\' + 'derivatives\\\\cleaned_epochs\\\\'\n",
    "# epochs_2 = []\n",
    "# for i in range(0, 111):\n",
    "#     eeg_file_epoch = file_path + f'sub-{i+1:03d}\\\\ses-t1\\\\eeg\\\\sub-{i+1:03d}_ses-t1_task-resteyesc_desc-epochs_eeg.set'\n",
    "#     epochs_data = mne.io.read_epochs_eeglab(eeg_file_epoch, events=None, event_id=None, eog=(), uint16_codec=None, montage_units='mm', verbose=None)\n",
    "#     if len(epochs_data.get_data()) == 55:\n",
    "#         cleaned_epoch = control_preprocessing(epochs_data, epochs_1, crop=False)\n",
    "#         epochs_2.append(cleaned_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_2_avg = np.mean(epochs_2, axis=0)\n",
    "# print(epochs_2_avg)\n",
    "\n",
    "# del epochs_2[:]\n",
    "# del epochs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info = cleaned_epoch.info\n",
    "# epochs_2 = mne.EpochsArray(epochs_2_avg, info)\n",
    "# epochs_2.plot(n_channels=len(raw_1.info['ch_names']), event_color={1:'r'}, events=None, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving epoched raw and control data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_1.save(\"loadData/epochsMDDpre3Active.fif\", overwrite=True)\n",
    "# epochs_2.save(\"loadData/epochsMDDpost3Active.fif\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. PSD graph plot between MDD and Control group\n",
    "\n",
    "For resting state EEG channel, analyzing the overall average power across channels provides a holistic view of the brain's activity without emphasizing the specificity of individual channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wavelet_plot(raw1, raw2, title):\n",
    "#     '''\n",
    "#     signal ----> breaks into frequency components/scales ----> WT computes coeffcients that represent signal's content \n",
    "#     at a specific scale ----->coeffs at lower level represent lower frequency components\n",
    "     \n",
    "#     Scales vs frequencies - lower scale = higher frequency (fine details)\n",
    "#     larger coefficient represents higher energy at a sepcific scale\n",
    "#     peaks in scale vs time plot = where energy is concentrated\n",
    "#     broad distribution across scales = mix of frequencies\n",
    "\n",
    "#     Find frequency component of interest \n",
    "#     Step1: Look for peaks (dominant frequencies)\n",
    "#     Step2: Convert scale to frequency using frequency = SFREQ/(2**scale)\n",
    "#     Step 3: Compare across time\n",
    "#     Step 4: Statistical analysis\n",
    "\n",
    "#     '''\n",
    "#     # Average channel wavelet transform\n",
    "#     raw1_avg = np.mean(raw1.get_data(), axis=0)\n",
    "#     raw2_avg = np.mean(raw2.get_data(), axis=0)\n",
    "\n",
    "#     # Individual channels wavelet transform\n",
    "#     t = np.arange(0, 150, 1/SFREQ)\n",
    "#     ts = t[:-1]\n",
    "    \n",
    "#     wavelet = 'db13'\n",
    "#     level = 4 # level of decomposition based on your signal characteristics\n",
    " \n",
    "#     coeffs1 = pywt.wavedec(raw1_avg, wavelet, level=level)    \n",
    "#     coeffs2 = pywt.wavedec(raw2_avg, wavelet, level=level)\n",
    "\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     for i in range(level+1):\n",
    "#         if i==0:\n",
    "#             plt.plot(t, raw1_avg, label='MDD raw')\n",
    "#         plt.plot(t, pywt.upcoef('a', coeffs1[i], wavelet, level=level)[:len(t)], label=f'MDD - Level {i}')\n",
    "#         if i==0:\n",
    "#             plt.plot(t, raw2_avg, label='Control raw')\n",
    "#         plt.plot(t, pywt.upcoef('a', coeffs2[i], wavelet, level=level)[:len(t)], label=f'Control - Level {i}')\n",
    "#         plt.title('DWT')\n",
    "#         plt.xlabel('Time')\n",
    "#         plt.ylabel('Amplitude')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "\n",
    "# wavelet_plot(raw_1, raw_2, \"gjhggj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amplitude plots between both groups\n",
    "epochs_1_avg = epochs_1['1'].average()\n",
    "epochs_2_avg = epochs_2['1'].average()\n",
    "# evokeds = dict(epochs_1=epochs_1)\n",
    "fig_MDD = epochs_1_avg.plot(titles=GROUP1, time_unit = 'ms')\n",
    "fig_control = epochs_2_avg.plot(titles=GROUP2, time_unit = 'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 PSD using plot_psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().\n",
      "Effective window size : 4.096 (s)\n",
      "NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().\n",
      "Effective window size : 4.096 (s)\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "#plot_psd uses welch method for continuous data\n",
    "raw_1.plot_psd(picks=raw_1.info['ch_names'], average=True, fmin=FMIN, fmax=FMAX, ax=ax, show=False, color='blue', dB=False)\n",
    "raw_2.plot_psd(picks=raw_2.info['ch_names'], average=True, fmin=FMIN, fmax=FMAX, ax=ax, show=False, color='red', dB=False)\n",
    "\n",
    "# dB = True plots PSD in decibels (logarithmic)\n",
    "# different n_fft compared to psd_array_welch\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Power/Frequency (microV^2/Hz)')\n",
    "ax.set_title('Power Spectral Density Comparison')\n",
    "\n",
    "ax.text(0.8, 0.9, GROUP1, color='blue', transform=ax.transAxes)\n",
    "ax.text(0.8, 0.85, GROUP2, color='red', transform=ax.transAxes)\n",
    "\n",
    "plt.ylim(0, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Average of power using welch method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.512 (s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.512 (s)\n"
     ]
    }
   ],
   "source": [
    "labels = np.arange(0, FMAX)\n",
    "# welch always gives positive psd\n",
    "psd_1, frequencies = mne.time_frequency.psd_array_welch(raw_1.get_data(), fmin=FMIN, fmax=FMAX, sfreq=SFREQ)\n",
    "psd_2, frequencies = mne.time_frequency.psd_array_welch(raw_2.get_data(), fmin=FMIN, fmax=FMAX, sfreq=SFREQ)\n",
    "avg_abs_power_1, avg_abs_power_2 = np.mean(psd_1, axis=0), np.mean(psd_2, axis=0) \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(frequencies, avg_abs_power_1, color='blue', label=GROUP1)\n",
    "plt.plot(frequencies, avg_abs_power_2, color='red', label=GROUP2)\n",
    "plt.title('Welch - Average Power')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.xticks(labels, labels, rotation ='vertical') \n",
    "plt.ylabel('Power (V^2/Hz)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Statistical testing between psds of raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.1 Plotting Histogram\n",
    "\n",
    "Shows if the data is bell shaped, skewed (positive or negative), uniform etc. Central tendency - highest peak in histogram. Spread - width of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_avg = np.mean(raw_1.get_data(), axis=0)\n",
    "plt.hist(g1_avg, bins='auto', alpha=0.7, edgecolor='black')\n",
    "plt.title(f'Histogram of {GROUP1} Data - averaged across all channels')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2_avg = np.mean(raw_2.get_data(), axis=0)\n",
    "plt.hist(g2_avg, bins='auto', alpha=0.7, edgecolor='black')\n",
    "plt.title(f'Histogram of {GROUP2} Data - averaged across all channels')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE-ACTIVE mean:  5.74804513030665e-15\n",
      "POST-ACTIVE mean:  -9.434248663081896e-15\n"
     ]
    }
   ],
   "source": [
    "print(f\"{GROUP1} mean: \", np.mean(g1_avg, axis=0))\n",
    "print(f\"{GROUP2} mean: \", np.mean(g2_avg, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.2 Calculate variance of both groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE-ACTIVE variance:  4.393636051591881e-23\n",
      "POST-ACTIVE variance:  1.146915391749627e-22\n"
     ]
    }
   ],
   "source": [
    "variance_1 = np.var(psd_1, ddof=1) \n",
    "variance_2 = np.var(psd_2, ddof=1)\n",
    "print(f\"{GROUP1} variance: \", variance_1)\n",
    "print(f\"{GROUP2} variance: \", variance_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.3 Find differences between the means of two independent groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, null hypothesis: there is no significant difference between groups (ie means are equal).\n",
    "alternative hypothesis: there is a significant difference between groups\n",
    "t-test : compares the differences between group means to expected variability in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data PSD Comparison Results:\n",
      "T-statistic: [-0.27304604 -0.03453517 -0.21751426 -1.00135135  0.1310346   0.16661762\n",
      "  0.53889779  0.06025445  0.11036171  0.26668035 -0.16806577 -0.39817457\n",
      "  0.87833595  0.63308663 -0.29067226 -0.21898807  1.30634713 -0.8337382\n",
      "  1.44027416  1.18135668  0.28608419 -0.80793568  0.84484441 -1.06582949\n",
      " -0.92871372  0.23145593  0.32488679  0.07026924 -0.10960572  1.54623124\n",
      "  0.4692573   1.12480499]\n",
      "P-values: [0.78609533 0.9726066  0.82881315 0.3221323  0.89634524 0.86843427\n",
      " 0.59267373 0.95222583 0.91262438 0.79096116 0.86730169 0.69242703\n",
      " 0.38453277 0.52995398 0.7726677  0.827672   0.19822231 0.40893198\n",
      " 0.15686793 0.24380712 0.7761563  0.42347425 0.4027683  0.29231451\n",
      " 0.35810455 0.81803364 0.74680649 0.94429778 0.91322045 0.12921175\n",
      " 0.64120279 0.2667704 ]\n"
     ]
    }
   ],
   "source": [
    "p_values = np.zeros(32)\n",
    "t = np.zeros(32)\n",
    "for i in range(32):\n",
    "    t[i], p_values[i] = ttest_ind(psd_1[i, :], psd_2[i, :])\n",
    "# independent t-test comparison : equal_var = True\n",
    "# welch's t-test comparison: equal_var = False\n",
    "print(\"Raw Data PSD Comparison Results:\")\n",
    "print(\"T-statistic:\", t)\n",
    "print(\"P-values:\", p_values) # probability of getting t-statistic >= what we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data PSD Comparison Results:\n",
      "T-statistic: -0.06768540561794865\n",
      "P-values: 0.9463921453925532\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_values = ttest_ind(np.mean(psd_1, axis=0), np.mean(psd_2, axis=0), equal_var=False)\n",
    "# independent t-test comparison : equal_var = True\n",
    "# welch's t-test comparison: equal_var = False\n",
    "print(\"Raw Data PSD Comparison Results:\")\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-values:\", p_values) # probability of getting t-statistic >= what we got"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If p value < 0.005, we reject the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PLI and construction of brain function matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_bands = [(0.01, 4), (4,8), (8, 10), (10, 13), (13, 15), (15, 22)]\n",
    "mapping = {0: 'delta', 1: 'theta', 2: 'alpha1', 3:'alpha2', 4:'beta1', 5:'beta2'}\n",
    "connectivity = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pli method always gives positive correlations\n",
    "def connectivity_matrix(epochs, i):\n",
    "    return spectral_connectivity_epochs(\n",
    "    epochs, method='pli', mode='multitaper', sfreq=SFREQ,\n",
    "    fmin=freq_bands[i][0], fmax=freq_bands[i][1], faverage=True, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 0.2Hz..4.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10587/1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  73 events (all good), 0 – 4 s, baseline off, ~54 kB, data not loaded,\n",
      " '1': 73>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n",
      "/tmp/ipykernel_10587/1345682627.py:3: RuntimeWarning: fmin=0.010 Hz corresponds to 0.040 < 5 cycles based on the epoch length 4.002 sec, need at least 500.000 sec epochs or fmin=1.249. Spectrum estimate will be unreliable.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 0.2Hz..4.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10587/1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  73 events (all good), 0 – 4 s, baseline off, ~54 kB, data not loaded,\n",
      " '1': 73>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n",
      "/tmp/ipykernel_10587/1345682627.py:3: RuntimeWarning: fmin=0.010 Hz corresponds to 0.040 < 5 cycles based on the epoch length 4.002 sec, need at least 500.000 sec epochs or fmin=1.249. Spectrum estimate will be unreliable.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 4.2Hz..8.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10587/1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  73 events (all good), 0 – 4 s, baseline off, ~54 kB, data not loaded,\n",
      " '1': 73>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 4.2Hz..8.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10587/1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  73 events (all good), 0 – 4 s, baseline off, ~54 kB, data not loaded,\n",
      " '1': 73>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 8.2Hz..10.0Hz (8 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10587/1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  73 events (all good), 0 – 4 s, baseline off, ~54 kB, data not loaded,\n",
      " '1': 73>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 8.2Hz..10.0Hz (8 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10587/1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  73 events (all good), 0 – 4 s, baseline off, ~54 kB, data not loaded,\n",
      " '1': 73>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 10.2Hz..13.0Hz (12 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10587/1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  73 events (all good), 0 – 4 s, baseline off, ~54 kB, data not loaded,\n",
      " '1': 73>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 10.2Hz..13.0Hz (12 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10587/1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  73 events (all good), 0 – 4 s, baseline off, ~54 kB, data not loaded,\n",
      " '1': 73>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 13.2Hz..15.0Hz (8 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10587/1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  73 events (all good), 0 – 4 s, baseline off, ~54 kB, data not loaded,\n",
      " '1': 73>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 13.2Hz..15.0Hz (8 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10587/1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  73 events (all good), 0 – 4 s, baseline off, ~54 kB, data not loaded,\n",
      " '1': 73>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 15.2Hz..22.0Hz (28 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10587/1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  73 events (all good), 0 – 4 s, baseline off, ~54 kB, data not loaded,\n",
      " '1': 73>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 15.2Hz..22.0Hz (28 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10587/1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  73 events (all good), 0 – 4 s, baseline off, ~54 kB, data not loaded,\n",
      " '1': 73>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n"
     ]
    }
   ],
   "source": [
    "n_channels = len(raw_1.info['ch_names'])\n",
    "for i in range(len(freq_bands)):\n",
    "    con = connectivity_matrix(epochs_1, i)\n",
    "    connectivity[f'{GROUP1}-{mapping[i]}'] = con.get_data().reshape((n_channels, n_channels))\n",
    "\n",
    "    con = connectivity_matrix(epochs_2, i)\n",
    "    connectivity[f'{GROUP2}-{mapping[i]}'] = con.get_data().reshape((n_channels, n_channels))\n",
    "\n",
    "    # Make matrix symmetric\n",
    "    for row in range(n_channels):\n",
    "        for col in range(n_channels):\n",
    "            connectivity[f'{GROUP1}-{mapping[i]}'][row][col] = connectivity[f'{GROUP1}-{mapping[i]}'][col][row]\n",
    "            connectivity[f'{GROUP2}-{mapping[i]}'][row][col] = connectivity[f'{GROUP2}-{mapping[i]}'][col][row]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['PRE-ACTIVE-delta', 'POST-ACTIVE-delta', 'PRE-ACTIVE-theta', 'POST-ACTIVE-theta', 'PRE-ACTIVE-alpha1', 'POST-ACTIVE-alpha1', 'PRE-ACTIVE-alpha2', 'POST-ACTIVE-alpha2', 'PRE-ACTIVE-beta1', 'POST-ACTIVE-beta1', 'PRE-ACTIVE-beta2', 'POST-ACTIVE-beta2'])\n"
     ]
    }
   ],
   "source": [
    "print((connectivity.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ALTERNATIVE: PLI calculation in Raw Python\n",
    "\n",
    "# def calculate_pli(data):\n",
    "#     # data = EEG data of channel Ci and Cj for 1 epoch (2000 data points (4s X 500fs))\n",
    "#     analytic_signal = hilbert(data)\n",
    "#     instantaneous_phase = np.angle(analytic_signal)\n",
    "#     return np.abs(np.mean(np.sign(np.diff(instantaneous_phase, axis=0))))\n",
    "\n",
    "# fun_connectivity = []\n",
    "# for k in range(len(epochs)):\n",
    "#     pli_matrix = [[0 for i in range(len(raw_cleaned.info['ch_names']))] for j in range(len(raw_cleaned.info['ch_names']))]\n",
    "#     for i in range(len(raw_cleaned.info['ch_names'])):\n",
    "#         for j in range(i+1, len(raw_cleaned.info['ch_names'])):\n",
    "#             pli_matrix[i][j] = pli_matrix[j][i] = calculate_pli([epochs[k].get_data(fmin = freq_bands[0][0], fmax=freq_bands[-1][-1])[0][i], epochs[k].get_data(fmin = freq_bands[0][0], fmax=freq_bands[-1][-1])[0][j]])\n",
    "\n",
    "#     fun_connectivity.append(pli_matrix)\n",
    "# conn = np.mean(fun_connectivity, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Thresholding - M1 -  Small World Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preserves small-world properties in both groups to ensure that any observed differences in connectivity are not biased by the thresholding method.\n",
    "# Preserving these properties ensures that information can be transmitted quickly and effectively across the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.693393438150762 Cw1  0.8206087665211639 Lw1  1.1834677419354838\n",
      "0.878539103750922 Cw2  0.9387615423144934 Lw2  1.0685483870967742\n",
      "delta - Optimal Threshold: 0.1 (Significant) 2.409809725245008e-12\n",
      "0.2830188679245283 Cw1  0.047619047619047616 Lw1  0.16825396825396824\n",
      "0.1336432771617957 Cw2  0.09124609957943292 Lw2  0.6827586206896551\n",
      "theta - Optimal Threshold: 0.6660000000000005 (Significant) 6.4050075170624085e-12\n",
      "0.2873103190846081 Cw1  0.2459129182702667 Lw1  0.8559139784946237\n",
      "0.3311533099912656 Cw2  0.5100829210349332 Lw2  1.5403225806451613\n",
      "alpha1 - Optimal Threshold: 0.4320000000000003 (Significant) 2.3706395712621753e-08\n",
      "0.09543804601944138 Cw1  0.01609347442680776 Lw1  0.16862745098039214\n",
      "0.038568778419393525 Cw2  0.033633156966490295 Lw2  0.8720306513409962\n",
      "alpha2 - Optimal Threshold: 0.7540000000000006 (Significant) 0.0004624686935601696\n",
      "0.02329650092081031 Cw1  0.003042328042328042 Lw1  0.1305916305916306\n",
      "0.004956427015250545 Cw2  0.00196969696969697 Lw2  0.3974025974025974\n",
      "beta1 - Optimal Threshold: 0.7980000000000006 (Significant) 0.0016150231750375857\n"
     ]
    }
   ],
   "source": [
    "optimal_threshold = {}\n",
    "edges_1 = {}\n",
    "edges_2 = {}\n",
    "# Generating 50 random networks with same number of vertices and edges \n",
    "random_networks = [nx.gnm_random_graph(n_channels, 496) for _ in range(50)]\n",
    "thresholds = np.arange(0.1, 0.9, 0.002)\n",
    "\n",
    "for i in range(len(freq_bands)):\n",
    "    edges_1[mapping[i]] = []\n",
    "    edges_2[mapping[i]] = []\n",
    "    ratios = []\n",
    "    for threshold in thresholds:\n",
    "        # TODO: Cross check should we ignore thresholds which result in matrix to be not connected ?\n",
    "        Lw_1_binarized = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] > threshold))[0]\n",
    "        Cw_1_binarized = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] > threshold))[3]\n",
    "\n",
    "        Lw_2_binarized = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP2}-{mapping[i]}'] > threshold))[0]\n",
    "        Cw_2_binarized = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP2}-{mapping[i]}'] > threshold))[3]\n",
    "\n",
    "        swi_ratio_binarized =  (Cw_1_binarized*Lw_2_binarized)/(Lw_1_binarized*Cw_2_binarized) if Lw_1_binarized and Cw_2_binarized else 0\n",
    "        ratios.append(swi_ratio_binarized)\n",
    "\n",
    "    t_stat, p_value = ttest_ind(np.mean(connectivity[f'{GROUP1}-{mapping[i]}'], axis=0), np.mean(connectivity[f'{GROUP2}-{mapping[i]}'], axis=0)) \n",
    "    if p_value < 0.005: # Reject the null hypotheses\n",
    "        optimal_threshold[mapping[i]] = thresholds[np.argmax(np.abs(ratios))] #TODO: ratios - swi_ratio ? OR remove swi_ratio and related code above\n",
    "        Crand = np.mean([calculate_avergae_components(nx.from_numpy_array((nx.to_numpy_array(G) > optimal_threshold[mapping[i]])))[3] for G in random_networks])\n",
    "        Lrand = np.mean([calculate_avergae_components(nx.from_numpy_array((nx.to_numpy_array(G) > optimal_threshold[mapping[i]])))[0] for G in random_networks])\n",
    "\n",
    "        Lw_1_binarized = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] > optimal_threshold[mapping[i]]))[0]\n",
    "        Cw_1_binarized = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] > optimal_threshold[mapping[i]]))[3]\n",
    "\n",
    "        Lw_2_binarized = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP2}-{mapping[i]}'] > optimal_threshold[mapping[i]]))[0]\n",
    "        Cw_2_binarized = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP2}-{mapping[i]}'] > optimal_threshold[mapping[i]]))[3]\n",
    "\n",
    "        swi_binarized_1 =  (Cw_1_binarized/Crand)/(Lw_1_binarized/Lrand)\n",
    "        swi_binarized_2 = (Cw_2_binarized/Crand)/(Lw_2_binarized/Lrand)\n",
    "        print(swi_binarized_1, \"Cw1 \", Cw_1_binarized, \"Lw1 \", Lw_1_binarized)\n",
    "        print(swi_binarized_2, \"Cw2 \", Cw_2_binarized, \"Lw2 \", Lw_2_binarized)  \n",
    "\n",
    "        edges_1[mapping[i]].append(nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] > optimal_threshold[mapping[i]]).number_of_edges())\n",
    "        edges_2[mapping[i]].append(nx.from_numpy_array(connectivity[f'{GROUP2}-{mapping[i]}'] > optimal_threshold[mapping[i]]).number_of_edges())\n",
    "\n",
    "        print(f\"{mapping[i]} - Optimal Threshold: {optimal_threshold[mapping[i]]} (Significant)\", p_value)\n",
    "\n",
    "    # plt.plot(thresholds, ratios, label='Threshold Ratios')\n",
    "    # plt.axhline(swi_ratio, color='red', linestyle='--', label=' SWI ratio (MDD/Control)')\n",
    "    # plt.xlabel(f'Threshold-{mapping[i]}')\n",
    "    # plt.ylabel('Ratio')\n",
    "    # plt.legend()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(freq_bands)):\n",
    "#     optimal_threshold[mapping[i]]  -= 0.1\n",
    "# print(optimal_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2 - Community structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "import networkx as nx\n",
    "# Calculate the participation coefficient for each node\n",
    "def participation_coefficient(node, modularity_matrix):\n",
    "    k_in = np.sum(modularity_matrix[node, :])\n",
    "    k_out = np.sum(modularity_matrix) - k_in\n",
    "    q = modularity_matrix.shape[0]\n",
    "    pc = 1 - ((k_in / q) ** 2 + (k_out / q) ** 2)\n",
    "    return pc\n",
    "\n",
    "def community_structure(G):\n",
    "    # Compute community structure (Louvain algorithm)\n",
    "    partition = list(nx.algorithms.community.modularity_max.greedy_modularity_communities(G)[0])\n",
    "    # pi_scores = nx.algorithms.community.indicators.participation(G, partition)(G)\n",
    "\n",
    "    print(nx.modularity_matrix(G))\n",
    "\n",
    "    # plot network with community structure \n",
    "    # pos = nx.spring_layout(G)\n",
    "    # colors = [partition[node] for node in G.nodes]\n",
    "    # plt.figure(figsize=(10, 8))\n",
    "    # nx.draw(G, pos, node_color=colors, with_labels=True, cmap=plt.cm.Paired, node_size=300)\n",
    "    # plt.title(\"Community structure\")\n",
    "    # plt.show()\n",
    "\n",
    "    num_nodes = len(G.nodes)\n",
    "    mod_matrix = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "    # Find modularity matrix\n",
    "    for i, j, _ in G.edges(data=True):\n",
    "        mod_matrix[i][j] = 1 if partition[i] == partition[j] else 0\n",
    "\n",
    "    pi_values = np.zeros(num_nodes)\n",
    "    for node in range(num_nodes):\n",
    "        pi_values[node] = participation_coefficient(node, mod_matrix)\n",
    "\n",
    "    # Rank-order the PI scores (lowest to highest)\n",
    "    ranked_pi = np.argsort(pi_values) + 1\n",
    "    return ranked_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4651826484018265 0.3002758751902588\n",
      "[[-0.96875  0.03125  0.03125 ...  0.03125  0.03125  0.03125]\n",
      " [ 0.03125 -0.96875  0.03125 ...  0.03125  0.03125  0.03125]\n",
      " [ 0.03125  0.03125 -0.96875 ...  0.03125  0.03125  0.03125]\n",
      " ...\n",
      " [ 0.03125  0.03125  0.03125 ... -0.96875  0.03125  0.03125]\n",
      " [ 0.03125  0.03125  0.03125 ...  0.03125 -0.96875  0.03125]\n",
      " [ 0.03125  0.03125  0.03125 ...  0.03125  0.03125 -0.96875]]\n",
      "-0.7693588280060883 0.48185407153729076\n",
      "[[-0.96875  0.03125  0.03125 ...  0.03125  0.03125  0.03125]\n",
      " [ 0.03125 -0.96875  0.03125 ...  0.03125  0.03125  0.03125]\n",
      " [ 0.03125  0.03125 -0.96875 ...  0.03125  0.03125  0.03125]\n",
      " ...\n",
      " [ 0.03125  0.03125  0.03125 ... -0.96875  0.03125  0.03125]\n",
      " [ 0.03125  0.03125  0.03125 ...  0.03125 -0.96875  0.03125]\n",
      " [ 0.03125  0.03125  0.03125 ...  0.03125  0.03125 -0.96875]]\n",
      "-0.7593226788432268 0.6359874429223745\n",
      "[[-0.96875  0.03125  0.03125 ...  0.03125  0.03125  0.03125]\n",
      " [ 0.03125 -0.96875  0.03125 ...  0.03125  0.03125  0.03125]\n",
      " [ 0.03125  0.03125 -0.96875 ...  0.03125  0.03125  0.03125]\n",
      " ...\n",
      " [ 0.03125  0.03125  0.03125 ... -0.96875  0.03125  0.03125]\n",
      " [ 0.03125  0.03125  0.03125 ...  0.03125 -0.96875  0.03125]\n",
      " [ 0.03125  0.03125  0.03125 ...  0.03125  0.03125 -0.96875]]\n",
      "-0.7630327245053272 0.5762937595129376\n",
      "[[-0.96875  0.03125  0.03125 ...  0.03125  0.03125  0.03125]\n",
      " [ 0.03125 -0.96875  0.03125 ...  0.03125  0.03125  0.03125]\n",
      " [ 0.03125  0.03125 -0.96875 ...  0.03125  0.03125  0.03125]\n",
      " ...\n",
      " [ 0.03125  0.03125  0.03125 ... -0.96875  0.03125  0.03125]\n",
      " [ 0.03125  0.03125  0.03125 ...  0.03125 -0.96875  0.03125]\n",
      " [ 0.03125  0.03125  0.03125 ...  0.03125  0.03125 -0.96875]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(freq_bands)):\n",
    "    # Values ranging from -1 to 1\n",
    "    diff_matrix = nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] - connectivity[f'{GROUP2}-{mapping[i]}'])\n",
    "    print(np.min(connectivity[f'{GROUP1}-{mapping[i]}'] - connectivity[f'{GROUP2}-{mapping[i]}']), np.max(connectivity[f'{GROUP1}-{mapping[i]}'] - connectivity[f'{GROUP2}-{mapping[i]}']))\n",
    "    ranked_pi = community_structure(diff_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M3 - Threshold using saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(freq_bands)):\n",
    "    plt.plot(thresholds, edges_MDD[mapping[i]])\n",
    "    plt.plot(thresholds, edges_control[mapping[i]])\n",
    "    plt.title(f'{mapping[i]} Threshold comparison (blue - MDD, red-Control)')\n",
    "    plt.xlabel('Thresholds')\n",
    "    plt.ylabel('Number of edges')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To remove:\n",
    "# optimal_threshold['delta'] = 0.442\n",
    "# optimal_threshold['theta'] =  0.529\n",
    "# optimal_threshold['alpha1'] = 0.786\n",
    "# optimal_threshold['alpha2'] = 0.741"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M4 - ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_1.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Binarization on functional connectivity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "del freq_bands[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['PRE-ACTIVE-delta', 'POST-ACTIVE-delta', 'PRE-ACTIVE-theta', 'POST-ACTIVE-theta', 'PRE-ACTIVE-alpha1', 'POST-ACTIVE-alpha1', 'PRE-ACTIVE-alpha2', 'POST-ACTIVE-alpha2', 'PRE-ACTIVE-beta1', 'POST-ACTIVE-beta1'])\n"
     ]
    }
   ],
   "source": [
    "binarized_matrix = {}\n",
    "for i in range(len(freq_bands)):\n",
    "    binarized_matrix[f'{GROUP1}-{mapping[i]}'] = connectivity[f'{GROUP1}-{mapping[i]}'] > optimal_threshold[mapping[i]]\n",
    "    binarized_matrix[f'{GROUP2}-{mapping[i]}'] = connectivity[f'{GROUP2}-{mapping[i]}'] > optimal_threshold[mapping[i]]\n",
    "print(binarized_matrix.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find number of links in each graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE-ACTIVE-delta-number of links: K= 405\n",
      "POST-ACTIVE-delta-number of links: K= 462\n",
      "PRE-ACTIVE-theta-number of links: K= 13\n",
      "POST-ACTIVE-theta-number of links: K= 108\n",
      "PRE-ACTIVE-alpha1-number of links: K= 152\n",
      "POST-ACTIVE-alpha1-number of links: K= 240\n",
      "PRE-ACTIVE-alpha2-number of links: K= 24\n",
      "POST-ACTIVE-alpha2-number of links: K= 57\n",
      "PRE-ACTIVE-beta1-number of links: K= 14\n",
      "POST-ACTIVE-beta1-number of links: K= 36\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(freq_bands)):\n",
    "    links_MDD = 0\n",
    "    links_control = 0\n",
    "\n",
    "    for row in range(n_channels):\n",
    "        for col in range(row+1):\n",
    "            if binarized_matrix[f'{GROUP1}-{mapping[i]}'][row][col] == 1:\n",
    "                links_MDD+=1\n",
    "            if binarized_matrix[f'{GROUP2}-{mapping[i]}'][row][col] == 1:\n",
    "                links_control+=1\n",
    "\n",
    "    print(f'{GROUP1}-{mapping[i]}-number of links: K=', links_MDD)\n",
    "    print(f'{GROUP2}-{mapping[i]}-number of links: K=', links_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yellow - Higher synchronisation\n",
    "for i in range(len(binarized_matrix)//2):\n",
    "    # i = 0, 1, 2\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for j in range(2):\n",
    "        # j = 0, 1\n",
    "        plt.subplot(1, 2, j+1)\n",
    "        plt.imshow(list(binarized_matrix.values())[2*i+j], interpolation='none')\n",
    "        plt.title(f'Functional connectivity - {list(binarized_matrix)[2*i+j]} - Visualization')\n",
    "        plt.xticks([_ for _ in range(n_channels)], raw_1.info['ch_names'], rotation='vertical')\n",
    "        plt.yticks([_ for _ in range(n_channels)], raw_1.info['ch_names'], rotation='horizontal')\n",
    "        plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asymmetry in  each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE-ACTIVE:  delta left region:  292 right region:  268 proportion:  1.0895522388059702\n",
      "POST-ACTIVE:  delta left region:  316 right region:  327 proportion:  0.9663608562691132\n",
      "PRE-ACTIVE:  theta left region:  9 right region:  4 proportion:  2.25\n",
      "POST-ACTIVE:  theta left region:  78 right region:  66 proportion:  1.1818181818181819\n",
      "PRE-ACTIVE:  alpha1 left region:  116 right region:  79 proportion:  1.4683544303797469\n",
      "POST-ACTIVE:  alpha1 left region:  176 right region:  160 proportion:  1.1\n",
      "PRE-ACTIVE:  alpha2 left region:  19 right region:  10 proportion:  1.9\n",
      "POST-ACTIVE:  alpha2 left region:  42 right region:  36 proportion:  1.1666666666666667\n",
      "PRE-ACTIVE:  beta1 left region:  10 right region:  6 proportion:  1.6666666666666667\n",
      "POST-ACTIVE:  beta1 left region:  29 right region:  19 proportion:  1.5263157894736843\n"
     ]
    }
   ],
   "source": [
    "left_region = ['Fp1', 'AF3', 'PO3','O1', 'CP1', 'FC1', 'P3', 'C3', 'F3', 'F7', 'FC5', 'CP5', 'T7', 'P7']\n",
    "right_region = ['P8', 'T8', 'CP6', 'FC6', 'F8', 'F4', 'C4', 'P4', 'AF4', 'Fp2', 'FC2', 'CP2', 'O2', 'PO4']\n",
    "\n",
    "for i in range(len(freq_bands)):\n",
    "    lr = 0 \n",
    "    rr = 0\n",
    "    lrc = 0\n",
    "    rrc = 0\n",
    "    for row in range(n_channels):\n",
    "        for col in range(row+1):\n",
    "            if binarized_matrix[f'{GROUP1}-{mapping[i]}'][row][col] == 1:\n",
    "                if raw_1.info['ch_names'][row] in left_region or raw_1.info['ch_names'][col] in left_region:\n",
    "                    lr += 1\n",
    "                if raw_1.info['ch_names'][row] in right_region or raw_1.info['ch_names'][col] in right_region:\n",
    "                    rr += 1\n",
    "                # print(raw_1.info['ch_names'][row], raw_1.info['ch_names'][col])\n",
    "\n",
    "            if binarized_matrix[f'{GROUP2}-{mapping[i]}'][row][col] == 1:\n",
    "                if raw_1.info['ch_names'][row] in left_region or raw_1.info['ch_names'][col] in left_region:\n",
    "                    lrc += 1\n",
    "                if raw_1.info['ch_names'][row] in right_region or raw_1.info['ch_names'][col] in right_region:\n",
    "                    rrc += 1\n",
    "                # print(raw_1.info['ch_names'][row], raw_1.info['ch_names'][col])\n",
    "\n",
    "    print(f\"{GROUP1}: \",mapping[i], \"left region: \", lr, \"right region: \", rr, \"proportion: \", lr/rr)\n",
    "    print(f\"{GROUP2}: \", mapping[i], \"left region: \", lrc, \"right region: \", rrc, \"proportion: \", lrc/rrc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Difference matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_index(channels_list, raw):\n",
    "    indexes = []\n",
    "    for channel in channels_list:\n",
    "        for i in range(len(raw.info['ch_names'])):\n",
    "            if raw.info['ch_names'][i]==channel:\n",
    "                indexes.append(i)\n",
    "    return(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_channels = return_index(['Pz', 'Oz', 'Fz', 'Cz'], raw_1)\n",
    "central_channels\n",
    "raw_1.info['bads'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL_CHANNELS = np.array(['P8', 'T8', 'CP6', 'FC6', 'F8', 'F4', 'C4', 'P4', 'AF4', 'Fp2',\n",
    "#        'Fp1', 'AF3', 'Fz', 'FC2', 'Cz', 'CP2', 'PO3', 'O1', 'Oz', 'O2',\n",
    "#        'PO4', 'Pz', 'CP1', 'FC1', 'P3', 'C3', 'F3', 'F7', 'FC5', 'CP5',\n",
    "#        'T7', 'P7'])\n",
    "# def set_montage(raw):\n",
    "#     mont1020 = mne.channels.make_standard_montage('standard_1020')\n",
    "#     ind = [i for (i, channel) in enumerate(mont1020.ch_names) if channel in ALL_CHANNELS]\n",
    "#     mont1020_new = mont1020.copy()\n",
    "#     mont1020_new.ch_names = [mont1020.ch_names[x] for x in ind]\n",
    "#     kept_channel_info = [mont1020.dig[x+3] for x in ind]\n",
    "#     mont1020_new.dig = mont1020.dig[0:3]+kept_channel_info\n",
    "#     print(\"sjkghdkgu\", mont1020_new)\n",
    "#     return raw.set_montage(mont1020_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using notebook 3d backend.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe7a96b407e41a691e680d3a1706fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', layout=Layout(margin='2px 0px 2px 0px', min_width='0px'), placeholder='Type a fi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "difference_matrix = {}\n",
    "for i in range(len(freq_bands)):\n",
    "    difference_matrix[mapping[i]] = binarized_matrix[f'{GROUP2}-{mapping[i]}'].astype(int) - binarized_matrix[f'{GROUP1}-{mapping[i]}'].astype(int) \n",
    "    # difference_matrix[mapping[i]] = binarized_matrix[f'{GROUP1}-{mapping[i]}'].astype(int) - binarized_matrix[f'{GROUP2}-{mapping[i]}'].astype(int) \n",
    "    for k in range(n_channels):\n",
    "        for l in range(n_channels):\n",
    "            if difference_matrix[mapping[i]][k][l] == -1 or k in central_channels or l in central_channels:\n",
    "                difference_matrix[mapping[i]][k][l] = 0\n",
    "\n",
    "    # Yellow - Higher synchronisation\n",
    "    # plt.imshow(difference_matrix[mapping[i]], interpolation='none')\n",
    "    # plt.title(f'Functional connectivity - {[mapping[i]]} - Visualization')\n",
    "    # plt.xticks([_ for _ in range(n_channels)], raw_1.info['ch_names'], rotation='vertical')\n",
    "    # plt.yticks([_ for _ in range(n_channels)], raw_1.info['ch_names'], rotation='horizontal')\n",
    "    # plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    # plt.show()\n",
    "\n",
    "    plot_sensors_connectivity(\n",
    "        raw_1.info,\n",
    "        difference_matrix[mapping[i]],\n",
    "        cbar_label=f'{mapping[i]}-Connectivity',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nilearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnilearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plotting\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnilearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnectome\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConnectivityMeasure\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnilearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmaskers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiNiftiLabelsMasker\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nilearn'"
     ]
    }
   ],
   "source": [
    "conn_measure = ConnectivityMeasure(kind='coherence', sfreq=raw.info['sfreq'])\n",
    "\n",
    "# Compute connectivity for each frequency band\n",
    "connectivity_matrices, freqs, times, n_epochs, n_tapers = conn_measure.fit_transform([raw])\n",
    "\n",
    "for i, freq_band in enumerate(freq_bands):\n",
    "    plt.imshow(connectivity_matrices[0, i, :, :], cmap='viridis', aspect='auto', extent=[times[0], times[-1], freqs[0], freqs[-1]])\n",
    "    plt.title(f'Connectivity Matrix ({freq_band[0]}-{freq_band[1]} Hz)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'delta': ['C3'], 'theta': ['O2', 'FC1', 'C3', 'T7'], 'alpha1': ['C3'], 'alpha2': []}\n"
     ]
    }
   ],
   "source": [
    "selected_channels = {}\n",
    "for i in range(len(freq_bands)):\n",
    "    selected_channels[mapping[i]] = []\n",
    "    for ch in range(32):\n",
    "        # TODO: instead of number of edges wise, we can explore other algorithm\n",
    "        if len(nx.from_numpy_array(difference_matrix[mapping[i]]).edges(ch)) > 8:\n",
    "            selected_channels[mapping[i]].append(raw_1.info['ch_names'][ch])\n",
    "print(selected_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary of Regions in brain vs channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionvschannel = {\n",
    "    'LC': ['C3', 'CP1', 'CP5', 'FC1', 'FC5'], # Left central \n",
    "    'LF': ['FP1', 'AF3', 'F3', 'F7'], # Left frontal\n",
    "    'LT': ['T7'], # Left temporal\n",
    "    'LPO': ['PO3',  'P3', 'P7', 'O1'], # Left parietal-occipital\n",
    "    'RC': ['CP6', 'FC6', 'C4', 'FC2', 'CP2',], # Right central \n",
    "    'RF': ['F8', 'F4', 'AF4', 'FP2'], # Right frontal\n",
    "    'RT': ['T8'], # Right temporal\n",
    "    'RPO': ['P8', 'P4', 'PO4', 'O2'] , # Right parietal-occipital\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(freq_bands)):\n",
    "selected_regions = {}\n",
    "# selected_regions['alpha2'] = ['RPO', 'LT', 'LF', 'LC']\n",
    "# selected_regions['alpha1'] = ['LT', 'LC', 'LF', 'RPO'] # 1 in RPO\n",
    "# selected_regions['theta'] = ['LC', 'LF'] # 1 in LC and 1 in LF\n",
    "# selected_regions['delta'] =  ['LF', 'LC', 'RF', 'RC'] # 1-1 in 'LC', 'RF', 'RC'\n",
    "selected_regions['delta'] =  ['LF', 'LC', 'RT']\n",
    "selected_regions['theta'] = ['LPO', 'LC', 'RPO']\n",
    "selected_regions['alpha1'] = ['LPO', 'RPO']\n",
    "selected_regions['alpha2'] = ['LC', 'RPO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Network Metrics for selected regions for selected bands\n",
    "\n",
    "\n",
    "Boxplot helps in reading median, interquartile range and outliers\n",
    "Box : middle 50% of all data lies (Interquartile range)\n",
    "Lower end: 1st quartile\n",
    "Upper end: 3rd quartile\n",
    "Solid line: Median\n",
    "Dashed line: Mean\n",
    "T shaped whiskers: Last point 1.5 times the interquartile range (max and min without outliers)\n",
    "Points: Further out are outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_measures = ['Lw', 'NBC', 'Eglo', 'CC', 'Eloc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_avergae_components(G):\n",
    "#     connected_components = list(nx.connected_components(G))\n",
    "#     component_avg_lengths = []\n",
    "#     component_nbc_values = []\n",
    "#     component_eglo_values = []\n",
    "#     component_cc_values = []\n",
    "#     component_eloc_values = []\n",
    "\n",
    "#     for component in connected_components:\n",
    "#         subgraph = G.subgraph(component)\n",
    "#         component_avg_lengths.append(nx.average_shortest_path_length(subgraph))\n",
    "#         component_nbc_values.append(nx.betweenness_centrality(subgraph))\n",
    "#         component_eglo_values.append(nx.global_efficiency(subgraph))\n",
    "#         component_cc_values.append(nx.clustering(subgraph))\n",
    "#         component_eloc_values.append(nx.local_efficiency(subgraph))\n",
    "\n",
    "#     merged_nbc_values = {}\n",
    "#     for dnbc in component_nbc_values:\n",
    "#         merged_nbc_values.update(dnbc)\n",
    "#     merged_nbc_values = dict(sorted(merged_nbc_values.items(), key=lambda item: item[0]))\n",
    "#     merged_cc_values = {}\n",
    "#     for dcc in component_cc_values:\n",
    "#         merged_cc_values.update(dcc)\n",
    "#     merged_cc_values = dict(sorted(merged_cc_values.items(), key=lambda item: item[0]))\n",
    "\n",
    "#     overall_avg_length = sum(component_avg_lengths) / len(component_avg_lengths)\n",
    "#     overall_eglo_values = sum(component_eglo_values) / len(component_eglo_values)\n",
    "#     overall_eloc_values = sum(component_eloc_values) / len(component_eloc_values)\n",
    "\n",
    "#     return [overall_avg_length, merged_nbc_values, overall_eglo_values, merged_cc_values, overall_eloc_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, {11: 0.0, 26: 0.0, 27: 0.0}, 0.0, 0.0, 0.0] fdhgjgdfjd [0.0, {11: 0.0, 26: 0.0, 27: 0.0}, 0.0, 0.0, 0.0]\n",
      "******** [0.0, {11: 0.0, 26: 0.0, 27: 0.0}, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m********\u001b[39m\u001b[38;5;124m\"\u001b[39m, MDD_list)\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMDD_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(MDD_list[_][\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mdict\u001b[39m()):\n\u001b[0;32m     36\u001b[0m             x \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "# Integration metrics - Lavg, Eglo \n",
    "# Segregation metrics - CC, Eloc, Nbc\n",
    "import seaborn as sns\n",
    "for i in range(len(freq_bands)):\n",
    "    selected_region = selected_regions[mapping[i]]\n",
    "\n",
    "    if selected_region == []:\n",
    "        continue\n",
    "\n",
    "    # con_MDD = connectivity_matrix(epochs_1, i)\n",
    "    # con_control = connectivity_matrix(epochs_2, i)\n",
    "    G_MDD = nx.from_numpy_array(binarized_matrix[f'{GROUP1}-{mapping[i]}'])\n",
    "    G_Control = nx.from_numpy_array(binarized_matrix[f'{GROUP2}-{mapping[i]}'])\n",
    "\n",
    "    for region in selected_region:\n",
    "        channels_list = regionvschannel[region]\n",
    "        G_sub = G_MDD.subgraph(return_index(channels_list, raw_1))\n",
    "        MDD_list = calculate_avergae_components(G_sub)\n",
    "        G_sub = G_Control.subgraph(return_index(channels_list, raw_2))\n",
    "        control_list = calculate_avergae_components(G_sub)\n",
    "\n",
    "        print(MDD_list, \"fdhgjgdfjd\", control_list)\n",
    "\n",
    "        # CHECK HERE if keys in MDD_list[1] matches with keys in control_list[1]\n",
    "        # and keys in MDD_list[3] matches with keys in control_list[3]\n",
    "        \n",
    "        values_MDD = []\n",
    "        values_control = []\n",
    "        group_labels_MDD = []\n",
    "        group_labels_control = [] \n",
    "\n",
    "        for _ in range(5):\n",
    "            print(\"********\", MDD_list)\n",
    "            if len(MDD_list[_]):\n",
    "                if type(MDD_list[_][0]) == type(dict()):\n",
    "                    x = []\n",
    "                    for __ in range(len(MDD_list[_])):\n",
    "                        for k,v in MDD_list[_][__].items():\n",
    "                            x.append(v)\n",
    "                    values_MDD.append(x)\n",
    "                else:\n",
    "                    values_MDD.append(MDD_list[_])\n",
    "            else:\n",
    "                values_MDD.append([])\n",
    "            if (control_list[_]):\n",
    "                if type(control_list[_][0]) == type(dict()):\n",
    "                    y = []\n",
    "                    for __ in range(len(control_list[_])):\n",
    "                        for k,v in control_list[_][__].items():\n",
    "                            y.append(v)\n",
    "                    values_control.append(y)\n",
    "                else:\n",
    "                    values_control.append(control_list[_])\n",
    "            else:\n",
    "                values_control.append([])\n",
    "            group_labels_MDD.append(f'{GROUP1}-{group_measures[_]}')\n",
    "            group_labels_control.append(f'{GROUP2}-{group_measures[_]}')\n",
    "            \n",
    "        values_all = values_1 + values_control\n",
    "        group_labels = group_labels_MDD + group_labels_control\n",
    "\n",
    "        print(\"values all\", values_all)\n",
    "        print(\"group labels\", group_labels)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.boxplot(values_all, labels=group_labels, vert=True)\n",
    "        plt.title(f'Boxplot of Network Metrics for MDD and Control Groups in {mapping[i]} band in {region} region')\n",
    "        plt.xlabel('Network Metrics')\n",
    "        plt.ylabel('Values')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Mark all regions in brain along with Netowrk metrics which are significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Find relationship between \"these\" Network Metrics and PHQ-9 scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. For further evaluation: RF based on ensemble learning, SVM, KNN, ANN with 10-fold cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
