{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=32, n_times=74999\n",
      "    Range : 0 ... 74998 =      0.000 ...   149.996 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "%run E:\\IITD\\Depression-IITD\\common.ipynb\n",
    "%run E:\\IITD\\Depression-IITD\\preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PRE VS CONTROL\n",
    "# raw_MDD = mne.io.read_raw_fif(\"loadData/rawMDDpre5.fif\")\n",
    "# raw_control = mne.io.read_raw_fif(\"loadData/rawControlOnline104.fif\")\n",
    "\n",
    "# epochs_MDD = mne.read_epochs(\"loadData/epochsMDDpre5.fif\", preload=False)\n",
    "# epochs_control = mne.read_epochs(\"loadData/epochsControlOnline104.fif\", preload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file loadData/rawMDDpre5.fif...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 32) active\n",
      "    Range : 0 ... 74998 =      0.000 ...   149.996 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\2280852796.py:2: RuntimeWarning: This filename (loadData/rawMDDpre5.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw_MDD = mne.io.read_raw_fif(\"loadData/rawMDDpre5.fif\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file loadData/rawMDDpost5.fif...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 32) active\n",
      "    Range : 0 ... 74998 =      0.000 ...   149.996 secs\n",
      "Ready.\n",
      "Reading e:\\IITD\\Depression-IITD\\loadData\\epochsMDDpre5.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 32) active\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    4000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "73 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Reading e:\\IITD\\Depression-IITD\\loadData\\epochsMDDpost5.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 32) active\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    4000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\2280852796.py:3: RuntimeWarning: This filename (loadData/rawMDDpost5.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw_control = mne.io.read_raw_fif(\"loadData/rawMDDpost5.fif\")\n",
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\2280852796.py:5: RuntimeWarning: This filename (loadData/epochsMDDpre5.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs_MDD = mne.read_epochs(\"loadData/epochsMDDpre5.fif\", preload=False)\n",
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\2280852796.py:6: RuntimeWarning: This filename (loadData/epochsMDDpost5.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs_control = mne.read_epochs(\"loadData/epochsMDDpost5.fif\", preload=False)\n"
     ]
    }
   ],
   "source": [
    "# PRE VS POST\n",
    "raw_MDD = mne.io.read_raw_fif(\"loadData/rawMDDpre5.fif\")\n",
    "raw_control = mne.io.read_raw_fif(\"loadData/rawMDDpost5.fif\")\n",
    "\n",
    "epochs_MDD = mne.read_epochs(\"loadData/epochsMDDpre5.fif\", preload=False)\n",
    "epochs_control = mne.read_epochs(\"loadData/epochsMDDpost5.fif\", preload=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # POST vs Control\n",
    "# raw_MDD = mne.io.read_raw_fif(\"loadData/rawMDDpost5.fif\")\n",
    "# raw_control = mne.io.read_raw_fif(\"loadData/rawControlOnline104.fif\")\n",
    "\n",
    "# epochs_MDD = mne.read_epochs(\"loadData/epochsMDDpost5.fif\", preload=False)\n",
    "# epochs_control = mne.read_epochs(\"loadData/epochsControlOnline104.fif\", preload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avergae_components(G):\n",
    "    connected_components = list(nx.connected_components(G))\n",
    "    component_avg_lengths = []\n",
    "    component_nbc_values = []\n",
    "    component_eglo_values = []\n",
    "    component_cc_values = []\n",
    "    component_eloc_values = []\n",
    "\n",
    "    for component in connected_components:\n",
    "        subgraph = G.subgraph(component)\n",
    "        component_avg_lengths.append(nx.average_shortest_path_length(subgraph))\n",
    "        component_nbc_values.append(nx.betweenness_centrality(subgraph))\n",
    "        component_eglo_values.append(nx.global_efficiency(subgraph))\n",
    "        component_cc_values.append(nx.average_clustering(subgraph))\n",
    "        component_eloc_values.append(nx.local_efficiency(subgraph))\n",
    "\n",
    "    merged_nbc_values = {}\n",
    "    for dnbc in component_nbc_values:\n",
    "        merged_nbc_values.update(dnbc)\n",
    "    merged_nbc_values = dict(sorted(merged_nbc_values.items(), key=lambda item: item[0]))\n",
    "    # merged_cc_values = {}\n",
    "    # for dcc in component_cc_values:\n",
    "    #     merged_cc_values.update(dcc)\n",
    "    # merged_cc_values = dict(sorted(merged_cc_values.items(), key=lambda item: item[0]))\n",
    "\n",
    "    overall_avg_length = sum(component_avg_lengths) / len(component_avg_lengths)\n",
    "    overall_eglo_values = sum(component_eglo_values) / len(component_eglo_values)\n",
    "    overall_cc_values = sum(component_cc_values) / len(component_cc_values)\n",
    "    overall_eloc_values = sum(component_eloc_values) / len(component_eloc_values)\n",
    "\n",
    "    return [overall_avg_length, merged_nbc_values, overall_eglo_values, overall_cc_values, overall_eloc_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELSE COMPUTE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MDD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eye_close_MDD = []\n",
    "eye_close_1 = '\\\\Depression-Sample-dataset-AIIMS\\\\Active\\\\PreetiSingh\\\\pre\\\\' + '20230718201550_Preeti singh_22.08.23-01_Eye Close'\n",
    "eye_close_2 = '\\\\Depression-Sample-dataset-AIIMS\\\\Active\\\\Hemlata\\\\pre\\\\' + '20230831105330_Hemlata_05.10.23_01_Eye Close'\n",
    "eye_close_3 = '\\\\Depression-Sample-dataset-AIIMS\\\\Active\\\\VinodKumarSharma\\\\pre\\\\' + '20230829195416_VinodKumarSharma_25.9.23_01_Eye Close'\n",
    "eye_close_4 = '\\\\Depression-Sample-dataset-AIIMS\\\\Sham\\\\JitenderKumar\\\\pre\\\\' + '20230825020227_JitenderKumar_29.08.23_01_Eye Close'\n",
    "eye_close_5 = '\\\\Depression-Sample-dataset-AIIMS\\\\Sham\\\\SeemaKumari\\\\pre\\\\' + '20230827073914_SeemaKumari_11.09.23_01_Eye Close'\n",
    "# eye_close_6 = '\\\\Depression-Sample-dataset-AIIMS\\\\Active\\\\PreetiSingh\\\\post\\\\' + '20230826225729_PreetiSingh_08.09.23_20_Eye Close'\n",
    "# eye_close_7 = '\\\\Depression-Sample-dataset-AIIMS\\\\Active\\\\Hemlata\\\\post\\\\' + '20231019110530_Hemlata_19.10.23_19A_Eye Close'\n",
    "# eye_close_8 = '\\\\Depression-Sample-dataset-AIIMS\\\\Active\\\\VinodKumarSharma\\\\post\\\\' + '20230901112451_VinodKumarSharma_11.10.23_20_Eye Close'\n",
    "# eye_close_9 = '\\\\Depression-Sample-dataset-AIIMS\\\\Sham\\\\JitenderKumar\\\\post\\\\' + '20230827174115_JitenderKumar_13.09.23_20_Eye Close'\n",
    "# eye_close_10 = '\\\\Depression-Sample-dataset-AIIMS\\\\Sham\\\\SeemaKumari\\\\post\\\\' + '20230829172634_SeemaKumari_23.9.23_20_Eye Close'\n",
    "eye_close_MDD = [eye_close_1, eye_close_2, eye_close_3, eye_close_4, eye_close_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_MDD = []\n",
    "# folder_path = os.getcwd()+'\\\\Depression-Sample-dataset-AIIMS\\\\'\n",
    "for file in eye_close_MDD:\n",
    "    file_path = os.getcwd()+ eye_close_MDD[i] + '.easy'\n",
    "    raw = data_transformation_easy(file_path)\n",
    "    # raw = mne.io.read_raw_edf(file, eog=None, misc=None, stim_channel='auto', exclude=(), infer_types=False, include=None, preload=True, units=None, encoding='utf8', verbose=None)\n",
    "    # By default read_raw_edf convert units to V\n",
    "    raw = MDD_preprocess(raw)\n",
    "    raw_MDD.append(raw.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M1 : Averaging using mean:\n",
    "\n",
    "raw_MDD_avg = np.mean(raw_MDD, axis=0)\n",
    "print(raw_MDD_avg)\n",
    "\n",
    "del raw_MDD[:]\n",
    "del raw_MDD\n",
    "del eye_close_MDD[:]\n",
    "del eye_close_MDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = raw.info\n",
    "raw_MDD = mne.io.RawArray(raw_MDD_avg, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control group data (Online control group data eye closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE VS POST COMPARISON\n",
    "eye_close_6 = '\\\\Depression-Sample-dataset-AIIMS\\\\Active\\\\PreetiSingh\\\\post\\\\' + '20230826225729_PreetiSingh_08.09.23_20_Eye Close'\n",
    "eye_close_7 = '\\\\Depression-Sample-dataset-AIIMS\\\\Active\\\\Hemlata\\\\post\\\\' + '20231019110530_Hemlata_19.10.23_19A_Eye Close'\n",
    "eye_close_8 = '\\\\Depression-Sample-dataset-AIIMS\\\\Active\\\\VinodKumarSharma\\\\post\\\\' + '20230901112451_VinodKumarSharma_11.10.23_20_Eye Close'\n",
    "eye_close_9 = '\\\\Depression-Sample-dataset-AIIMS\\\\Sham\\\\JitenderKumar\\\\post\\\\' + '20230827174115_JitenderKumar_13.09.23_20_Eye Close'\n",
    "eye_close_10 = '\\\\Depression-Sample-dataset-AIIMS\\\\Sham\\\\SeemaKumari\\\\post\\\\' + '20230829172634_SeemaKumari_23.9.23_20_Eye Close'\n",
    "eye_close_control = [eye_close_6, eye_close_7, eye_close_8, eye_close_9, eye_close_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE VS POST COMPARISON\n",
    "raw_control = []\n",
    "# folder_path = os.getcwd()+'\\\\Depression-Sample-dataset-AIIMS\\\\'\n",
    "for file in eye_close_control:\n",
    "    file_path = os.getcwd()+ file + '.easy'\n",
    "    raw = data_transformation_easy(file_path)\n",
    "    # raw = mne.io.read_raw_edf(file, eog=None, misc=None, stim_channel='auto', exclude=(), infer_types=False, include=None, preload=True, units=None, encoding='utf8', verbose=None)\n",
    "    # By default read_raw_edf convert units to V\n",
    "    raw = MDD_preprocess(raw)\n",
    "    raw_control.append(raw.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE VS POST COMPARISON\n",
    "# M1 : Averaging using mean:\n",
    "raw_control_avg = np.mean(raw_control, axis=0)\n",
    "print(raw_control_avg)\n",
    "\n",
    "del raw_control[:]\n",
    "del raw_control\n",
    "del eye_close_control[:]\n",
    "del eye_close_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE VS POST COMPARISON\n",
    "info = raw.info\n",
    "raw_control = mne.io.RawArray(raw_control_avg, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find control indexes\n",
    "# file_path = os.getcwd() + '\\\\Depression-Sample-dataset-AIIMS\\\\' + 'Control\\\\' + 'derivatives\\\\cleaned_epochs\\\\'\n",
    "# control_indexes = []\n",
    "# for i in range(0, 111):\n",
    "#     eeg_file_epoch = file_path + f'sub-{i+1:03d}\\\\ses-t1\\\\eeg\\\\sub-{i+1:03d}_ses-t1_task-resteyesc_desc-epochs_eeg.set'\n",
    "#     epochs_data = mne.io.read_epochs_eeglab(eeg_file_epoch, events=None, event_id=None, eog=(), uint16_codec=None, montage_units='mm', verbose=None)\n",
    "#     if len(epochs_data.get_data()) == 55:\n",
    "#         control_indexes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = os.getcwd() + '\\\\Depression-Sample-dataset-AIIMS\\\\' + 'Control\\\\'\n",
    "# raw_control = []\n",
    "# for i in control_indexes:\n",
    "#     eeg_file_raw = file_path + f'sub-{i+1:03d}\\\\ses-t1\\\\eeg\\\\sub-{i+1:03d}_ses-t1_task-resteyesc_eeg.edf'\n",
    "#     raw = mne.io.read_raw_edf(eeg_file_raw, eog=None, misc=None, stim_channel='auto', exclude=(), infer_types=False, include=None, preload=False, units=None, encoding='utf8', verbose=None)\n",
    "#     # By default read_raw_edf convert units to V\n",
    "#     raw = control_preprocessing(raw, raw_MDD)\n",
    "#     raw_control.append(raw.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del control_indexes[:]\n",
    "# del control_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_control_avg = np.mean(raw_control, axis=0)\n",
    "\n",
    "# del raw_control[:]\n",
    "# del raw_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info = raw.info\n",
    "# raw_control = mne.io.RawArray(raw_control_avg, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Raw MDD and control data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_MDD.save(\"loadData/rawMDDpre5.fif\", overwrite=True)\n",
    "# raw_control.save(\"loadData/rawMDDpost5.fif\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 4.0\n",
    "overlap = 2.0 \n",
    "\n",
    "samples_per_epoch = int(duration * SFREQ)\n",
    "samples_per_overlap = int(overlap * SFREQ)\n",
    "\n",
    "# Manually created events\n",
    "start, stop = 0, samples_per_epoch\n",
    "events = []\n",
    "while stop <= len(raw_MDD):\n",
    "    events.append([start, 0, 1]) \n",
    "    start += samples_per_overlap\n",
    "    stop += samples_per_overlap\n",
    "\n",
    "events = np.array(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Segmenting epochs for MDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_MDD = mne.Epochs(raw_MDD, events, tmin=0, tmax=duration, baseline=None, detrend=1,\n",
    "                    picks=None, preload=True, reject=None)\n",
    "raw_MDD.plot(n_channels=len(raw_MDD.info['ch_names']), events=events, event_color={1:'r'}, scalings=SCALINGS)\n",
    "epochs_MDD.plot(n_channels=len(raw_MDD.info['ch_names']), event_color={1:'r'}, events=None, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Segmenting epochs for control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_control = mne.Epochs(raw_control, events, tmin=0, tmax=duration, baseline=None, detrend=1,\n",
    "                    picks=None, preload=True, reject=None)\n",
    "raw_control.plot(n_channels=len(raw_MDD.info['ch_names']), events=events, event_color={1:'r'}, scalings=SCALINGS)\n",
    "epochs_control.plot(n_channels=len(raw_MDD.info['ch_names']), event_color={1:'r'}, events=None, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = os.getcwd() + '\\\\Depression-Sample-dataset-AIIMS\\\\' + 'Control\\\\' + 'derivatives\\\\cleaned_epochs\\\\'\n",
    "# epochs_control = []\n",
    "# for i in range(0, 111):\n",
    "#     eeg_file_epoch = file_path + f'sub-{i+1:03d}\\\\ses-t1\\\\eeg\\\\sub-{i+1:03d}_ses-t1_task-resteyesc_desc-epochs_eeg.set'\n",
    "#     epochs_data = mne.io.read_epochs_eeglab(eeg_file_epoch, events=None, event_id=None, eog=(), uint16_codec=None, montage_units='mm', verbose=None)\n",
    "#     if len(epochs_data.get_data()) == 55:\n",
    "#         cleaned_epoch = control_preprocessing(epochs_data, epochs_MDD, crop=False)\n",
    "#         epochs_control.append(cleaned_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_control_avg = np.mean(epochs_control, axis=0)\n",
    "# print(epochs_control_avg)\n",
    "\n",
    "# del epochs_control[:]\n",
    "# del epochs_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info = cleaned_epoch.info\n",
    "# epochs_control = mne.EpochsArray(epochs_control_avg, info)\n",
    "# epochs_control.plot(n_channels=len(raw_MDD.info['ch_names']), event_color={1:'r'}, events=None, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving epoched raw and control data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_MDD.save(\"loadData/epochsMDDpre5.fif\", overwrite=True)\n",
    "# epochs_control.save(\"loadData/epochsMDDpost5.fif\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. PSD graph plot between MDD and Control group\n",
    "\n",
    "For resting state EEG channel, analyzing the overall average power across channels provides a holistic view of the brain's activity without emphasizing the specificity of individual channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wavelet_plot(raw1, raw2, title):\n",
    "#     '''\n",
    "#     signal ----> breaks into frequency components/scales ----> WT computes coeffcients that represent signal's content \n",
    "#     at a specific scale ----->coeffs at lower level represent lower frequency components\n",
    "     \n",
    "#     Scales vs frequencies - lower scale = higher frequency (fine details)\n",
    "#     larger coefficient represents higher energy at a sepcific scale\n",
    "#     peaks in scale vs time plot = where energy is concentrated\n",
    "#     broad distribution across scales = mix of frequencies\n",
    "\n",
    "#     Find frequency component of interest \n",
    "#     Step1: Look for peaks (dominant frequencies)\n",
    "#     Step2: Convert scale to frequency using frequency = SFREQ/(2**scale)\n",
    "#     Step 3: Compare across time\n",
    "#     Step 4: Statistical analysis\n",
    "\n",
    "#     '''\n",
    "#     # Average channel wavelet transform\n",
    "#     raw1_avg = np.mean(raw1.get_data(), axis=0)\n",
    "#     raw2_avg = np.mean(raw2.get_data(), axis=0)\n",
    "\n",
    "#     # Individual channels wavelet transform\n",
    "#     t = np.arange(0, 150, 1/SFREQ)\n",
    "#     ts = t[:-1]\n",
    "    \n",
    "#     wavelet = 'db13'\n",
    "#     level = 4 # level of decomposition based on your signal characteristics\n",
    " \n",
    "#     coeffs1 = pywt.wavedec(raw1_avg, wavelet, level=level)    \n",
    "#     coeffs2 = pywt.wavedec(raw2_avg, wavelet, level=level)\n",
    "\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     for i in range(level+1):\n",
    "#         if i==0:\n",
    "#             plt.plot(t, raw1_avg, label='MDD raw')\n",
    "#         plt.plot(t, pywt.upcoef('a', coeffs1[i], wavelet, level=level)[:len(t)], label=f'MDD - Level {i}')\n",
    "#         if i==0:\n",
    "#             plt.plot(t, raw2_avg, label='Control raw')\n",
    "#         plt.plot(t, pywt.upcoef('a', coeffs2[i], wavelet, level=level)[:len(t)], label=f'Control - Level {i}')\n",
    "#         plt.title('DWT')\n",
    "#         plt.xlabel('Time')\n",
    "#         plt.ylabel('Amplitude')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "\n",
    "# wavelet_plot(raw_MDD, raw_control, \"gjhggj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    }
   ],
   "source": [
    "# Amplitude plots between both groups\n",
    "epochs_MDD_avg = epochs_MDD['1'].average()\n",
    "epochs_control_avg = epochs_control['1'].average()\n",
    "# evokeds = dict(epochs_MDD=epochs_MDD)\n",
    "fig_MDD = epochs_MDD_avg.plot(titles='MDD', time_unit = 'ms')\n",
    "fig_control = epochs_control_avg.plot(titles='control', time_unit = 'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 PSD using plot_psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().\n",
      "Effective window size : 4.096 (s)\n",
      "NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().\n",
      "Effective window size : 4.096 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "#plot_psd uses welch method for continuous data\n",
    "raw_MDD.plot_psd(picks=raw_MDD.info['ch_names'], average=True, fmin=FMIN, fmax=FMAX, ax=ax, show=False, color='blue', dB=False)\n",
    "raw_control.plot_psd(picks=raw_control.info['ch_names'], average=True, fmin=FMIN, fmax=FMAX, ax=ax, show=False, color='red', dB=False)\n",
    "\n",
    "# dB = True plots PSD in decibels (logarithmic)\n",
    "# different n_fft compared to psd_array_welch\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Power/Frequency (microV^2/Hz)')\n",
    "ax.set_title('Power Spectral Density Comparison')\n",
    "ax.legend() \n",
    "plt.ylim(0, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Average of power using welch method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.512 (s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.512 (s)\n"
     ]
    }
   ],
   "source": [
    "labels = np.arange(0, FMAX)\n",
    "# welch always gives positive psd\n",
    "psd_MDD, frequencies = mne.time_frequency.psd_array_welch(raw_MDD.get_data(), fmin=FMIN, fmax=FMAX, sfreq=SFREQ)\n",
    "psd_control, frequencies = mne.time_frequency.psd_array_welch(raw_control.get_data(), fmin=FMIN, fmax=FMAX, sfreq=SFREQ)\n",
    "avg_abs_power_MDD, avg_abs_power_control = np.mean(psd_MDD, axis=0), np.mean(psd_control, axis=0) \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(frequencies, avg_abs_power_MDD, color='blue')\n",
    "plt.plot(frequencies, avg_abs_power_control, color='red')\n",
    "plt.title('Welch - Average Power-blue(MDD)-red(Control)')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.xticks(labels, labels, rotation ='vertical') \n",
    "plt.ylabel('Power (V^2/Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Statistical testing between psds of raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.1 Plotting Histogram\n",
    "\n",
    "Shows if the data is bell shaped, skewed (positive or negative), uniform etc. Central tendency - highest peak in histogram. Spread - width of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDD_avg = np.mean(raw_MDD.get_data(), axis=0)\n",
    "plt.hist(MDD_avg, bins='auto', alpha=0.7, edgecolor='black')\n",
    "plt.title(f'Histogram of MDD Data - averaged across all channels')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_avg = np.mean(raw_control.get_data(), axis=0)\n",
    "plt.hist(control_avg, bins='auto', alpha=0.7, edgecolor='black')\n",
    "plt.title(f'Histogram of control Data - averaged across all channels')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDD mean:  -2.0070764813061382e-16\n",
      "Control mean:  1.0924363901150833e-15\n"
     ]
    }
   ],
   "source": [
    "print(\"MDD mean: \", np.mean(MDD_avg, axis=0))\n",
    "print(\"Control mean: \", np.mean(control_avg, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.2 Calculate variance of both groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDD variance:  6.2507817976989105e-24\n",
      "Control variance:  1.5712764319411083e-23\n"
     ]
    }
   ],
   "source": [
    "variance_MDD = np.var(psd_MDD, ddof=1) \n",
    "variance_control = np.var(psd_control, ddof=1)\n",
    "print(\"MDD variance: \", variance_MDD)\n",
    "print(\"Control variance: \", variance_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.3 Find differences between the means of two independent groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, null hypothesis: there is no significant difference between groups (ie means are equal).\n",
    "alternative hypothesis: there is a significant difference between groups\n",
    "t-test : compares the differences between group means to expected variability in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data PSD Comparison Results:\n",
      "T-statistic: [-0.49523536  0.14744193 -0.31393649 -0.97294841 -0.01139994 -0.297804\n",
      "  0.36400093 -0.83812901 -0.05735324  0.05408089 -0.15951497  0.16853522\n",
      "  0.88251566  0.64645463  0.0807843   0.15865084  1.73768353 -0.68993094\n",
      "  1.50677987  1.57381697  0.9410575  -0.72802323  0.75261838 -0.74717936\n",
      " -0.9011082  -0.75598126  0.50658117  0.48093111 -0.16564691  1.53928994\n",
      "  0.36200718  0.94130491]\n",
      "P-values: [0.62289827 0.88345677 0.7550529  0.33589763 0.99095589 0.76725444\n",
      " 0.71760068 0.40648827 0.95452348 0.95711553 0.87399316 0.8669346\n",
      " 0.3822942  0.52134289 0.93597984 0.87466993 0.08926211 0.49386072\n",
      " 0.13901363 0.1226937  0.35181353 0.47045615 0.45568713 0.45892976\n",
      " 0.37243687 0.45368895 0.61497796 0.63294841 0.8691936  0.13089495\n",
      " 0.71907953 0.35168819]\n"
     ]
    }
   ],
   "source": [
    "p_values = np.zeros(32)\n",
    "t = np.zeros(32)\n",
    "for i in range(32):\n",
    "    t[i], p_values[i] = ttest_ind(psd_MDD[i, :], psd_control[i, :])\n",
    "# independent t-test comparison : equal_var = True\n",
    "# welch's t-test comparison: equal_var = False\n",
    "print(\"Raw Data PSD Comparison Results:\")\n",
    "print(\"T-statistic:\", t)\n",
    "print(\"P-values:\", p_values) # probability of getting t-statistic >= what we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data PSD Comparison Results:\n",
      "T-statistic: -0.03914189465736664\n",
      "P-values: 0.9689746759463302\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_values = ttest_ind(np.mean(psd_MDD, axis=0), np.mean(psd_control, axis=0), equal_var=False)\n",
    "# independent t-test comparison : equal_var = True\n",
    "# welch's t-test comparison: equal_var = False\n",
    "print(\"Raw Data PSD Comparison Results:\")\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-values:\", p_values) # probability of getting t-statistic >= what we got"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If p value < 0.005, we reject the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PLI and construction of brain function matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_bands = [(0.01, 4), (4,8), (8, 10), (10, 13)]\n",
    "mapping = {0: 'delta', 1: 'theta', 2: 'alpha1', 3:'alpha2'}\n",
    "connectivity = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pli method always gives positive correlations\n",
    "def connectivity_matrix(epochs, i):\n",
    "    return spectral_connectivity_epochs(\n",
    "    epochs, method='pli', mode='multitaper', sfreq=SFREQ,\n",
    "    fmin=freq_bands[i][0], fmax=freq_bands[i][1], faverage=True, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 73 events and 2001 original time points ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(epochs_MDD.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 0.2Hz..4.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  73 events (all good), 0 – 4 s, baseline off, ~47 kB, data not loaded,\n",
      " '1': 73>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n",
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\1345682627.py:3: RuntimeWarning: fmin=0.010 Hz corresponds to 0.040 < 5 cycles based on the epoch length 4.002 sec, need at least 500.000 sec epochs or fmin=1.249. Spectrum estimate will be unreliable.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 0.2Hz..4.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  72 events (all good), 0 – 4 s, baseline off, ~47 kB, data not loaded,\n",
      " '1': 72>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n",
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\1345682627.py:3: RuntimeWarning: fmin=0.010 Hz corresponds to 0.040 < 5 cycles based on the epoch length 4.002 sec, need at least 500.000 sec epochs or fmin=1.249. Spectrum estimate will be unreliable.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 4.2Hz..8.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  73 events (all good), 0 – 4 s, baseline off, ~47 kB, data not loaded,\n",
      " '1': 73>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 4.2Hz..8.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  72 events (all good), 0 – 4 s, baseline off, ~47 kB, data not loaded,\n",
      " '1': 72>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 8.2Hz..10.0Hz (8 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  73 events (all good), 0 – 4 s, baseline off, ~47 kB, data not loaded,\n",
      " '1': 73>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 8.2Hz..10.0Hz (8 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  72 events (all good), 0 – 4 s, baseline off, ~47 kB, data not loaded,\n",
      " '1': 72>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 10.2Hz..13.0Hz (12 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  73 events (all good), 0 – 4 s, baseline off, ~47 kB, data not loaded,\n",
      " '1': 73>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 10.2Hz..13.0Hz (12 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\1345682627.py:3: RuntimeWarning: There were no Annotations stored in <EpochsFIF |  72 events (all good), 0 – 4 s, baseline off, ~47 kB, data not loaded,\n",
      " '1': 72>, so metadata was not modified.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n"
     ]
    }
   ],
   "source": [
    "n_channels = len(raw_MDD.info['ch_names'])\n",
    "for i in range(len(freq_bands)):\n",
    "    con = connectivity_matrix(epochs_MDD, i)\n",
    "    connectivity[f'MDD-{mapping[i]}'] = con.get_data().reshape((n_channels, n_channels))\n",
    "\n",
    "    con = connectivity_matrix(epochs_control, i)\n",
    "    connectivity[f'Control-{mapping[i]}'] = con.get_data().reshape((n_channels, n_channels))\n",
    "\n",
    "    # Make matrix symmetric\n",
    "    for row in range(n_channels):\n",
    "        for col in range(n_channels):\n",
    "            connectivity[f'MDD-{mapping[i]}'][row][col] = connectivity[f'MDD-{mapping[i]}'][col][row]\n",
    "            connectivity[f'Control-{mapping[i]}'][row][col] = connectivity[f'Control-{mapping[i]}'][col][row]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical analysis using NBS to cross check frequency band of interest calculated using small world network (binarization method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(freq_bands)):\n",
    "    print()\n",
    "    # find NBS in all freq_bands \n",
    "    # Find freq band sof interest \n",
    "    # FInd mean and SD for all adjacency matrices for both groups \n",
    "    # make matrix in such a way that channels closer are together ? TODO: - 0 values in diagonal\n",
    "    # plot adjacency matrix for both groups in all bands of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['MDD-delta', 'Control-delta', 'MDD-theta', 'Control-theta', 'MDD-alpha1', 'Control-alpha1', 'MDD-alpha2', 'Control-alpha2'])\n"
     ]
    }
   ],
   "source": [
    "print((connectivity.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ALTERNATIVE: PLI calculation in Raw Python\n",
    "\n",
    "# def calculate_pli(data):\n",
    "#     # data = EEG data of channel Ci and Cj for 1 epoch (2000 data points (4s X 500fs))\n",
    "#     analytic_signal = hilbert(data)\n",
    "#     instantaneous_phase = np.angle(analytic_signal)\n",
    "#     return np.abs(np.mean(np.sign(np.diff(instantaneous_phase, axis=0))))\n",
    "\n",
    "# fun_connectivity = []\n",
    "# for k in range(len(epochs)):\n",
    "#     pli_matrix = [[0 for i in range(len(raw_cleaned.info['ch_names']))] for j in range(len(raw_cleaned.info['ch_names']))]\n",
    "#     for i in range(len(raw_cleaned.info['ch_names'])):\n",
    "#         for j in range(i+1, len(raw_cleaned.info['ch_names'])):\n",
    "#             pli_matrix[i][j] = pli_matrix[j][i] = calculate_pli([epochs[k].get_data(fmin = freq_bands[0][0], fmax=freq_bands[-1][-1])[0][i], epochs[k].get_data(fmin = freq_bands[0][0], fmax=freq_bands[-1][-1])[0][j]])\n",
    "\n",
    "#     fun_connectivity.append(pli_matrix)\n",
    "# conn = np.mean(fun_connectivity, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M1 - 4. Small World Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\523292313.py:50: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  swi_ratio_binarized =  swi_binarized_MDD/swi_binarized_control\n",
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\523292313.py:47: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  swi_binarized_MDD =  (Cw_MDD_binarized/Crand)/(Lw_MDD_binarized/Lrand)\n",
      "C:\\Users\\vishw\\AppData\\Local\\Temp\\ipykernel_19780\\523292313.py:48: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  swi_binarized_control = (Cw_control_binarized/Crand)/(Lw_control_binarized/Lrand)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.5720000000000004 (Significant) 8.317776485975295e-14\n",
      "Optimal Threshold: 0.8160000000000006 (Significant) 6.94800957753124e-05\n",
      "{'delta': 0.4340000000000003, 'theta': 0.5720000000000004, 'alpha1': 0.8160000000000006, 'alpha2': 0.8420000000000006}\n"
     ]
    }
   ],
   "source": [
    "optimal_threshold = {}\n",
    "edges_MDD = {}\n",
    "edges_control = {}\n",
    "from scipy.stats import kurtosis, zscore, ttest_ind\n",
    "\n",
    "for i in range(len(freq_bands)):\n",
    "    \n",
    "    MDD_average = calculate_avergae_components(nx.from_numpy_array(connectivity[f'MDD-{mapping[i]}']))\n",
    "    Lw_MDD = MDD_average[0]\n",
    "    Cw_MDD = MDD_average[3]\n",
    "\n",
    "    control_average = calculate_avergae_components(nx.from_numpy_array(connectivity[f'Control-{mapping[i]}']))\n",
    "    Lw_control = control_average[0]\n",
    "    Cw_control = control_average[3]\n",
    "\n",
    "\n",
    "    # Generating 50 random networks with same number of vertices and edges \n",
    "    random_networks = [nx.gnm_random_graph(n_channels, 496) for _ in range(50)]\n",
    "    # Average of clustering coefficients of all random networks and average of shortest path length of\n",
    "    # all random networks\n",
    "    Crand = np.mean([nx.average_clustering(G) for G in random_networks])\n",
    "    Lrand = np.mean([nx.average_shortest_path_length(G) for G in random_networks])\n",
    "\n",
    "    small_world_index_MDD =  (Cw_MDD/Crand)/(Lw_MDD/Lrand)\n",
    "    small_world_index_control = (Cw_control/Crand)/(Lw_control/Lrand)\n",
    "    swi_ratio = small_world_index_MDD/small_world_index_control\n",
    "\n",
    "    thresholds = np.arange(0.1, 0.9, 0.002)\n",
    "    edges_MDD[mapping[i]] = []\n",
    "    edges_control[mapping[i]] = []\n",
    "\n",
    "    ratios = []\n",
    "    for threshold in thresholds:\n",
    "        binarized_MDD = connectivity[f'MDD-{mapping[i]}'] > threshold\n",
    "        binarized_control = connectivity[f'Control-{mapping[i]}'] > threshold\n",
    "\n",
    "        edges_MDD[mapping[i]].append(nx.from_numpy_array(binarized_MDD).number_of_edges())\n",
    "        edges_control[mapping[i]].append(nx.from_numpy_array(binarized_control).number_of_edges())\n",
    "\n",
    "        # TODO: Cross check should we ignore thresholds which result in matrix to be not connected ?\n",
    "        MDD_average_binarized = calculate_avergae_components(nx.from_numpy_array(binarized_MDD))\n",
    "        Lw_MDD_binarized = MDD_average_binarized[0]\n",
    "        Cw_MDD_binarized = MDD_average_binarized[3]\n",
    "        control_average_binarized = calculate_avergae_components(nx.from_numpy_array(binarized_control))\n",
    "        Lw_control_binarized = control_average_binarized[0]\n",
    "        Cw_control_binarized = control_average_binarized[3]\n",
    "        swi_binarized_MDD =  (Cw_MDD_binarized/Crand)/(Lw_MDD_binarized/Lrand)\n",
    "        swi_binarized_control = (Cw_control_binarized/Crand)/(Lw_control_binarized/Lrand)\n",
    "        \n",
    "        swi_ratio_binarized =  swi_binarized_MDD/swi_binarized_control\n",
    "        ratios.append(swi_ratio_binarized)\n",
    "\n",
    "    optimal_threshold[mapping[i]] = thresholds[np.argmax(np.abs(ratios))] #TODO: ratios - swi_ratio\n",
    "    # OR remove swi_ratio and related code above\n",
    "\n",
    "    t_stat, p_value = ttest_ind(np.mean(connectivity[f'MDD-{mapping[i]}'], axis=0), np.mean(connectivity[f'Control-{mapping[i]}'], axis=0)) \n",
    "\n",
    "    # _, p_value = mne.stats.ttest_ind_no_p(connectivity[f'MDD-{mapping[i]}'], connectivity[f'Control-{mapping[i]}'])\n",
    "    if p_value < 0.005: # Reject the null hypotheses\n",
    "        print(f\"Optimal Threshold: {optimal_threshold[mapping[i]]} (Significant)\", p_value)\n",
    "\n",
    "    # plt.plot(thresholds, ratios, label='Threshold Ratios')\n",
    "    # plt.axhline(swi_ratio, color='red', linestyle='--', label=' SWI ratio (MDD/Control)')\n",
    "    # plt.xlabel(f'Threshold-{mapping[i]}')\n",
    "    # plt.ylabel('Ratio')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "print(optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(freq_bands)):\n",
    "#     optimal_threshold[mapping[i]]  += 0.1\n",
    "# print(optimal_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2 - 4. Community structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "import networkx as nx\n",
    "# Calculate the participation coefficient for each node\n",
    "def participation_coefficient(node, modularity_matrix):\n",
    "    k_in = np.sum(modularity_matrix[node, :])\n",
    "    k_out = np.sum(modularity_matrix) - k_in\n",
    "    q = modularity_matrix.shape[0]\n",
    "    pc = 1 - ((k_in / q) ** 2 + (k_out / q) ** 2)\n",
    "    return pc\n",
    "\n",
    "def community_structure(G):\n",
    "    # Compute community structure (Louvain algorithm)\n",
    "    partition = list(nx.algorithms.community.modularity_max.greedy_modularity_communities(G)[0])\n",
    "    # pi_scores = nx.algorithms.community.indicators.participation(G, partition)(G)\n",
    "\n",
    "    print(nx.modularity_matrix(G))\n",
    "\n",
    "    # plot network with community structure \n",
    "    # pos = nx.spring_layout(G)\n",
    "    # colors = [partition[node] for node in G.nodes]\n",
    "    # plt.figure(figsize=(10, 8))\n",
    "    # nx.draw(G, pos, node_color=colors, with_labels=True, cmap=plt.cm.Paired, node_size=300)\n",
    "    # plt.title(\"Community structure\")\n",
    "    # plt.show()\n",
    "\n",
    "    num_nodes = len(G.nodes)\n",
    "    mod_matrix = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "    # Find modularity matrix\n",
    "    for i, j, _ in G.edges(data=True):\n",
    "        mod_matrix[i][j] = 1 if partition[i] == partition[j] else 0\n",
    "\n",
    "    pi_values = np.zeros(num_nodes)\n",
    "    for node in range(num_nodes):\n",
    "        pi_values[node] = participation_coefficient(node, mod_matrix)\n",
    "\n",
    "    # Rank-order the PI scores (lowest to highest)\n",
    "    ranked_pi = np.argsort(pi_values) + 1\n",
    "    return ranked_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4651826484018265 0.3002758751902588\n",
      "[[-0.96875  0.03125  0.03125 ...  0.03125  0.03125  0.03125]\n",
      " [ 0.03125 -0.96875  0.03125 ...  0.03125  0.03125  0.03125]\n",
      " [ 0.03125  0.03125 -0.96875 ...  0.03125  0.03125  0.03125]\n",
      " ...\n",
      " [ 0.03125  0.03125  0.03125 ... -0.96875  0.03125  0.03125]\n",
      " [ 0.03125  0.03125  0.03125 ...  0.03125 -0.96875  0.03125]\n",
      " [ 0.03125  0.03125  0.03125 ...  0.03125  0.03125 -0.96875]]\n",
      "-0.7693588280060883 0.48185407153729076\n",
      "[[-0.96875  0.03125  0.03125 ...  0.03125  0.03125  0.03125]\n",
      " [ 0.03125 -0.96875  0.03125 ...  0.03125  0.03125  0.03125]\n",
      " [ 0.03125  0.03125 -0.96875 ...  0.03125  0.03125  0.03125]\n",
      " ...\n",
      " [ 0.03125  0.03125  0.03125 ... -0.96875  0.03125  0.03125]\n",
      " [ 0.03125  0.03125  0.03125 ...  0.03125 -0.96875  0.03125]\n",
      " [ 0.03125  0.03125  0.03125 ...  0.03125  0.03125 -0.96875]]\n",
      "-0.7593226788432268 0.6359874429223745\n",
      "[[-0.96875  0.03125  0.03125 ...  0.03125  0.03125  0.03125]\n",
      " [ 0.03125 -0.96875  0.03125 ...  0.03125  0.03125  0.03125]\n",
      " [ 0.03125  0.03125 -0.96875 ...  0.03125  0.03125  0.03125]\n",
      " ...\n",
      " [ 0.03125  0.03125  0.03125 ... -0.96875  0.03125  0.03125]\n",
      " [ 0.03125  0.03125  0.03125 ...  0.03125 -0.96875  0.03125]\n",
      " [ 0.03125  0.03125  0.03125 ...  0.03125  0.03125 -0.96875]]\n",
      "-0.7630327245053272 0.5762937595129376\n",
      "[[-0.96875  0.03125  0.03125 ...  0.03125  0.03125  0.03125]\n",
      " [ 0.03125 -0.96875  0.03125 ...  0.03125  0.03125  0.03125]\n",
      " [ 0.03125  0.03125 -0.96875 ...  0.03125  0.03125  0.03125]\n",
      " ...\n",
      " [ 0.03125  0.03125  0.03125 ... -0.96875  0.03125  0.03125]\n",
      " [ 0.03125  0.03125  0.03125 ...  0.03125 -0.96875  0.03125]\n",
      " [ 0.03125  0.03125  0.03125 ...  0.03125  0.03125 -0.96875]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(freq_bands)):\n",
    "    # Values ranging from -1 to 1\n",
    "    diff_matrix = nx.from_numpy_array(connectivity[f'MDD-{mapping[i]}'] - connectivity[f'Control-{mapping[i]}'])\n",
    "    print(np.min(connectivity[f'MDD-{mapping[i]}'] - connectivity[f'Control-{mapping[i]}']), np.max(connectivity[f'MDD-{mapping[i]}'] - connectivity[f'Control-{mapping[i]}']))\n",
    "    ranked_pi = community_structure(diff_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M3 - 4. Threshold using saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(freq_bands)):\n",
    "    plt.plot(thresholds, edges_MDD[mapping[i]])\n",
    "    plt.plot(thresholds, edges_control[mapping[i]])\n",
    "    plt.title(f'{mapping[i]} Threshold comparison (blue - MDD, red-Control)')\n",
    "    plt.xlabel('Thresholds')\n",
    "    plt.ylabel('Number of edges')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To remove:\n",
    "# optimal_threshold['delta'] = 0.442\n",
    "# optimal_threshold['theta'] =  0.529\n",
    "# optimal_threshold['alpha1'] = 0.786\n",
    "# optimal_threshold['alpha2'] = 0.741"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M4 - 4. ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_MDD.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Binarization on functional connectivity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['MDD-delta', 'Control-delta', 'MDD-theta', 'Control-theta', 'MDD-alpha1', 'Control-alpha1', 'MDD-alpha2', 'Control-alpha2'])\n"
     ]
    }
   ],
   "source": [
    "binarized_matrix = {}\n",
    "for i in range(len(freq_bands)):\n",
    "    binarized_matrix[f'MDD-{mapping[i]}'] = connectivity[f'MDD-{mapping[i]}'] > optimal_threshold[mapping[i]]\n",
    "    binarized_matrix[f'Control-{mapping[i]}'] = connectivity[f'Control-{mapping[i]}'] > optimal_threshold[mapping[i]]\n",
    "print(binarized_matrix.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find number of links in each graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDD-delta-number of links: K= 5\n",
      "Control-delta-number of links: K= 18\n",
      "MDD-theta-number of links: K= 0\n",
      "Control-theta-number of links: K= 53\n",
      "MDD-alpha1-number of links: K= 0\n",
      "Control-alpha1-number of links: K= 18\n",
      "MDD-alpha2-number of links: K= 0\n",
      "Control-alpha2-number of links: K= 7\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(freq_bands)):\n",
    "    links_MDD = 0\n",
    "    links_control = 0\n",
    "\n",
    "    for row in range(n_channels):\n",
    "        for col in range(row+1):\n",
    "            if binarized_matrix[f'MDD-{mapping[i]}'][row][col] == 1:\n",
    "                links_MDD+=1\n",
    "            if binarized_matrix[f'Control-{mapping[i]}'][row][col] == 1:\n",
    "                links_control+=1\n",
    "\n",
    "    print(f'MDD-{mapping[i]}-number of links: K=', links_MDD)\n",
    "    print(f'Control-{mapping[i]}-number of links: K=', links_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yellow - Higher synchronisation\n",
    "for i in range(len(binarized_matrix)//2):\n",
    "    # i = 0, 1, 2\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for j in range(2):\n",
    "        # j = 0, 1\n",
    "        plt.subplot(1, 2, j+1)\n",
    "        plt.imshow(list(binarized_matrix.values())[2*i+j], interpolation='none')\n",
    "        plt.title(f'Functional connectivity - {list(binarized_matrix)[2*i+j]} - Visualization')\n",
    "        plt.xticks([_ for _ in range(n_channels)], raw_MDD.info['ch_names'], rotation='vertical')\n",
    "        plt.yticks([_ for _ in range(n_channels)], raw_MDD.info['ch_names'], rotation='horizontal')\n",
    "        plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Difference matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_index(channels_list, raw):\n",
    "    indexes = []\n",
    "    for channel in channels_list:\n",
    "        for i in range(len(raw.info['ch_names'])):\n",
    "            if raw.info['ch_names'][i]==channel:\n",
    "                indexes.append(i)\n",
    "    return(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_channels = return_index(['Pz', 'Oz', 'Fz', 'Cz'], raw_MDD)\n",
    "central_channels\n",
    "raw_MDD.info['bads'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL_CHANNELS = np.array(['P8', 'T8', 'CP6', 'FC6', 'F8', 'F4', 'C4', 'P4', 'AF4', 'Fp2',\n",
    "#        'Fp1', 'AF3', 'Fz', 'FC2', 'Cz', 'CP2', 'PO3', 'O1', 'Oz', 'O2',\n",
    "#        'PO4', 'Pz', 'CP1', 'FC1', 'P3', 'C3', 'F3', 'F7', 'FC5', 'CP5',\n",
    "#        'T7', 'P7'])\n",
    "# def set_montage(raw):\n",
    "#     mont1020 = mne.channels.make_standard_montage('standard_1020')\n",
    "#     ind = [i for (i, channel) in enumerate(mont1020.ch_names) if channel in ALL_CHANNELS]\n",
    "#     mont1020_new = mont1020.copy()\n",
    "#     mont1020_new.ch_names = [mont1020.ch_names[x] for x in ind]\n",
    "#     kept_channel_info = [mont1020.dig[x+3] for x in ind]\n",
    "#     mont1020_new.dig = mont1020.dig[0:3]+kept_channel_info\n",
    "#     print(\"sjkghdkgu\", mont1020_new)\n",
    "#     return raw.set_montage(mont1020_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Cannot activate multiple GUI eventloops\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Cannot activate multiple GUI eventloops\n",
      "ERROR:root:Cannot activate multiple GUI eventloops\n",
      "ERROR:root:Cannot activate multiple GUI eventloops\n"
     ]
    }
   ],
   "source": [
    "difference_matrix = {}\n",
    "from mne.io.pick import _picks_to_idx\n",
    "for i in range(len(freq_bands)):\n",
    "    difference_matrix[mapping[i]] = binarized_matrix[f'Control-{mapping[i]}'].astype(int) - binarized_matrix[f'MDD-{mapping[i]}'].astype(int) \n",
    "    for k in range(n_channels):\n",
    "        for l in range(n_channels):\n",
    "            if difference_matrix[mapping[i]][k][l] == -1 or k in central_channels or l in central_channels:\n",
    "                difference_matrix[mapping[i]][k][l] = 0\n",
    "\n",
    "    # Yellow - Higher synchronisation\n",
    "    plt.imshow(difference_matrix[mapping[i]], interpolation='none')\n",
    "    plt.title(f'Functional connectivity - {[mapping[i]]} - Visualization')\n",
    "    plt.xticks([_ for _ in range(n_channels)], raw_MDD.info['ch_names'], rotation='vertical')\n",
    "    plt.yticks([_ for _ in range(n_channels)], raw_MDD.info['ch_names'], rotation='horizontal')\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.show()\n",
    "\n",
    "    # epochs_MDD = set_montage(epochs_MDD)\n",
    "\n",
    "    # plot_sensors_connectivity(\n",
    "    #     raw_MDD.info,\n",
    "    #     difference_matrix[mapping[i]],\n",
    "    #     cbar_label=f'{mapping[i]}-Connectivity',\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nilearn import plotting\n",
    "# from nilearn.connectome import ConnectivityMeasure\n",
    "# from nilearn.maskers import MultiNiftiLabelsMasker\n",
    "# from nilearn import datasets\n",
    "\n",
    "# # Load MNI152 atlas\n",
    "# atlas = datasets.fetch_atlas_aal()\n",
    "\n",
    "# # Extract MNI coordinates for 32 regions\n",
    "# num_regions = 31*3\n",
    "# coordinates = atlas.indices[:num_regions]\n",
    "# # coordinates = atlas.region_coords[region_indices]\n",
    "\n",
    "# # coordinates = raw_MDD.plot_sensors()\n",
    "# print(raw_MDD.info, coordinates)\n",
    "\n",
    "# # Plot the connectivity matrix\n",
    "# plotting.plot_connectome(adjacency_matrix=binarized_matrix['MDD-alpha1'], node_coords=coordinates)\n",
    "# plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'delta': ['C3'], 'theta': ['O2', 'FC1', 'C3', 'T7'], 'alpha1': ['C3'], 'alpha2': []}\n"
     ]
    }
   ],
   "source": [
    "selected_channels = {}\n",
    "for i in range(len(freq_bands)):\n",
    "    selected_channels[mapping[i]] = []\n",
    "    for ch in range(32):\n",
    "        # TODO: instead of number of edges wise, we can explore other algorithm\n",
    "        if len(nx.from_numpy_array(difference_matrix[mapping[i]]).edges(ch)) >=6:\n",
    "            selected_channels[mapping[i]].append(raw_MDD.info['ch_names'][ch])\n",
    "print(selected_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary of Regions in brain vs channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionvschannel = {\n",
    "    'LC': ['C3', 'CP1', 'CP5', 'FC1', 'FC5'], # Left central \n",
    "    'LF': ['FP1', 'AF3', 'F3', 'F7'], # Left frontal\n",
    "    'LT': ['T7'], # Left temporal\n",
    "    'LPO': ['PO3',  'P3', 'P7', 'O1'], # Left parietal-occipital\n",
    "    'RC': ['CP6', 'FC6', 'C4', 'FC2', 'CP2',], # Right central \n",
    "    'RF': ['F8', 'F4', 'AF4', 'FP2'], # Right frontal\n",
    "    'RT': ['T8'], # Right temporal\n",
    "    'RPO': ['P8', 'P4', 'PO4', 'O2'] , # Right parietal-occipital\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(freq_bands)):\n",
    "selected_regions = {}\n",
    "# selected_regions['alpha2'] = ['RPO', 'LT', 'LF', 'LC']\n",
    "# selected_regions['alpha1'] = ['LT', 'LC', 'LF', 'RPO'] # 1 in RPO\n",
    "# selected_regions['theta'] = ['LC', 'LF'] # 1 in LC and 1 in LF\n",
    "# selected_regions['delta'] =  ['LF', 'LC', 'RF', 'RC'] # 1-1 in 'LC', 'RF', 'RC'\n",
    "selected_regions['delta'] =  ['LF', 'LC', 'RT']\n",
    "selected_regions['theta'] = ['LPO', 'LC', 'RPO']\n",
    "selected_regions['alpha1'] = ['LPO', 'RPO']\n",
    "selected_regions['alpha2'] = ['LC', 'RPO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Network Metrics for selected regions for selected bands\n",
    "\n",
    "\n",
    "Boxplot helps in reading median, interquartile range and outliers\n",
    "Box : middle 50% of all data lies (Interquartile range)\n",
    "Lower end: 1st quartile\n",
    "Upper end: 3rd quartile\n",
    "Solid line: Median\n",
    "Dashed line: Mean\n",
    "T shaped whiskers: Last point 1.5 times the interquartile range (max and min without outliers)\n",
    "Points: Further out are outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_measures = ['Lw', 'NBC', 'Eglo', 'CC', 'Eloc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_avergae_components(G):\n",
    "#     connected_components = list(nx.connected_components(G))\n",
    "#     component_avg_lengths = []\n",
    "#     component_nbc_values = []\n",
    "#     component_eglo_values = []\n",
    "#     component_cc_values = []\n",
    "#     component_eloc_values = []\n",
    "\n",
    "#     for component in connected_components:\n",
    "#         subgraph = G.subgraph(component)\n",
    "#         component_avg_lengths.append(nx.average_shortest_path_length(subgraph))\n",
    "#         component_nbc_values.append(nx.betweenness_centrality(subgraph))\n",
    "#         component_eglo_values.append(nx.global_efficiency(subgraph))\n",
    "#         component_cc_values.append(nx.clustering(subgraph))\n",
    "#         component_eloc_values.append(nx.local_efficiency(subgraph))\n",
    "\n",
    "#     merged_nbc_values = {}\n",
    "#     for dnbc in component_nbc_values:\n",
    "#         merged_nbc_values.update(dnbc)\n",
    "#     merged_nbc_values = dict(sorted(merged_nbc_values.items(), key=lambda item: item[0]))\n",
    "#     merged_cc_values = {}\n",
    "#     for dcc in component_cc_values:\n",
    "#         merged_cc_values.update(dcc)\n",
    "#     merged_cc_values = dict(sorted(merged_cc_values.items(), key=lambda item: item[0]))\n",
    "\n",
    "#     overall_avg_length = sum(component_avg_lengths) / len(component_avg_lengths)\n",
    "#     overall_eglo_values = sum(component_eglo_values) / len(component_eglo_values)\n",
    "#     overall_eloc_values = sum(component_eloc_values) / len(component_eloc_values)\n",
    "\n",
    "#     return [overall_avg_length, merged_nbc_values, overall_eglo_values, merged_cc_values, overall_eloc_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, {11: 0.0, 26: 0.0, 27: 0.0}, 0.0, 0.0, 0.0] fdhgjgdfjd [0.0, {11: 0.0, 26: 0.0, 27: 0.0}, 0.0, 0.0, 0.0]\n",
      "******** [0.0, {11: 0.0, 26: 0.0, 27: 0.0}, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m********\u001b[39m\u001b[38;5;124m\"\u001b[39m, MDD_list)\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMDD_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(MDD_list[_][\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mdict\u001b[39m()):\n\u001b[0;32m     36\u001b[0m             x \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "# Integration metrics - Lavg, Eglo \n",
    "# Segregation metrics - CC, Eloc, Nbc\n",
    "import seaborn as sns\n",
    "for i in range(len(freq_bands)):\n",
    "    selected_region = selected_regions[mapping[i]]\n",
    "\n",
    "    if selected_region == []:\n",
    "        continue\n",
    "\n",
    "    # con_MDD = connectivity_matrix(epochs_MDD, i)\n",
    "    # con_control = connectivity_matrix(epochs_control, i)\n",
    "    G_MDD = nx.from_numpy_array(binarized_matrix[f'MDD-{mapping[i]}'])\n",
    "    G_Control = nx.from_numpy_array(binarized_matrix[f'Control-{mapping[i]}'])\n",
    "\n",
    "    for region in selected_region:\n",
    "        channels_list = regionvschannel[region]\n",
    "        G_sub = G_MDD.subgraph(return_index(channels_list, raw_MDD))\n",
    "        MDD_list = calculate_avergae_components(G_sub)\n",
    "        G_sub = G_Control.subgraph(return_index(channels_list, raw_control))\n",
    "        control_list = calculate_avergae_components(G_sub)\n",
    "\n",
    "        print(MDD_list, \"fdhgjgdfjd\", control_list)\n",
    "\n",
    "        # CHECK HERE if keys in MDD_list[1] matches with keys in control_list[1]\n",
    "        # and keys in MDD_list[3] matches with keys in control_list[3]\n",
    "        \n",
    "        values_MDD = []\n",
    "        values_control = []\n",
    "        group_labels_MDD = []\n",
    "        group_labels_control = [] \n",
    "\n",
    "        for _ in range(5):\n",
    "            print(\"********\", MDD_list)\n",
    "            if len(MDD_list[_]):\n",
    "                if type(MDD_list[_][0]) == type(dict()):\n",
    "                    x = []\n",
    "                    for __ in range(len(MDD_list[_])):\n",
    "                        for k,v in MDD_list[_][__].items():\n",
    "                            x.append(v)\n",
    "                    values_MDD.append(x)\n",
    "                else:\n",
    "                    values_MDD.append(MDD_list[_])\n",
    "            else:\n",
    "                values_MDD.append([])\n",
    "            if (control_list[_]):\n",
    "                if type(control_list[_][0]) == type(dict()):\n",
    "                    y = []\n",
    "                    for __ in range(len(control_list[_])):\n",
    "                        for k,v in control_list[_][__].items():\n",
    "                            y.append(v)\n",
    "                    values_control.append(y)\n",
    "                else:\n",
    "                    values_control.append(control_list[_])\n",
    "            else:\n",
    "                values_control.append([])\n",
    "            group_labels_MDD.append(f'MDD-{group_measures[_]}')\n",
    "            group_labels_control.append(f'Control-{group_measures[_]}')\n",
    "            \n",
    "        values_all = values_MDD + values_control\n",
    "        group_labels = group_labels_MDD + group_labels_control\n",
    "\n",
    "        print(\"values all\", values_all)\n",
    "        print(\"group labels\", group_labels)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.boxplot(values_all, labels=group_labels, vert=True)\n",
    "        plt.title(f'Boxplot of Network Metrics for MDD and Control Groups in {mapping[i]} band in {region} region')\n",
    "        plt.xlabel('Network Metrics')\n",
    "        plt.ylabel('Values')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Mark all regions in brain along with Netowrk metrics which are significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Find relationship between \"these\" Network Metrics and PHQ-9 scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. For further evaluation: RF based on ensemble learning, SVM, KNN, ANN with 10-fold cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
