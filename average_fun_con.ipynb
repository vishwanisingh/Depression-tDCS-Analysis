{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALINGS = 4e-4\n",
    "SFREQ = 500\n",
    "WINDOW_SIZE = 1\n",
    "SHOW = False\n",
    "FMIN = 0.01\n",
    "FMAX = 45\n",
    "FREQ_BANDS = {\n",
    "    'delta': (0.01, 4),\n",
    "    'theta': (4, 8),\n",
    "    'alpha1': (8, 10),\n",
    "    'alpha2': (10, 13),\n",
    "    'beta1': (13, 15), \n",
    "    'beta2': (15, 22),\n",
    "    'beta3': (22, 30),\n",
    "    'gamma': (30, 45)\n",
    "}\n",
    "ALL_CHANNELS=[]\n",
    "GROUP1 = 'PRE-ACTIVE'\n",
    "GROUP2 = 'POST-ACTIVE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack\n",
    "from scipy.fft import fft\n",
    "import time\n",
    "import mne\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import kurtosis, zscore, ttest_ind\n",
    "from mne.preprocessing import create_ecg_epochs, create_eog_epochs, read_ica\n",
    "from mne.time_frequency import tfr_morlet, tfr_array_morlet, morlet, AverageTFR\n",
    "from itertools import product\n",
    "import pywt\n",
    "from scipy.signal import hilbert\n",
    "from mne_connectivity import spectral_connectivity_epochs\n",
    "from mne_connectivity.viz import plot_sensors_connectivity\n",
    "import networkx as nx\n",
    "import numpy as np \n",
    "import re\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from colabcode import ColabCode\n",
    "from nilearn import plotting\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from nilearn.maskers import MultiNiftiLabelsMasker\n",
    "from nilearn import datasets\n",
    "from communities.algorithms import hierarchical_clustering\n",
    "\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = os.getcwd()+'\\\\Depression-Sample-dataset-AIIMS\\\\32electrodes'\n",
    "# items = os.listdir(folder_path)\n",
    "# active_or_sham_list = [item for item in items if os.path.isdir(os.path.join(folder_path, item))]\n",
    "# for active_or_sham in active_or_sham_list:\n",
    "#     patient_folder_path = os.path.join(folder_path, active_or_sham)\n",
    "#     items = os.listdir(patient_folder_path)\n",
    "#     patients_list = [item for item in items if os.path.isdir(os.path.join(patient_folder_path, item))]\n",
    "#     patients_list = ['PreetiSingh', 'Hemlata', 'VinodKumarSharma']\n",
    "#     for patient in patients_list:\n",
    "#         pre_post_int_folder_path = os.path.join(patient_folder_path, patient)\n",
    "#         items = os.listdir(pre_post_int_folder_path)\n",
    "#         pre_post_int_list = [item for item in items if os.path.isdir(os.path.join(pre_post_int_folder_path, item))]\n",
    "#         for var in pre_post_int_list:\n",
    "#             if var=='Pre':\n",
    "#                 pre_path = os.path.join(pre_post_int_folder_path, var)\n",
    "#                 file_path = pre_path + '\\\\' + '20230718201550_Preeti singh_22.08.23-01_Eye Close' + '.easy'\n",
    "#                 break # Remove for all pre, post and intervention for a patient\n",
    "#         break # Remove for all patients in active or sham\n",
    "#     break # Remove for both active and sham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transformation_easy(file_path):\n",
    "\tdf = pd.read_csv(file_path, sep='\\t')\n",
    "\tchannel_str='Channel 1:P8\\\n",
    "\t\tChannel 2:T8\\\n",
    "\t\tChannel 3:CP6\\\n",
    "\t\tChannel 4:FC6\\\n",
    "\t\tChannel 5:F8\\\n",
    "\t\tChannel 6:F4\\\n",
    "\t\tChannel 7:C4\\\n",
    "\t\tChannel 8:P4\\\n",
    "\t\tChannel 9:AF4\\\n",
    "\t\tChannel 10:Fp2\\\n",
    "\t\tChannel 11:Fp1\\\n",
    "\t\tChannel 12:AF3\\\n",
    "\t\tChannel 13:Fz\\\n",
    "\t\tChannel 14:FC2\\\n",
    "\t\tChannel 15:Cz\\\n",
    "\t\tChannel 16:CP2\\\n",
    "\t\tChannel 17:PO3\\\n",
    "\t\tChannel 18:O1\\\n",
    "\t\tChannel 19:Oz\\\n",
    "\t\tChannel 20:O2\\\n",
    "\t\tChannel 21:PO4\\\n",
    "\t\tChannel 22:Pz\\\n",
    "\t\tChannel 23:CP1\\\n",
    "\t\tChannel 24:FC1\\\n",
    "\t\tChannel 25:P3\\\n",
    "\t\tChannel 26:C3\\\n",
    "\t\tChannel 27:F3\\\n",
    "\t\tChannel 28:F7\\\n",
    "\t\tChannel 29:FC5\\\n",
    "\t\tChannel 30:CP5\\\n",
    "\t\tChannel 31:T7\\\n",
    "\t\tChannel 32:P7'\n",
    "\n",
    "\tchannel_names = re.findall(r'Channel \\d+:(\\w+)', channel_str)\n",
    "\tchannel_names.append('ax')\n",
    "\tchannel_names.append('ay')\n",
    "\tchannel_names.append('az')\n",
    "\tchannel_names.append('trigger')\n",
    "\tchannel_names.append('timestamp(ms)')\n",
    "\tglobal ALL_CHANNELS\n",
    "\tALL_CHANNELS = np.array(channel_names[:-5])\n",
    "\tdf.columns=channel_names\n",
    "\ttransposed_data=df.T\n",
    "\tch_names = df.columns.tolist()[:-5]\n",
    "\tch_types = ['eeg' for i in range(32)]\n",
    "\tinfo = mne.create_info(ch_names=ch_names,ch_types=ch_types, sfreq=500)\n",
    "\traw = mne.io.RawArray(transposed_data.values[:-5,:]/1e9, info) # Example: 33129984 nV = 0.033129984 V = 33129.984000000004 uV\n",
    "\treturn raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_montage(raw):\n",
    "    mont1020 = mne.channels.make_standard_montage('standard_1020')\n",
    "    ind = [i for (i, channel) in enumerate(mont1020.ch_names) if channel in ALL_CHANNELS]\n",
    "    mont1020_new = mont1020.copy()\n",
    "    mont1020_new.ch_names = [mont1020.ch_names[x] for x in ind]\n",
    "    kept_channel_info = [mont1020.dig[x+3] for x in ind]\n",
    "    mont1020_new.dig = mont1020.dig[0:3]+kept_channel_info\n",
    "    raw.set_montage(mont1020_new)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate absolute power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_absolute_power(raw_data):\n",
    "    psds, freqs = mne.time_frequency.psd_array_welch(raw_data.get_data(), fmin=FMIN, fmax=FMAX, sfreq=SFREQ)\n",
    "    absolute_powers = {}\n",
    "    for band, (FMIN, FMAX) in FREQ_BANDS.items():\n",
    "        idx_band = np.logical_and(freqs >= FMIN, freqs <= FMAX)\n",
    "        absolute_power = np.trapz(psds[:, idx_band], dx=(freqs[1] - freqs[0]), axis=-1)\n",
    "        absolute_powers[band] = absolute_power\n",
    "    total_absolute_power = sum(absolute_powers.values())\n",
    "    return total_absolute_power\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time amplitude plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_amplitude(raw):\n",
    "    fig = raw.plot(\n",
    "        n_channels=32, \n",
    "        scalings=SCALINGS,\n",
    "        show=SHOW\n",
    "        )\n",
    "    # fig.savefig(f'MNE-graphs/time-amplitude/{title}-EEG.png')\n",
    "\n",
    "    print(raw.info)\n",
    "    # TODO: Extract statistical features from time domain such as mean, median, variance, skewness, kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power spectral density plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psd(raw):\n",
    "    fig = raw.plot_psd(\n",
    "        picks=raw.info['ch_names'], \n",
    "        show=SHOW)\n",
    "    # fig.savefig(f'MNE-graphs/psd-frequency/{title}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wavelet plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wavelet(raw1, raw2=None, title):\n",
    "#     raw1_avg = np.mean(raw1.get_data(), axis=0)\n",
    "#     t = np.arange(0, 150, 1/SFREQ)\n",
    "#     ts = t[:-1]\n",
    "#     wavelet = 'db13'\n",
    "#     level = 5 # level of decomposition based on your signal characteristics\n",
    "\n",
    "#     # coeffs_multi_channel = []\n",
    "#     # for i in range(32): \n",
    "#     coeffs1 = pywt.wavedec(raw1_avg, wavelet, level=level)\n",
    "#         # coeffs_multi_channel.append(coeffs)\n",
    "    \n",
    "#     plt.figure(figsize=(10, 6))\n",
    "\n",
    "#     # raw1\n",
    "#     plt.subplot(4, 1, 1)\n",
    "#     plt.plot(ts, raw1_avg, label='xyz')\n",
    "#     plt.title('Channel 1')\n",
    "#     plt.xlabel('Time')\n",
    "#     plt.ylabel('Amplitude')\n",
    "#     plt.legend()\n",
    "\n",
    "#     # raw1 coeffs\n",
    "#     plt.subplot(4, 1, 2)\n",
    "#     for i in range(level+1):\n",
    "#         plt.plot(t, pywt.upcoef('a', coeffs1[i], wavelet, level=level)[:len(t)], label=f'Level {i}')\n",
    "#     plt.title('DWT')\n",
    "#     plt.xlabel('Time')\n",
    "#     plt.ylabel('Amplitude')\n",
    "#     plt.legend()\n",
    "\n",
    "#     if raw2:\n",
    "#         raw2_avg = np.mean(raw2.get_data(), axis=0)\n",
    "#         coeffs2 = pywt.wavedec(raw2_avg, wavelet, level=level)\n",
    "\n",
    "#         # raw2\n",
    "#         plt.subplot(4, 1, 3)\n",
    "#         plt.plot(t, raw2_avg, label='ddd')\n",
    "#         plt.title('Channel 1')\n",
    "#         plt.xlabel('Time')\n",
    "#         plt.ylabel('Amplitude')\n",
    "#         plt.legend()\n",
    "\n",
    "#         # raw2 coeffs\n",
    "#         plt.subplot(4, 1, 4)\n",
    "#         for i in range(level+1):\n",
    "#             plt.plot(t, pywt.upcoef('a', coeffs2[i], wavelet, level=level)[:len(t)], label=f'Level {i}')\n",
    "#         plt.title('DWT')\n",
    "#         plt.xlabel('Time')\n",
    "#         plt.ylabel('Amplitude')\n",
    "#         plt.legend()\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Band pass filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_pass_filter(raw, l_freq=FMIN, h_freq=FMAX):\n",
    "    raw.filter(method= 'fir',\n",
    "        phase= 'minimum',\n",
    "        fir_window= 'hann',\n",
    "        l_freq= l_freq,\n",
    "        h_freq= h_freq)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rereferencing\n",
    "\n",
    "Calculates the mean voltage from all electrodes at each time point and subtracts this mean from the voltage at each individual electrode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rereferencing(raw):\n",
    "    raw.set_eeg_reference('average', projection=True).apply_proj() \n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artifact Rejection (EOG/ECG) using Wavelet decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wavelet_decompose(raw):\n",
    "#     info = raw.info\n",
    "#     coeffs = pywt.wavedec(raw.get_data(), 'db13', level=4)\n",
    "#     threshold = 0.00001 # applying a shrinkage function that smoothly brings coefficients below the threshold to zero\n",
    "#     coeffs_thresholded = [pywt.threshold(c, threshold, mode='soft') for c in coeffs] \n",
    "#     denoised_signal = pywt.waverec(coeffs_thresholded, 'db13')\n",
    "#     raw = mne.io.RawArray(denoised_signal, info)\n",
    "#     return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(raw, l, h):\n",
    "    return raw.crop(l,h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampling(raw, SFREQ=SFREQ):\n",
    "    return raw.resample(sfreq=SFREQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop channels\n",
    "\n",
    "Dropping extra channels in both groups\n",
    "TODO: Instead of dropping we can convert 10-10 64 channels montage to 10-20 32 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_channels(raw, raw_1):\n",
    "    drop = []\n",
    "    for chan in raw.info['ch_names']:\n",
    "        if chan not in raw_1.info['ch_names']:\n",
    "            drop.append(chan)\n",
    "    raw.drop_channels(drop)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 1 preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g1_preprocess(raw):\n",
    "    raw = set_montage(raw)\n",
    "    raw  = band_pass_filter(raw, l_freq = FMIN, h_freq = FMAX)\n",
    "    raw = rereferencing(raw)\n",
    "    # raw = wavelet_decompose(raw)\n",
    "    raw.info['bads'] = []\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 2 preprcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g2_preprocessing(raw, raw_1, crop=True):\n",
    "    # For epochs crop=False\n",
    "    raw = drop_channels(raw, raw_1)\n",
    "    if crop:\n",
    "        raw = set_montage(raw)\n",
    "        raw = raw.crop(50, 200)\n",
    "    raw = resampling(raw)\n",
    "    raw = band_pass_filter(raw, l_freq = 0.01, h_freq = 45)\n",
    "    # raw = wavelet_decompose(raw)\n",
    "    raw.info['bads'] = []\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate average components of a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avergae_components(G):\n",
    "    connected_components = list(nx.connected_components(G))\n",
    "    component_avg_lengths = []\n",
    "    component_nbc_values = []\n",
    "    component_eglo_values = []\n",
    "    component_cc_values = []\n",
    "    component_eloc_values = []\n",
    "\n",
    "    for component in connected_components:\n",
    "        subgraph = G.subgraph(component)\n",
    "        component_avg_lengths.append(nx.average_shortest_path_length(subgraph))\n",
    "        component_nbc_values.append(nx.betweenness_centrality(subgraph))\n",
    "        component_eglo_values.append(nx.global_efficiency(subgraph))\n",
    "        component_cc_values.append(nx.average_clustering(subgraph))\n",
    "        component_eloc_values.append(nx.local_efficiency(subgraph))\n",
    "\n",
    "    merged_nbc_values = {}\n",
    "    for dnbc in component_nbc_values:\n",
    "        merged_nbc_values.update(dnbc)\n",
    "    merged_nbc_values = dict(sorted(merged_nbc_values.items(), key=lambda item: item[0]))\n",
    " \n",
    "    overall_avg_length = sum(component_avg_lengths) / len(component_avg_lengths)\n",
    "    overall_eglo_values = sum(component_eglo_values) / len(component_eglo_values)\n",
    "    overall_cc_values = sum(component_cc_values) / len(component_cc_values)\n",
    "    overall_eloc_values = sum(component_eloc_values) / len(component_eloc_values)\n",
    "\n",
    "    return [overall_avg_length, merged_nbc_values, overall_eglo_values, overall_cc_values, overall_eloc_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PRE VS CONTROL\n",
    "# if GROUP1 == 'PRE-ALL' and GROUP2 == 'CONTROL':\n",
    "    # raw_1 = mne.io.read_raw_fif(\"loadData/rawMDDpre5.fif\")\n",
    "    # raw_2 = mne.io.read_raw_fif(\"loadData/rawControlOnline104.fif\")\n",
    "\n",
    "    # epochs_1 = mne.read_epochs(\"loadData/epochsMDDpre5.fif\", preload=False)\n",
    "    # epochs_2 = mne.read_epochs(\"loadData/epochsControlOnline104.fif\", preload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file loadData/rawMDDpre2PS+VKSActive.fif...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 32) active\n",
      "    Range : 0 ... 74998 =      0.000 ...   149.996 secs\n",
      "Ready.\n",
      "Opening raw data file loadData/rawMDDpost2PS+VKSActive.fif...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 32) active\n",
      "    Range : 0 ... 74998 =      0.000 ...   149.996 secs\n",
      "Ready.\n",
      "Reading /home/vishwani/Downloads/IITD/Depression-IITD/loadData/epochsMDDpre2PS+VKSActive.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 32) active\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    4000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "73 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12225/123082804.py:3: RuntimeWarning: This filename (loadData/rawMDDpre2PS+VKSActive.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw_1 = mne.io.read_raw_fif(\"loadData/rawMDDpre2PS+VKSActive.fif\")\n",
      "/tmp/ipykernel_12225/123082804.py:4: RuntimeWarning: This filename (loadData/rawMDDpost2PS+VKSActive.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw_2 = mne.io.read_raw_fif(\"loadData/rawMDDpost2PS+VKSActive.fif\")\n",
      "/tmp/ipykernel_12225/123082804.py:6: RuntimeWarning: This filename (loadData/epochsMDDpre2PS+VKSActive.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs_1 = mne.read_epochs(\"loadData/epochsMDDpre2PS+VKSActive.fif\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/vishwani/Downloads/IITD/Depression-IITD/loadData/epochsMDDpost2PS+VKSActive.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 32) active\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    4000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "73 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12225/123082804.py:7: RuntimeWarning: This filename (loadData/epochsMDDpost2PS+VKSActive.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs_2 = mne.read_epochs(\"loadData/epochsMDDpost2PS+VKSActive.fif\")\n"
     ]
    }
   ],
   "source": [
    "# PRE VS POST - ACTIVE\n",
    "if GROUP1 == 'PRE-ACTIVE' and GROUP2 == 'POST-ACTIVE':\n",
    "    raw_1 = mne.io.read_raw_fif(\"loadData/rawMDDpre2PS+VKSActive.fif\")\n",
    "    raw_2 = mne.io.read_raw_fif(\"loadData/rawMDDpost2PS+VKSActive.fif\")\n",
    "\n",
    "    epochs_1 = mne.read_epochs(\"loadData/epochsMDDpre2PS+VKSActive.fif\")\n",
    "    epochs_2 = mne.read_epochs(\"loadData/epochsMDDpost2PS+VKSActive.fif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE VS POST - SHAM\n",
    "if GROUP1 == 'PRE-SHAM' and GROUP2 == 'POST-SHAM':\n",
    "    raw_1 = mne.io.read_raw_fif(\"loadData/rawMDDpre2Sham.fif\")\n",
    "    raw_2 = mne.io.read_raw_fif(\"loadData/rawMDDpost2Sham.fif\")\n",
    "\n",
    "    epochs_1 = mne.read_epochs(\"loadData/epochsMDDpre2Sham.fif\")\n",
    "    epochs_2 = mne.read_epochs(\"loadData/epochsMDDpost2Sham.fif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # POST -Active vs Control\n",
    "# if GROUP1 == 'POST-ACTIVE' and GROUP2 == 'CONTROL':\n",
    "    # raw_1 = mne.io.read_raw_fif(\"loadData/rawMDDpost3Active.fif\")\n",
    "    # raw_2 = mne.io.read_raw_fif(\"loadData/rawControlOnline104.fif\")\n",
    "\n",
    "    # epochs_1 = mne.read_epochs(\"loadData/epochsMDDpre3Active.fif\", preload=False)\n",
    "    # epochs_2 = mne.read_epochs(\"loadData/epochsControlOnline104.fif\", preload=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELSE COMPUTE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_close_1 = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Active', 'PreetiSingh', 'Pre', '20230718201550_Preeti singh_22.08.23-01_Eye Close.easy' )\n",
    "# eye_close_2 = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Active', 'Hemlata', 'Pre', '20230831105330_Hemlata_05.10.23_01_Eye Close.easy') \n",
    "# eye_close_3 = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Active', 'VinodKumarSharma', 'Pre', '20230829195416_VinodKumarSharma_25.9.23_01_Eye Close.easy' ) \n",
    "# eye_close_4 = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Sham', 'JitenderKumar', 'Pre', '20230825020227_JitenderKumar_29.08.23_01_Eye Close.easy' )\n",
    "# eye_close_5 = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Sham', 'SeemaKumari', 'Pre', '20230827073914_SeemaKumari_11.09.23_01_Eye Close.easy') \n",
    "eye_close_MDD = [eye_close_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=32, n_times=74999\n",
      "    Range : 0 ... 74998 =      0.000 ...   149.996 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, non-linear phase, causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hann window with 0.0546 passband ripple and 44 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.01 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz\n",
      "- Filter length: 155001 samples (310.002 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6656/607340406.py:2: RuntimeWarning: filter_length (155001) is longer than the signal (74999), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  raw.filter(method= 'fir',\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "SSP projectors applied...\n"
     ]
    }
   ],
   "source": [
    "raw_1 = []\n",
    "for file_path in eye_close_MDD:\n",
    "    raw = data_transformation_easy(file_path)\n",
    "    # raw = mne.io.read_raw_edf(file, eog=None, misc=None, stim_channel='auto', exclude=(), infer_types=False, include=None, preload=True, units=None, encoding='utf8', verbose=None)\n",
    "    # By default read_raw_edf convert units to V\n",
    "    raw = g1_preprocess(raw)\n",
    "    raw_1.append(raw.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.33525372e-04 -1.31549983e-04 -1.30168912e-04 ... -8.90369881e-05\n",
      "  -8.93129180e-05 -8.99036218e-05]\n",
      " [-2.64856612e-04 -2.65373564e-04 -2.66976073e-04 ... -3.79363217e-04\n",
      "  -3.80135019e-04 -3.81474539e-04]\n",
      " [-5.44371580e-05 -5.44189804e-05 -5.49040051e-05 ... -2.77286963e-05\n",
      "  -2.82030785e-05 -2.89511124e-05]\n",
      " ...\n",
      " [ 2.69166157e-05  2.86575379e-05  2.97079177e-05 ... -1.51144863e-05\n",
      "  -1.48540252e-05 -1.44233095e-05]\n",
      " [-1.57322445e-05 -1.47326176e-05 -1.46809070e-05 ... -3.69658107e-05\n",
      "  -3.60525239e-05 -3.55223779e-05]\n",
      " [-1.86501924e-04 -1.84657575e-04 -1.83527947e-04 ... -3.66963308e-04\n",
      "  -3.67113251e-04 -3.67332142e-04]]\n"
     ]
    }
   ],
   "source": [
    "# M1 : Averaging using mean:\n",
    "\n",
    "raw_1_avg = np.mean(raw_1, axis=0)\n",
    "print(raw_1_avg)\n",
    "\n",
    "del raw_1[:]\n",
    "del raw_1\n",
    "del eye_close_MDD[:]\n",
    "del eye_close_MDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=32, n_times=74999\n",
      "    Range : 0 ... 74998 =      0.000 ...   149.996 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "info = raw.info\n",
    "raw_1 = mne.io.RawArray(raw_1_avg, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 2 data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE VS POST COMPARISON\n",
    "eye_close_6 = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Active', 'PreetiSingh', 'Post', '20230826225729_PreetiSingh_08.09.23_20_Eye Close.easy' )\n",
    "# eye_close_7 = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Active', 'Hemlata', 'Post', '20231019110530_Hemlata_19.10.23_19A_Eye Close.easy') \n",
    "# eye_close_8 = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Active', 'VinodKumarSharma', 'Post', '20230901112451_VinodKumarSharma_11.10.23_20_Eye Close.easy' ) \n",
    "# eye_close_9 = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Sham', 'JitenderKumar', 'Post', '20230827174115_JitenderKumar_13.09.23_20_Eye Close.easy') \n",
    "# eye_close_10 = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', 'Sham', 'SeemaKumari', 'Post', '20230829172634_SeemaKumari_23.9.23_20_Eye Close.easy' ) \n",
    "eye_close_control = [eye_close_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=32, n_times=74999\n",
      "    Range : 0 ... 74998 =      0.000 ...   149.996 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, non-linear phase, causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hann window with 0.0546 passband ripple and 44 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.01 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz\n",
      "- Filter length: 155001 samples (310.002 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6656/607340406.py:2: RuntimeWarning: filter_length (155001) is longer than the signal (74999), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  raw.filter(method= 'fir',\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "SSP projectors applied...\n"
     ]
    }
   ],
   "source": [
    "# PRE VS POST COMPARISON\n",
    "raw_2 = []\n",
    "# folder_path = os.getcwd()+'\\\\Depression-Sample-dataset-AIIMS\\\\'\n",
    "for file_path in eye_close_control:\n",
    "    raw = data_transformation_easy(file_path)\n",
    "    # raw = mne.io.read_raw_edf(file, eog=None, misc=None, stim_channel='auto', exclude=(), infer_types=False, include=None, preload=True, units=None, encoding='utf8', verbose=None)\n",
    "    # By default read_raw_edf convert units to V\n",
    "    raw = g1_preprocess(raw)\n",
    "    raw_2.append(raw.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.66707444e-04  3.69226617e-04  3.72762004e-04 ...  1.42365541e-04\n",
      "   1.45821637e-04  1.49468734e-04]\n",
      " [ 1.98725191e-04  2.01175111e-04  2.03737522e-04 ...  1.98313038e-04\n",
      "   1.99498501e-04  2.01247720e-04]\n",
      " [ 7.65867784e-05  7.91526875e-05  8.12511615e-05 ... -1.67104261e-04\n",
      "  -1.66983543e-04 -1.66786701e-04]\n",
      " ...\n",
      " [ 1.59169991e-05  1.85238215e-05  2.10020239e-05 ...  9.60917172e-05\n",
      "   9.57351693e-05  9.54917300e-05]\n",
      " [ 1.00989194e-04  1.05452448e-04  1.09764297e-04 ...  9.75266930e-07\n",
      "   1.92562680e-06  3.09349092e-06]\n",
      " [ 9.92068113e-07  4.65518537e-06  8.00444834e-06 ...  1.66590794e-05\n",
      "   1.64337570e-05  1.65672982e-05]]\n"
     ]
    }
   ],
   "source": [
    "# PRE VS POST COMPARISON\n",
    "# M1 : Averaging using mean:\n",
    "raw_2_avg = np.mean(raw_2, axis=0)\n",
    "print(raw_2_avg)\n",
    "\n",
    "del raw_2[:]\n",
    "del raw_2\n",
    "del eye_close_control[:]\n",
    "del eye_close_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=32, n_times=74999\n",
      "    Range : 0 ... 74998 =      0.000 ...   149.996 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# PRE VS POST COMPARISON\n",
    "info = raw.info\n",
    "raw_2 = mne.io.RawArray(raw_2_avg, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find control indexes\n",
    "# file_path = os.getcwd() + '\\\\Depression-Sample-dataset-AIIMS\\\\' + 'Control\\\\' + 'derivatives\\\\cleaned_epochs\\\\'\n",
    "# control_indexes = []\n",
    "# for i in range(0, 111):\n",
    "#     eeg_file_epoch = file_path + f'sub-{i+1:03d}\\\\ses-t1\\\\eeg\\\\sub-{i+1:03d}_ses-t1_task-resteyesc_desc-epochs_eeg.set'\n",
    "#     epochs_data = mne.io.read_epochs_eeglab(eeg_file_epoch, events=None, event_id=None, eog=(), uint16_codec=None, montage_units='mm', verbose=None)\n",
    "#     if len(epochs_data.get_data()) == 55:\n",
    "#         control_indexes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = os.getcwd() + '\\\\Depression-Sample-dataset-AIIMS\\\\' + 'Control\\\\'\n",
    "# raw_2 = []\n",
    "# for i in control_indexes:\n",
    "#     eeg_file_raw = file_path + f'sub-{i+1:03d}\\\\ses-t1\\\\eeg\\\\sub-{i+1:03d}_ses-t1_task-resteyesc_eeg.edf'\n",
    "#     raw = mne.io.read_raw_edf(eeg_file_raw, eog=None, misc=None, stim_channel='auto', exclude=(), infer_types=False, include=None, preload=False, units=None, encoding='utf8', verbose=None)\n",
    "#     # By default read_raw_edf convert units to V\n",
    "#     raw = control_preprocessing(raw, raw_1)\n",
    "#     raw_2.append(raw.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del control_indexes[:]\n",
    "# del control_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_2_avg = np.mean(raw_2, axis=0)\n",
    "\n",
    "# del raw_2[:]\n",
    "# del raw_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info = raw.info\n",
    "# raw_2 = mne.io.RawArray(raw_2_avg, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Raw MDD and control data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/vishwani/Downloads/IITD/Depression-IITD/loadData/rawMDDpreActive1.fif\n",
      "Closing /home/vishwani/Downloads/IITD/Depression-IITD/loadData/rawMDDpreActive1.fif\n",
      "[done]\n",
      "Writing /home/vishwani/Downloads/IITD/Depression-IITD/loadData/rawMDDpostActive1.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6656/385234496.py:1: RuntimeWarning: This filename (/home/vishwani/Downloads/IITD/Depression-IITD/loadData/rawMDDpreActive1.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw_1.save(\"loadData/rawMDDpreActive1.fif\")\n",
      "/tmp/ipykernel_6656/385234496.py:2: RuntimeWarning: This filename (/home/vishwani/Downloads/IITD/Depression-IITD/loadData/rawMDDpostActive1.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw_2.save(\"loadData/rawMDDpostActive1.fif\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /home/vishwani/Downloads/IITD/Depression-IITD/loadData/rawMDDpostActive1.fif\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "raw_1.save(\"loadData/rawMDDpreActive1.fif\")\n",
    "raw_2.save(\"loadData/rawMDDpostActive1.fif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 4.0\n",
    "overlap = 2.0 \n",
    "\n",
    "samples_per_epoch = int(duration * SFREQ)\n",
    "samples_per_overlap = int(overlap * SFREQ)\n",
    "\n",
    "# Manually created events\n",
    "start, stop = 0, samples_per_epoch\n",
    "events = []\n",
    "while stop <= len(raw_1):\n",
    "    events.append([start, 0, 1]) \n",
    "    start += samples_per_overlap\n",
    "    stop += samples_per_overlap\n",
    "\n",
    "events = np.array(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Segmenting epochs for MDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "73 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Using data from preloaded Raw for 73 events and 2001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using matplotlib as 2D backend.\n",
      "You seem to have overlapping epochs. Some event lines may be duplicated in the plot.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 1848x1016 with 4 Axes>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_1 = mne.Epochs(raw_1, events, tmin=0, tmax=duration, baseline=None, detrend=1,\n",
    "                    picks=None, preload=True, reject=None)\n",
    "raw_1.plot(n_channels=len(raw_1.info['ch_names']), events=events, event_color={1:'r'}, scalings=SCALINGS)\n",
    "epochs_1.plot(n_channels=len(raw_1.info['ch_names']), event_color={1:'r'}, events=events, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Segmenting epochs for control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "73 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Using data from preloaded Raw for 73 events and 2001 original time points ...\n",
      "0 bad epochs dropped\n",
      "You seem to have overlapping epochs. Some event lines may be duplicated in the plot.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 1848x1016 with 4 Axes>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_2 = mne.Epochs(raw_2, events, tmin=0, tmax=duration, baseline=None, detrend=1,\n",
    "                    picks=None, preload=True, reject=None)\n",
    "raw_2.plot(n_channels=len(raw_1.info['ch_names']), events=events, event_color={1:'r'}, scalings=SCALINGS)\n",
    "epochs_2.plot(n_channels=len(raw_1.info['ch_names']), event_color={1:'r'}, events=events, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = os.getcwd() + '\\\\Depression-Sample-dataset-AIIMS\\\\' + 'Control\\\\' + 'derivatives\\\\cleaned_epochs\\\\'\n",
    "# epochs_2 = []\n",
    "# for i in range(0, 111):\n",
    "#     eeg_file_epoch = file_path + f'sub-{i+1:03d}\\\\ses-t1\\\\eeg\\\\sub-{i+1:03d}_ses-t1_task-resteyesc_desc-epochs_eeg.set'\n",
    "#     epochs_data = mne.io.read_epochs_eeglab(eeg_file_epoch, events=None, event_id=None, eog=(), uint16_codec=None, montage_units='mm', verbose=None)\n",
    "#     if len(epochs_data.get_data()) == 55:\n",
    "#         cleaned_epoch = control_preprocessing(epochs_data, epochs_1, crop=False)\n",
    "#         epochs_2.append(cleaned_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_2_avg = np.mean(epochs_2, axis=0)\n",
    "# print(epochs_2_avg)\n",
    "\n",
    "# del epochs_2[:]\n",
    "# del epochs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info = cleaned_epoch.info\n",
    "# epochs_2 = mne.EpochsArray(epochs_2_avg, info)\n",
    "# epochs_2.plot(n_channels=len(raw_1.info['ch_names']), event_color={1:'r'}, events=None, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving epoched raw and control data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6656/2269747080.py:1: RuntimeWarning: This filename (loadData/epochsMDDpreActive1.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs_1.save(\"loadData/epochsMDDpreActive1.fif\")\n",
      "/tmp/ipykernel_6656/2269747080.py:2: RuntimeWarning: This filename (loadData/epochsMDDpostActive1.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs_2.save(\"loadData/epochsMDDpostActive1.fif\")\n"
     ]
    }
   ],
   "source": [
    "epochs_1.save(\"loadData/epochsMDDpreActive1.fif\")\n",
    "epochs_2.save(\"loadData/epochsMDDpostActive1.fif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. PSD graph plot between MDD and Control group\n",
    "\n",
    "For resting state EEG channel, analyzing the overall average power across channels provides a holistic view of the brain's activity without emphasizing the specificity of individual channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wavelet_plot(raw1, raw2, title):\n",
    "#     '''\n",
    "#     signal ----> breaks into frequency components/scales ----> WT computes coeffcients that represent signal's content \n",
    "#     at a specific scale ----->coeffs at lower level represent lower frequency components\n",
    "     \n",
    "#     Scales vs frequencies - lower scale = higher frequency (fine details)\n",
    "#     larger coefficient represents higher energy at a sepcific scale\n",
    "#     peaks in scale vs time plot = where energy is concentrated\n",
    "#     broad distribution across scales = mix of frequencies\n",
    "\n",
    "#     Find frequency component of interest \n",
    "#     Step1: Look for peaks (dominant frequencies)\n",
    "#     Step2: Convert scale to frequency using frequency = SFREQ/(2**scale)\n",
    "#     Step 3: Compare across time\n",
    "#     Step 4: Statistical analysis\n",
    "\n",
    "#     '''\n",
    "#     # Average channel wavelet transform\n",
    "#     raw1_avg = np.mean(raw1.get_data(), axis=0)\n",
    "#     raw2_avg = np.mean(raw2.get_data(), axis=0)\n",
    "\n",
    "#     # Individual channels wavelet transform\n",
    "#     t = np.arange(0, 150, 1/SFREQ)\n",
    "#     ts = t[:-1]\n",
    "    \n",
    "#     wavelet = 'db13'\n",
    "#     level = 4 # level of decomposition based on your signal characteristics\n",
    " \n",
    "#     coeffs1 = pywt.wavedec(raw1_avg, wavelet, level=level)    \n",
    "#     coeffs2 = pywt.wavedec(raw2_avg, wavelet, level=level)\n",
    "\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     for i in range(level+1):\n",
    "#         if i==0:\n",
    "#             plt.plot(t, raw1_avg, label='MDD raw')\n",
    "#         plt.plot(t, pywt.upcoef('a', coeffs1[i], wavelet, level=level)[:len(t)], label=f'MDD - Level {i}')\n",
    "#         if i==0:\n",
    "#             plt.plot(t, raw2_avg, label='Control raw')\n",
    "#         plt.plot(t, pywt.upcoef('a', coeffs2[i], wavelet, level=level)[:len(t)], label=f'Control - Level {i}')\n",
    "#         plt.title('DWT')\n",
    "#         plt.xlabel('Time')\n",
    "#         plt.ylabel('Amplitude')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "\n",
    "# wavelet_plot(raw_1, raw_2, \"gjhggj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amplitude plots between both groups\n",
    "epochs_1_avg = epochs_1['1'].average()\n",
    "epochs_2_avg = epochs_2['1'].average()\n",
    "# evokeds = dict(epochs_1=epochs_1)\n",
    "fig_MDD = epochs_1_avg.plot(titles=GROUP1, time_unit = 'ms')\n",
    "fig_control = epochs_2_avg.plot(titles=GROUP2, time_unit = 'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 PSD using plot_psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().\n",
      "Effective window size : 4.096 (s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().\n",
      "Effective window size : 4.096 (s)\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "#plot_psd uses welch method for continuous data\n",
    "raw_1.plot_psd(picks=raw_1.info['ch_names'], average=True, fmin=FMIN, fmax=FMAX, ax=ax, show=False, color='blue', dB=False)\n",
    "raw_2.plot_psd(picks=raw_2.info['ch_names'], average=True, fmin=FMIN, fmax=FMAX, ax=ax, show=False, color='red', dB=False)\n",
    "\n",
    "# dB = True plots PSD in decibels (logarithmic)\n",
    "# different n_fft compared to psd_array_welch\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Power/Frequency (microV^2/Hz)')\n",
    "ax.set_title('Power Spectral Density Comparison')\n",
    "\n",
    "ax.text(0.8, 0.9, GROUP1, color='blue', transform=ax.transAxes)\n",
    "ax.text(0.8, 0.85, GROUP2, color='red', transform=ax.transAxes)\n",
    "\n",
    "plt.ylim(0, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Average of power using welch method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.512 (s)\n",
      "Effective window size : 0.512 (s)\n"
     ]
    }
   ],
   "source": [
    "labels = np.arange(0, FMAX)\n",
    "# welch always gives positive psd\n",
    "psd_1, frequencies = mne.time_frequency.psd_array_welch(raw_1.get_data(), fmin=FMIN, fmax=FMAX, sfreq=SFREQ)\n",
    "psd_2, frequencies = mne.time_frequency.psd_array_welch(raw_2.get_data(), fmin=FMIN, fmax=FMAX, sfreq=SFREQ)\n",
    "avg_abs_power_1, avg_abs_power_2 = np.mean(psd_1, axis=0), np.mean(psd_2, axis=0) \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(frequencies, avg_abs_power_1, color='blue', label=GROUP1)\n",
    "plt.plot(frequencies, avg_abs_power_2, color='red', label=GROUP2)\n",
    "plt.title('Welch - Average Power')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.xticks(labels, labels, rotation ='vertical') \n",
    "plt.ylabel('Power (V^2/Hz)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Statistical testing between psds of raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.1 Plotting Histogram\n",
    "\n",
    "Shows if the data is bell shaped, skewed (positive or negative), uniform etc. Central tendency - highest peak in histogram. Spread - width of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_avg = np.mean(raw_1.get_data(), axis=0)\n",
    "plt.hist(g1_avg, bins='auto', alpha=0.7, edgecolor='black')\n",
    "plt.title(f'Histogram of {GROUP1} Data - averaged across all channels')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2_avg = np.mean(raw_2.get_data(), axis=0)\n",
    "plt.hist(g2_avg, bins='auto', alpha=0.7, edgecolor='black')\n",
    "plt.title(f'Histogram of {GROUP2} Data - averaged across all channels')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE-ACTIVE mean:  -2.731056396534766e-20\n",
      "POST-ACTIVE mean:  1.692875659705057e-19\n"
     ]
    }
   ],
   "source": [
    "print(f\"{GROUP1} mean: \", np.mean(g1_avg, axis=0))\n",
    "print(f\"{GROUP2} mean: \", np.mean(g2_avg, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.2 Calculate variance of both groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE-ACTIVE variance:  1.2098970477639453e-22\n",
      "POST-ACTIVE variance:  2.0461106706757122e-21\n"
     ]
    }
   ],
   "source": [
    "variance_1 = np.var(psd_1, ddof=1) \n",
    "variance_2 = np.var(psd_2, ddof=1)\n",
    "print(f\"{GROUP1} variance: \", variance_1)\n",
    "print(f\"{GROUP2} variance: \", variance_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.3 Find differences between the means of two independent groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, null hypothesis: there is no significant difference between groups (ie means are equal).\n",
    "alternative hypothesis: there is a significant difference between groups\n",
    "t-test : compares the differences between group means to expected variability in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data PSD Comparison Results:\n",
      "T-statistic: [-0.04957784 -0.35657848  0.33271042  0.54242062  0.69979297 -0.68891656\n",
      "  0.84500274  1.03620539  1.43944407  1.19659036  0.49105201  0.14672671\n",
      "  1.1878187   0.32602976  0.4017483  -0.20915025  1.31812777  1.39441829\n",
      "  1.76767718  1.61483116  0.29346189 -0.35884248  0.2892291  -1.80899163\n",
      " -1.00442816  0.57351979 -0.68345264  0.09693589 -0.29832039  0.48549147\n",
      "  0.85871083  1.24192976]\n",
      "P-values: [0.96068318 0.72311173 0.74093294 0.5902657  0.48774013 0.49449267\n",
      " 0.40268084 0.3057678  0.15710165 0.2378742  0.62583009 0.88401797\n",
      " 0.24127741 0.74594744 0.68981407 0.83529627 0.19428211 0.1701926\n",
      " 0.08404917 0.11349657 0.77054889 0.72142915 0.77376452 0.07728811\n",
      " 0.32066432 0.56921281 0.49790432 0.92321752 0.76686293 0.62973657\n",
      " 0.3951541  0.22084179]\n"
     ]
    }
   ],
   "source": [
    "p_values = np.zeros(32)\n",
    "t = np.zeros(32)\n",
    "for i in range(32):\n",
    "    t[i], p_values[i] = ttest_ind(psd_1[i, :], psd_2[i, :])\n",
    "# independent t-test comparison : equal_var = True\n",
    "# welch's t-test comparison: equal_var = False\n",
    "print(\"Raw Data PSD Comparison Results:\")\n",
    "print(\"T-statistic:\", t)\n",
    "print(\"P-values:\", p_values) # probability of getting t-statistic >= what we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data PSD Comparison Results:\n",
      "T-statistic: -0.2403350744582439\n",
      "P-values: 0.8115773225009455\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_values = ttest_ind(np.mean(psd_1, axis=0), np.mean(psd_2, axis=0), equal_var=False)\n",
    "# independent t-test comparison : equal_var = True\n",
    "# welch's t-test comparison: equal_var = False\n",
    "print(\"Raw Data PSD Comparison Results:\")\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-values:\", p_values) # probability of getting t-statistic >= what we got"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If p value < 0.005, we reject the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PLI and construction of brain function matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_bands = [(0.01, 4), (4,8), (8, 10), (10, 13), (13, 15), (15, 22)]\n",
    "mapping = {0: 'delta', 1: 'theta', 2: 'alpha1', 3:'alpha2', 4:'beta1', 5:'beta2'}\n",
    "connectivity = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pli method always gives positive correlations\n",
    "def connectivity_matrix(epochs, i):\n",
    "    return spectral_connectivity_epochs(\n",
    "    epochs, method='pli', mode='multitaper', sfreq=SFREQ,\n",
    "    fmin=freq_bands[i][0], fmax=freq_bands[i][1], faverage=True, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 0.2Hz..4.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6656/1345682627.py:3: RuntimeWarning: fmin=0.010 Hz corresponds to 0.040 < 5 cycles based on the epoch length 4.002 sec, need at least 500.000 sec epochs or fmin=1.249. Spectrum estimate will be unreliable.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Adding metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 0.2Hz..4.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6656/1345682627.py:3: RuntimeWarning: fmin=0.010 Hz corresponds to 0.040 < 5 cycles based on the epoch length 4.002 sec, need at least 500.000 sec epochs or fmin=1.249. Spectrum estimate will be unreliable.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 4.2Hz..8.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 4.2Hz..8.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 8.2Hz..10.0Hz (8 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 8.2Hz..10.0Hz (8 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 10.2Hz..13.0Hz (12 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 10.2Hz..13.0Hz (12 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 13.2Hz..15.0Hz (8 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 13.2Hz..15.0Hz (8 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 15.2Hz..22.0Hz (28 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 15.2Hz..22.0Hz (28 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    computing connectivity for epoch 35\n",
      "    computing connectivity for epoch 36\n",
      "    computing connectivity for epoch 37\n",
      "    computing connectivity for epoch 38\n",
      "    computing connectivity for epoch 39\n",
      "    computing connectivity for epoch 40\n",
      "    computing connectivity for epoch 41\n",
      "    computing connectivity for epoch 42\n",
      "    computing connectivity for epoch 43\n",
      "    computing connectivity for epoch 44\n",
      "    computing connectivity for epoch 45\n",
      "    computing connectivity for epoch 46\n",
      "    computing connectivity for epoch 47\n",
      "    computing connectivity for epoch 48\n",
      "    computing connectivity for epoch 49\n",
      "    computing connectivity for epoch 50\n",
      "    computing connectivity for epoch 51\n",
      "    computing connectivity for epoch 52\n",
      "    computing connectivity for epoch 53\n",
      "    computing connectivity for epoch 54\n",
      "    computing connectivity for epoch 55\n",
      "    computing connectivity for epoch 56\n",
      "    computing connectivity for epoch 57\n",
      "    computing connectivity for epoch 58\n",
      "    computing connectivity for epoch 59\n",
      "    computing connectivity for epoch 60\n",
      "    computing connectivity for epoch 61\n",
      "    computing connectivity for epoch 62\n",
      "    computing connectivity for epoch 63\n",
      "    computing connectivity for epoch 64\n",
      "    computing connectivity for epoch 65\n",
      "    computing connectivity for epoch 66\n",
      "    computing connectivity for epoch 67\n",
      "    computing connectivity for epoch 68\n",
      "    computing connectivity for epoch 69\n",
      "    computing connectivity for epoch 70\n",
      "    computing connectivity for epoch 71\n",
      "    computing connectivity for epoch 72\n",
      "    computing connectivity for epoch 73\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n"
     ]
    }
   ],
   "source": [
    "n_channels = len(raw_1.info['ch_names'])\n",
    "for i in range(len(freq_bands)):\n",
    "    con = connectivity_matrix(epochs_1, i)\n",
    "    connectivity[f'{GROUP1}-{mapping[i]}'] = con.get_data().reshape((n_channels, n_channels))\n",
    "\n",
    "    con = connectivity_matrix(epochs_2, i)\n",
    "    connectivity[f'{GROUP2}-{mapping[i]}'] = con.get_data().reshape((n_channels, n_channels))\n",
    "\n",
    "    # Make matrix symmetric\n",
    "    for row in range(n_channels):\n",
    "        for col in range(n_channels):\n",
    "            connectivity[f'{GROUP1}-{mapping[i]}'][row][col] = connectivity[f'{GROUP1}-{mapping[i]}'][col][row]\n",
    "            connectivity[f'{GROUP2}-{mapping[i]}'][row][col] = connectivity[f'{GROUP2}-{mapping[i]}'][col][row]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['PRE-ACTIVE-delta', 'POST-ACTIVE-delta', 'PRE-ACTIVE-theta', 'POST-ACTIVE-theta', 'PRE-ACTIVE-alpha1', 'POST-ACTIVE-alpha1', 'PRE-ACTIVE-alpha2', 'POST-ACTIVE-alpha2', 'PRE-ACTIVE-beta1', 'POST-ACTIVE-beta1', 'PRE-ACTIVE-beta2', 'POST-ACTIVE-beta2'])\n"
     ]
    }
   ],
   "source": [
    "print((connectivity.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ALTERNATIVE: PLI calculation in Raw Python\n",
    "\n",
    "# def calculate_pli(data):\n",
    "#     # data = EEG data of channel Ci and Cj for 1 epoch (2000 data points (4s X 500fs))\n",
    "#     analytic_signal = hilbert(data)\n",
    "#     instantaneous_phase = np.angle(analytic_signal)\n",
    "#     return np.abs(np.mean(np.sign(np.diff(instantaneous_phase, axis=0))))\n",
    "\n",
    "# fun_connectivity = []\n",
    "# for k in range(len(epochs)):\n",
    "#     pli_matrix = [[0 for i in range(len(raw_cleaned.info['ch_names']))] for j in range(len(raw_cleaned.info['ch_names']))]\n",
    "#     for i in range(len(raw_cleaned.info['ch_names'])):\n",
    "#         for j in range(i+1, len(raw_cleaned.info['ch_names'])):\n",
    "#             pli_matrix[i][j] = pli_matrix[j][i] = calculate_pli([epochs[k].get_data(fmin = freq_bands[0][0], fmax=freq_bands[-1][-1])[0][i], epochs[k].get_data(fmin = freq_bands[0][0], fmax=freq_bands[-1][-1])[0][j]])\n",
    "\n",
    "#     fun_connectivity.append(pli_matrix)\n",
    "# conn = np.mean(fun_connectivity, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Thresholding - M1 -  Small World Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preserves small-world properties in both groups to ensure that any observed differences in connectivity are not biased by the thresholding method.\n",
    "# Preserving these properties ensures that information can be transmitted quickly and effectively across the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_network = nx.gnm_random_graph(1, 0)\n",
    "# x = calculate_avergae_components(random_network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842533231488193 Cw1  0.9155754269599516 Lw1  1.0866935483870968\n",
      "0.9597204190613847 Cw2  0.9810045412583106 Lw2  1.0221774193548387\n",
      "delta - Optimal Threshold: 0.1 (Significant) 1.0550568410553957e-23\n",
      "0.8793954047761517 Cw1  0.9361305921810648 Lw1  1.064516129032258\n",
      "0.9438008144567295 Cw2  0.9723431777971548 Lw2  1.030241935483871\n",
      "theta - Optimal Threshold: 0.1 (Significant) 8.697582882585772e-20\n",
      "0.7930987067150148 Cw1  0.8890380663982826 Lw1  1.1209677419354838\n",
      "0.9840403940886702 Cw2  0.9919762037184175 Lw2  1.0080645161290323\n",
      "alpha1 - Optimal Threshold: 0.1 (Significant) 1.097132045358269e-21\n",
      "0.9269402562372101 Cw1  0.9624480483108129 Lw1  1.0383064516129032\n",
      "0.9919494068226931 Cw2  0.995949202817946 Lw2  1.0040322580645162\n",
      "alpha2 - Optimal Threshold: 0.1 (Significant) 4.084208690088537e-15\n",
      "0.7784827956682662 Cw1  0.8820712321886403 Lw1  1.1330645161290323\n",
      "0.9560557774085626 Cw2  0.9772586273107687 Lw2  1.0221774193548387\n",
      "beta1 - Optimal Threshold: 0.1 (Significant) 1.0943298467485468e-20\n",
      "0.9014855466553228 Cw1  0.9505583485901892 Lw1  1.0544354838709677\n",
      "0.96423840413598 Cw2  0.9817346655013506 Lw2  1.0181451612903225\n",
      "beta2 - Optimal Threshold: 0.1 (Significant) 7.309796224444247e-21\n"
     ]
    }
   ],
   "source": [
    "optimal_threshold = {}\n",
    "edges_1 = {}\n",
    "edges_2 = {}\n",
    "# Generating 50 random networks with same number of vertices and edges \n",
    "random_networks = [nx.gnm_random_graph(n_channels, 496) for _ in range(50)]\n",
    "thresholds = np.arange(0.1, 0.9, 0.002)\n",
    "\n",
    "for i in range(len(freq_bands)):\n",
    "    edges_1[mapping[i]] = []\n",
    "    edges_2[mapping[i]] = []\n",
    "    ratios = []\n",
    "    for threshold in thresholds:\n",
    "        # TODO: Cross check should we ignore thresholds which result in matrix to be not connected ?\n",
    "        Lw_1_binarized = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] > threshold))[0]\n",
    "        Cw_1_binarized = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] > threshold))[3]\n",
    "\n",
    "        Lw_2_binarized = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP2}-{mapping[i]}'] > threshold))[0]\n",
    "        Cw_2_binarized = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP2}-{mapping[i]}'] > threshold))[3]\n",
    "\n",
    "        swi_ratio_binarized =  (Cw_1_binarized*Lw_2_binarized)/(Lw_1_binarized*Cw_2_binarized) if Lw_1_binarized and Cw_2_binarized else 0\n",
    "        ratios.append(swi_ratio_binarized)\n",
    "        \n",
    "    optimal_threshold[mapping[i]] = thresholds[np.argmax(np.abs(ratios))] #TODO: ratios - swi_ratio ? OR remove swi_ratio and related code above\n",
    "    t_stat, p_value = ttest_ind(np.mean(connectivity[f'{GROUP1}-{mapping[i]}'], axis=0), np.mean(connectivity[f'{GROUP2}-{mapping[i]}'], axis=0)) \n",
    "    if p_value < 0.005: # Reject the null hypotheses\n",
    "        Crand = np.mean([calculate_avergae_components(nx.from_numpy_array((nx.to_numpy_array(G) > optimal_threshold[mapping[i]])))[3] for G in random_networks])\n",
    "        Lrand = np.mean([calculate_avergae_components(nx.from_numpy_array((nx.to_numpy_array(G) > optimal_threshold[mapping[i]])))[0] for G in random_networks])\n",
    "\n",
    "        Lw_1_binarized = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] > optimal_threshold[mapping[i]]))[0]\n",
    "        Cw_1_binarized = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] > optimal_threshold[mapping[i]]))[3]\n",
    "\n",
    "        Lw_2_binarized = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP2}-{mapping[i]}'] > optimal_threshold[mapping[i]]))[0]\n",
    "        Cw_2_binarized = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP2}-{mapping[i]}'] > optimal_threshold[mapping[i]]))[3]\n",
    "\n",
    "        swi_binarized_1 =  (Cw_1_binarized/Crand)/(Lw_1_binarized/Lrand)\n",
    "        swi_binarized_2 = (Cw_2_binarized/Crand)/(Lw_2_binarized/Lrand)\n",
    "        print(swi_binarized_1, \"Cw1 \", Cw_1_binarized, \"Lw1 \", Lw_1_binarized)\n",
    "        print(swi_binarized_2, \"Cw2 \", Cw_2_binarized, \"Lw2 \", Lw_2_binarized)  \n",
    "\n",
    "        edges_1[mapping[i]].append(nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] > optimal_threshold[mapping[i]]).number_of_edges())\n",
    "        edges_2[mapping[i]].append(nx.from_numpy_array(connectivity[f'{GROUP2}-{mapping[i]}'] > optimal_threshold[mapping[i]]).number_of_edges())\n",
    "\n",
    "        print(f\"{mapping[i]} - Optimal Threshold: {optimal_threshold[mapping[i]]} (Significant)\", p_value)\n",
    "\n",
    "    # plt.plot(thresholds, ratios, label='Threshold Ratios')\n",
    "    # plt.axhline(swi_ratio, color='red', linestyle='--', label=' SWI ratio (MDD/Control)')\n",
    "    # plt.xlabel(f'Threshold-{mapping[i]}')\n",
    "    # plt.ylabel('Ratio')\n",
    "    # plt.legend()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'delta': 0.1, 'theta': 0.1, 'alpha1': 0.1, 'alpha2': 0.1, 'beta1': 0.1, 'beta2': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(freq_bands)):\n",
    "#     optimal_threshold[mapping[i]]  -= 0.1\n",
    "print(optimal_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2 - Community structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from networkx.algorithms.community import greedy_modularity_communities\n",
    "# import networkx as nx\n",
    "# # Calculate the participation coefficient for each node\n",
    "# def participation_coefficient(node, modularity_matrix):\n",
    "#     k_in = np.sum(modularity_matrix[node, :])\n",
    "#     k_out = np.sum(modularity_matrix) - k_in\n",
    "#     q = modularity_matrix.shape[0]\n",
    "#     pc = 1 - ((k_in / q) ** 2 + (k_out / q) ** 2)\n",
    "#     return pc\n",
    "\n",
    "# def community_structure(G):\n",
    "#     # Compute community structure (Louvain algorithm)\n",
    "#     partition = list(nx.algorithms.community.modularity_max.greedy_modularity_communities(G)[0])\n",
    "#     # pi_scores = nx.algorithms.community.indicators.participation(G, partition)(G)\n",
    "\n",
    "#     print(nx.modularity_matrix(G))\n",
    "\n",
    "#     # plot network with community structure \n",
    "#     # pos = nx.spring_layout(G)\n",
    "#     # colors = [partition[node] for node in G.nodes]\n",
    "#     # plt.figure(figsize=(10, 8))\n",
    "#     # nx.draw(G, pos, node_color=colors, with_labels=True, cmap=plt.cm.Paired, node_size=300)\n",
    "#     # plt.title(\"Community structure\")\n",
    "#     # plt.show()\n",
    "\n",
    "#     num_nodes = len(G.nodes)\n",
    "#     mod_matrix = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "#     # Find modularity matrix\n",
    "#     for i, j, _ in G.edges(data=True):\n",
    "#         mod_matrix[i][j] = 1 if partition[i] == partition[j] else 0\n",
    "\n",
    "#     pi_values = np.zeros(num_nodes)\n",
    "#     for node in range(num_nodes):\n",
    "#         pi_values[node] = participation_coefficient(node, mod_matrix)\n",
    "\n",
    "#     # Rank-order the PI scores (lowest to highest)\n",
    "#     ranked_pi = np.argsort(pi_values) + 1\n",
    "#     return ranked_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(freq_bands)):\n",
    "#     # Values ranging from -1 to 1\n",
    "#     diff_matrix = nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] - connectivity[f'{GROUP2}-{mapping[i]}'])\n",
    "#     print(np.min(connectivity[f'{GROUP1}-{mapping[i]}'] - connectivity[f'{GROUP2}-{mapping[i]}']), np.max(connectivity[f'{GROUP1}-{mapping[i]}'] - connectivity[f'{GROUP2}-{mapping[i]}']))\n",
    "#     ranked_pi = community_structure(diff_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M3 - Threshold using saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(freq_bands)):\n",
    "#     plt.plot(thresholds, edges_MDD[mapping[i]])\n",
    "#     plt.plot(thresholds, edges_control[mapping[i]])\n",
    "#     plt.title(f'{mapping[i]} Threshold comparison (blue - MDD, red-Control)')\n",
    "#     plt.xlabel('Thresholds')\n",
    "#     plt.ylabel('Number of edges')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To remove:\n",
    "# optimal_threshold['delta'] = 0.442\n",
    "# optimal_threshold['theta'] =  0.529\n",
    "# optimal_threshold['alpha1'] = 0.786\n",
    "# optimal_threshold['alpha2'] = 0.741"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M4 - ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_1.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Binarization on functional connectivity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'delta': 0.1, 'theta': 0.1, 'alpha1': 0.1, 'alpha2': 0.1, 'beta1': 0.1, 'beta2': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# for i in mapping:\n",
    "#     optimal_threshold[mapping[i]]  -= 0.2\n",
    "print(optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['PRE-ACTIVE-delta', 'POST-ACTIVE-delta', 'PRE-ACTIVE-theta', 'POST-ACTIVE-theta', 'PRE-ACTIVE-alpha1', 'POST-ACTIVE-alpha1', 'PRE-ACTIVE-alpha2', 'POST-ACTIVE-alpha2', 'PRE-ACTIVE-beta1', 'POST-ACTIVE-beta1', 'PRE-ACTIVE-beta2', 'POST-ACTIVE-beta2'])\n"
     ]
    }
   ],
   "source": [
    "binarized_matrix = {}\n",
    "for i in mapping:\n",
    "    binarized_matrix[f'{GROUP1}-{mapping[i]}'] = connectivity[f'{GROUP1}-{mapping[i]}'] > optimal_threshold[mapping[i]]\n",
    "    binarized_matrix[f'{GROUP2}-{mapping[i]}'] = connectivity[f'{GROUP2}-{mapping[i]}'] > optimal_threshold[mapping[i]]\n",
    "print(binarized_matrix.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find number of links in each graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE-ACTIVE-delta-number of links: K= 453\n",
      "POST-ACTIVE-delta-number of links: K= 485\n",
      "PRE-ACTIVE-theta-number of links: K= 464\n",
      "POST-ACTIVE-theta-number of links: K= 481\n",
      "PRE-ACTIVE-alpha1-number of links: K= 436\n",
      "POST-ACTIVE-alpha1-number of links: K= 492\n",
      "PRE-ACTIVE-alpha2-number of links: K= 477\n",
      "POST-ACTIVE-alpha2-number of links: K= 494\n",
      "PRE-ACTIVE-beta1-number of links: K= 430\n",
      "POST-ACTIVE-beta1-number of links: K= 485\n",
      "PRE-ACTIVE-beta2-number of links: K= 469\n",
      "POST-ACTIVE-beta2-number of links: K= 487\n"
     ]
    }
   ],
   "source": [
    "for i in mapping:\n",
    "    links_MDD = 0\n",
    "    links_control = 0\n",
    "\n",
    "    for row in range(n_channels):\n",
    "        for col in range(row+1):\n",
    "            if binarized_matrix[f'{GROUP1}-{mapping[i]}'][row][col] == 1:\n",
    "                links_MDD+=1\n",
    "            if binarized_matrix[f'{GROUP2}-{mapping[i]}'][row][col] == 1:\n",
    "                links_control+=1\n",
    "\n",
    "    print(f'{GROUP1}-{mapping[i]}-number of links: K=', links_MDD)\n",
    "    print(f'{GROUP2}-{mapping[i]}-number of links: K=', links_control)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Yellow - Higher synchronisation\n",
    "# for i in range(len(binarized_matrix)//2):\n",
    "#     # i = 0, 1, 2\n",
    "#     plt.figure(figsize=(12, 4))\n",
    "#     for j in range(2):\n",
    "#         # j = 0, 1\n",
    "#         plt.subplot(1, 2, j+1)\n",
    "#         plt.imshow(list(binarized_matrix.values())[2*i+j], interpolation='none')\n",
    "#         plt.title(f'Functional connectivity - {list(binarized_matrix)[2*i+j]} - Visualization')\n",
    "#         plt.xticks([_ for _ in range(n_channels)], raw_1.info['ch_names'], rotation='vertical')\n",
    "#         plt.yticks([_ for _ in range(n_channels)], raw_1.info['ch_names'], rotation='horizontal')\n",
    "#         plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Asymmetry in  each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE-ACTIVE:  delta left region:  315 right region:  307 proportion:  1.0260586319218241\n",
      "POST-ACTIVE:  delta left region:  335 right region:  335 proportion:  1.0\n",
      "PRE-ACTIVE:  theta left region:  317 right region:  321 proportion:  0.9875389408099688\n",
      "POST-ACTIVE:  theta left region:  331 right region:  332 proportion:  0.9969879518072289\n",
      "PRE-ACTIVE:  alpha1 left region:  301 right region:  295 proportion:  1.0203389830508474\n",
      "POST-ACTIVE:  alpha1 left region:  339 right region:  340 proportion:  0.9970588235294118\n",
      "PRE-ACTIVE:  alpha2 left region:  327 right region:  328 proportion:  0.9969512195121951\n",
      "POST-ACTIVE:  alpha2 left region:  342 right region:  342 proportion:  1.0\n",
      "PRE-ACTIVE:  beta1 left region:  294 right region:  289 proportion:  1.0173010380622838\n",
      "POST-ACTIVE:  beta1 left region:  335 right region:  336 proportion:  0.9970238095238095\n",
      "PRE-ACTIVE:  beta2 left region:  326 right region:  320 proportion:  1.01875\n",
      "POST-ACTIVE:  beta2 left region:  337 right region:  337 proportion:  1.0\n"
     ]
    }
   ],
   "source": [
    "left_region = ['Fp1', 'AF3', 'PO3','O1', 'CP1', 'FC1', 'P3', 'C3', 'F3', 'F7', 'FC5', 'CP5', 'T7', 'P7']\n",
    "right_region = ['P8', 'T8', 'CP6', 'FC6', 'F8', 'F4', 'C4', 'P4', 'AF4', 'Fp2', 'FC2', 'CP2', 'O2', 'PO4']\n",
    "\n",
    "for i in mapping:\n",
    "    lr = 0 \n",
    "    rr = 0\n",
    "    lrc = 0\n",
    "    rrc = 0\n",
    "    for row in range(n_channels):\n",
    "        for col in range(row+1):\n",
    "            if binarized_matrix[f'{GROUP1}-{mapping[i]}'][row][col] == 1:\n",
    "                if raw_1.info['ch_names'][row] in left_region or raw_1.info['ch_names'][col] in left_region:\n",
    "                    lr += 1\n",
    "                if raw_1.info['ch_names'][row] in right_region or raw_1.info['ch_names'][col] in right_region:\n",
    "                    rr += 1\n",
    "                # print(raw_1.info['ch_names'][row], raw_1.info['ch_names'][col])\n",
    "\n",
    "            if binarized_matrix[f'{GROUP2}-{mapping[i]}'][row][col] == 1:\n",
    "                if raw_1.info['ch_names'][row] in left_region or raw_1.info['ch_names'][col] in left_region:\n",
    "                    lrc += 1\n",
    "                if raw_1.info['ch_names'][row] in right_region or raw_1.info['ch_names'][col] in right_region:\n",
    "                    rrc += 1\n",
    "                # print(raw_1.info['ch_names'][row], raw_1.info['ch_names'][col])\n",
    "\n",
    "    print(f\"{GROUP1}: \",mapping[i], \"left region: \", lr, \"right region: \", rr, \"proportion: \", lr/rr)\n",
    "    print(f\"{GROUP2}: \", mapping[i], \"left region: \", lrc, \"right region: \", rrc, \"proportion: \", lrc/rrc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Difference matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_index(channels_list, raw):\n",
    "    indexes = []\n",
    "    for channel in channels_list:\n",
    "        for i in range(len(raw.info['ch_names'])):\n",
    "            if raw.info['ch_names'][i]==channel:\n",
    "                indexes.append(i)\n",
    "    return(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_channels = return_index(['Pz', 'Oz', 'Fz', 'Cz'], raw_1)\n",
    "central_channels\n",
    "raw_1.info['bads'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL_CHANNELS = np.array(['P8', 'T8', 'CP6', 'FC6', 'F8', 'F4', 'C4', 'P4', 'AF4', 'Fp2',\n",
    "#        'Fp1', 'AF3', 'Fz', 'FC2', 'Cz', 'CP2', 'PO3', 'O1', 'Oz', 'O2',\n",
    "#        'PO4', 'Pz', 'CP1', 'FC1', 'P3', 'C3', 'F3', 'F7', 'FC5', 'CP5',\n",
    "#        'T7', 'P7'])\n",
    "# def set_montage(raw):\n",
    "#     mont1020 = mne.channels.make_standard_montage('standard_1020')\n",
    "#     ind = [i for (i, channel) in enumerate(mont1020.ch_names) if channel in ALL_CHANNELS]\n",
    "#     mont1020_new = mont1020.copy()\n",
    "#     mont1020_new.ch_names = [mont1020.ch_names[x] for x in ind]\n",
    "#     kept_channel_info = [mont1020.dig[x+3] for x in ind]\n",
    "#     mont1020_new.dig = mont1020.dig[0:3]+kept_channel_info\n",
    "#     print(\"sjkghdkgu\", mont1020_new)\n",
    "#     return raw.set_montage(mont1020_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_matrix = {}\n",
    "for i in mapping:\n",
    "    difference_matrix[mapping[i]] = binarized_matrix[f'{GROUP2}-{mapping[i]}'].astype(int) - binarized_matrix[f'{GROUP1}-{mapping[i]}'].astype(int) \n",
    "    # difference_matrix[mapping[i]] = binarized_matrix[f'{GROUP1}-{mapping[i]}'].astype(int) - binarized_matrix[f'{GROUP2}-{mapping[i]}'].astype(int) \n",
    "    for k in range(n_channels):\n",
    "        for l in range(n_channels):\n",
    "            if difference_matrix[mapping[i]][k][l] == -1 or k in central_channels or l in central_channels:\n",
    "                difference_matrix[mapping[i]][k][l] = 0\n",
    "\n",
    "    # Yellow - Higher synchronisation\n",
    "    plt.imshow(difference_matrix[mapping[i]], interpolation='none')\n",
    "    plt.title(f'Functional connectivity - {[mapping[i]]} - Visualization')\n",
    "    plt.xticks([_ for _ in range(n_channels)], raw_1.info['ch_names'], rotation='vertical')\n",
    "    plt.yticks([_ for _ in range(n_channels)], raw_1.info['ch_names'], rotation='horizontal')\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.show()\n",
    "\n",
    "    # plot_sensors_connectivity(\n",
    "    #     raw_1.info,\n",
    "    #     difference_matrix[mapping[i]],\n",
    "    #     cbar_label=f'{mapping[i]}-Connectivity',\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn_measure = ConnectivityMeasure(kind='coherence', sfreq=raw.info['sfreq'])\n",
    "\n",
    "# # Compute connectivity for each frequency band\n",
    "# connectivity_matrices, freqs, times, n_epochs, n_tapers = conn_measure.fit_transform([raw])\n",
    "\n",
    "# for i, freq_band in enumerate(freq_bands):\n",
    "#     plt.imshow(connectivity_matrices[0, i, :, :], cmap='viridis', aspect='auto', extent=[times[0], times[-1], freqs[0], freqs[-1]])\n",
    "#     plt.title(f'Connectivity Matrix ({freq_band[0]}-{freq_band[1]} Hz)')\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Frequency (Hz)')\n",
    "#     plt.colorbar()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'delta': ['CP6', 'FC2'], 'theta': [], 'alpha1': ['T8', 'FC6', 'F8', 'F4', 'FC2', 'FC1', 'T7'], 'alpha2': [], 'beta1': ['T8', 'FC6', 'P4', 'AF4', 'Fp2', 'Fp1', 'O1', 'F7', 'T7'], 'beta2': ['AF4']}\n"
     ]
    }
   ],
   "source": [
    "selected_channels = {}\n",
    "for i in mapping:\n",
    "    selected_channels[mapping[i]] = []\n",
    "\n",
    "    for ch in range(32):\n",
    "        # TODO: instead of number of edges wise, we can explore other algorithm\n",
    "        if len(nx.from_numpy_array(difference_matrix[mapping[i]]).edges(ch)) > 5:\n",
    "            selected_channels[mapping[i]].append(raw_1.info['ch_names'][ch])\n",
    "print(selected_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary of Regions in brain vs channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_loc = {}\n",
    "dig_points = []\n",
    "for _ in range(n_channels):\n",
    "    channel_loc[raw_1.info['chs'][_]['ch_name']] = raw_1.info['chs'][_]['loc'][:3]\n",
    "    dig_points = np.append(dig_points, raw_1.info['chs'][_]['loc'][:3])\n",
    "dig_points = dig_points.reshape(n_channels, 3)\n",
    "# dig_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07103247, -0.04225998,  0.04119886],\n",
       "       [ 0.08326137,  0.01525819,  0.03097297],\n",
       "       [ 0.08140111, -0.01346204,  0.07336367],\n",
       "       [ 0.07784662,  0.05209881,  0.06286711],\n",
       "       [ 0.07143527,  0.07450513,  0.02510103],\n",
       "       [ 0.05027428,  0.08743839,  0.07727065],\n",
       "       [ 0.06532888,  0.0235731 ,  0.10369243],\n",
       "       [ 0.05363602, -0.04433452,  0.10051603],\n",
       "       [ 0.03422986,  0.10981127,  0.05711667],\n",
       "       [ 0.0284095 ,  0.11534631,  0.02772126],\n",
       "       [-0.03090259,  0.11458518,  0.02786657],\n",
       "       [-0.03518601,  0.10912957,  0.05643921],\n",
       "       [-0.00122927,  0.09327445,  0.10263929],\n",
       "       [ 0.03313098,  0.06182849,  0.1167817 ],\n",
       "       [-0.00137413,  0.02761709,  0.14019949],\n",
       "       [ 0.03647196, -0.01090379,  0.13281227],\n",
       "       [-0.0386246 , -0.06736158,  0.08241555],\n",
       "       [-0.03157356, -0.08056835,  0.05478965],\n",
       "       [-0.00206025, -0.08278299,  0.06073663],\n",
       "       [ 0.0276831 , -0.08048884,  0.05473408],\n",
       "       [ 0.03466779, -0.06766214,  0.08164653],\n",
       "       [-0.00170945, -0.04521299,  0.12667292],\n",
       "       [-0.03742513, -0.01082424,  0.13344371],\n",
       "       [-0.03571586,  0.06171406,  0.11798302],\n",
       "       [-0.05503823, -0.0442103 ,  0.09990898],\n",
       "       [-0.06714872,  0.02335823,  0.10451068],\n",
       "       [-0.05180904,  0.0866879 ,  0.07871409],\n",
       "       [-0.07187663,  0.07310353,  0.02579046],\n",
       "       [-0.07890598,  0.05136738,  0.06296235],\n",
       "       [-0.08151351, -0.01334569,  0.07313263],\n",
       "       [-0.08598208,  0.01487164,  0.03117337],\n",
       "       [-0.07445796, -0.04212316,  0.04127363]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dig_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dig_points = []\n",
    "# for _ in range(n_channels): \n",
    "#     x = str(raw_1.info['dig'][_+3]).strip().split(':')[1]\n",
    "#     x = x.replace('(', '').replace(')', '').replace('mm', '').split(',')\n",
    "#     dig_points.append([float(i) for i in x])\n",
    "# print(dig_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import networkx as nx\n",
    "# from sklearn.cluster import SpectralClustering\n",
    "# import matplotlib.pyplot as plt\n",
    "# import mne\n",
    "\n",
    "# for i in mapping:\n",
    "#     G = nx.from_numpy_array(difference_matrix[mapping[i]])\n",
    "\n",
    "#     # Compute spectral clustering\n",
    "#     num_clusters = 8\n",
    "#     sc = SpectralClustering(n_clusters=num_clusters, affinity='precomputed_nearest_neighbors', random_state=42)\n",
    "#     clusters = sc.fit_predict(difference_matrix[mapping[i]])\n",
    "\n",
    "#     # Visualize clustering results\n",
    "#     fig = plt.figure(figsize=(8, 6))\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "#     for cluster_label in range(num_clusters):\n",
    "#         cluster_indices = np.where(clusters == cluster_label)[0]\n",
    "#         cluster_positions = dig_points[cluster_indices]\n",
    "        \n",
    "#         ax.scatter(cluster_positions[:, 0], cluster_positions[:, 1], cluster_positions[:, 2], label=f'Cluster {cluster_label + 1}')\n",
    "\n",
    "#     ax.set_title('Graph Clustering of Electrode Regions')\n",
    "#     ax.set_xlabel('X-axis')\n",
    "#     ax.set_ylabel('Y-axis')\n",
    "#     ax.set_zlabel('Z-axis')\n",
    "#     ax.legend()\n",
    "#     plt.show()\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionvschannel = {\n",
    "    'LC': ['C3', 'CP1', 'CP5', 'FC1', 'FC5'], # Left central \n",
    "    'LF': ['FP1', 'AF3', 'F3', 'F7'], # Left frontal\n",
    "    'LT': ['T7'], # Left temporal\n",
    "    'LPO': ['PO3',  'P3', 'P7', 'O1'], # Left parietal-occipital\n",
    "    'RC': ['CP6', 'FC6', 'C4', 'FC2', 'CP2',], # Right central \n",
    "    'RF': ['F8', 'F4', 'AF4', 'FP2'], # Right frontal\n",
    "    'RT': ['T8'], # Right temporal\n",
    "    'RPO': ['P8', 'P4', 'PO4', 'O2'] , # Right parietal-occipital\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(freq_bands)):\n",
    "selected_regions = {}\n",
    "# selected_regions['alpha2'] = ['RPO', 'LT', 'LF', 'LC']\n",
    "# selected_regions['alpha1'] = ['LT', 'LC', 'LF', 'RPO'] # 1 in RPO\n",
    "# selected_regions['theta'] = ['LC', 'LF'] # 1 in LC and 1 in LF\n",
    "# selected_regions['delta'] =  ['LF', 'LC', 'RF', 'RC'] # 1-1 in 'LC', 'RF', 'RC'\n",
    "selected_regions['delta'] =  ['LF', 'LC', 'RT']\n",
    "selected_regions['theta'] = ['LPO', 'LC', 'RPO']\n",
    "selected_regions['alpha1'] = ['LPO', 'RPO']\n",
    "selected_regions['alpha2'] = ['LC', 'RPO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Network Metrics for selected regions for selected bands\n",
    "\n",
    "\n",
    "Boxplot helps in reading median, interquartile range and outliers\n",
    "Box : middle 50% of all data lies (Interquartile range)\n",
    "Lower end: 1st quartile\n",
    "Upper end: 3rd quartile\n",
    "Solid line: Median\n",
    "Dashed line: Mean\n",
    "T shaped whiskers: Last point 1.5 times the interquartile range (max and min without outliers)\n",
    "Points: Further out are outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_measures = ['Lw', 'NBC', 'Eglo', 'CC', 'Eloc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Integration metrics - Lavg, Eglo \n",
    "# # Segregation metrics - CC, Eloc, Nbc\n",
    "# import seaborn as sns\n",
    "# for i in range(len(freq_bands)):\n",
    "#     selected_region = selected_regions[mapping[i]]\n",
    "\n",
    "#     if selected_region == []:\n",
    "#         continue\n",
    "\n",
    "#     # con_MDD = connectivity_matrix(epochs_1, i)\n",
    "#     # con_control = connectivity_matrix(epochs_2, i)\n",
    "#     G_MDD = nx.from_numpy_array(binarized_matrix[f'{GROUP1}-{mapping[i]}'])\n",
    "#     G_Control = nx.from_numpy_array(binarized_matrix[f'{GROUP2}-{mapping[i]}'])\n",
    "\n",
    "#     for region in selected_region:\n",
    "#         channels_list = regionvschannel[region]\n",
    "#         G_sub = G_MDD.subgraph(return_index(channels_list, raw_1))\n",
    "#         MDD_list = calculate_avergae_components(G_sub)\n",
    "#         G_sub = G_Control.subgraph(return_index(channels_list, raw_2))\n",
    "#         control_list = calculate_avergae_components(G_sub)\n",
    "\n",
    "#         print(MDD_list, \"fdhgjgdfjd\", control_list)\n",
    "\n",
    "#         # CHECK HERE if keys in MDD_list[1] matches with keys in control_list[1]\n",
    "#         # and keys in MDD_list[3] matches with keys in control_list[3]\n",
    "        \n",
    "#         values_MDD = []\n",
    "#         values_control = []\n",
    "#         group_labels_MDD = []\n",
    "#         group_labels_control = [] \n",
    "\n",
    "#         for _ in range(5):\n",
    "#             print(\"********\", MDD_list)\n",
    "#             if len(MDD_list[_]):\n",
    "#                 if type(MDD_list[_][0]) == type(dict()):\n",
    "#                     x = []\n",
    "#                     for __ in range(len(MDD_list[_])):\n",
    "#                         for k,v in MDD_list[_][__].items():\n",
    "#                             x.append(v)\n",
    "#                     values_MDD.append(x)\n",
    "#                 else:\n",
    "#                     values_MDD.append(MDD_list[_])\n",
    "#             else:\n",
    "#                 values_MDD.append([])\n",
    "#             if (control_list[_]):\n",
    "#                 if type(control_list[_][0]) == type(dict()):\n",
    "#                     y = []\n",
    "#                     for __ in range(len(control_list[_])):\n",
    "#                         for k,v in control_list[_][__].items():\n",
    "#                             y.append(v)\n",
    "#                     values_control.append(y)\n",
    "#                 else:\n",
    "#                     values_control.append(control_list[_])\n",
    "#             else:\n",
    "#                 values_control.append([])\n",
    "#             group_labels_MDD.append(f'{GROUP1}-{group_measures[_]}')\n",
    "#             group_labels_control.append(f'{GROUP2}-{group_measures[_]}')\n",
    "            \n",
    "#         values_all = values_1 + values_control\n",
    "#         group_labels = group_labels_MDD + group_labels_control\n",
    "\n",
    "#         print(\"values all\", values_all)\n",
    "#         print(\"group labels\", group_labels)\n",
    "\n",
    "#         plt.figure(figsize=(12, 8))\n",
    "#         plt.boxplot(values_all, labels=group_labels, vert=True)\n",
    "#         plt.title(f'Boxplot of Network Metrics for MDD and Control Groups in {mapping[i]} band in {region} region')\n",
    "#         plt.xlabel('Network Metrics')\n",
    "#         plt.ylabel('Values')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Mark all regions in brain along with Netowrk metrics which are significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Find relationship between \"these\" Network Metrics and PHQ-9 scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. For further evaluation: RF based on ensemble learning, SVM, KNN, ANN with 10-fold cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
