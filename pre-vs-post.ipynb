{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVE_SHAM = 'Active'\n",
    "SAMPLE = 'Preeti'\n",
    "RANGE = 1\n",
    "mapping = {0: 'delta', 1: 'theta', 2: 'alpha1', 3:'alpha2', 4:'beta1', 5:'beta2', 6: 'beta3', 7: 'gamma'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack\n",
    "from scipy.fft import fft\n",
    "import time\n",
    "import mne\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import kurtosis, zscore, ttest_ind\n",
    "from mne.preprocessing import create_ecg_epochs, create_eog_epochs, read_ica\n",
    "from mne.time_frequency import tfr_morlet, tfr_array_morlet, morlet, AverageTFR\n",
    "from itertools import product\n",
    "import pywt\n",
    "from scipy.signal import hilbert\n",
    "from mne_connectivity import spectral_connectivity_epochs\n",
    "from mne_connectivity.viz import plot_sensors_connectivity\n",
    "import networkx as nx\n",
    "import numpy as np \n",
    "import re\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from colabcode import ColabCode\n",
    "from nilearn import plotting\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from nilearn.maskers import MultiNiftiLabelsMasker\n",
    "from nilearn import datasets\n",
    "from communities.algorithms import hierarchical_clustering\n",
    "\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 ['/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/2Pre-TDCS/Preeti/20230718201550_Preeti singh_22.08.23-01_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230718210007_Preeti singh_22.08.23_01_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826191815_PreetiSingh_06.09.23_19_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826220508_PreetiSingh_08.09.23_20_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826155056_PreetiSingh_06.09.23_10_18A_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230824165000_PreetiSingh_26.08.23_06_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230719054417_PreetiSingh_23.08.23_04_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826013138_PreetiSingh_04.09.23_14_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826151321_PreetiSingh_06.09.23_10_18_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230718203406_Preeti singh_22.08.23_01_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230825004359_PreetiSingh_29.08.23_07_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230825113039_PreetiSingh_30.08.23_10_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230825164355_PreetiSingh_01.09.23_12_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230825072415_PreetiSingh_30.08.23_09_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826121530_Preetisingh_05.09.23_17_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230719030920_PreetiSingh_23.08.23_03_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826050809_PreetiSingh_04.09.23_15_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826120834_Preetisingh_05.09.23_17_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826223108_PreetiSingh_08.09.23_20_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230825044607_Preetisingh_29.08.23_08_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826081853_PreetiSingh_05.09.23_16_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826084454_PreetiSingh_05.09.23_16_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230719004104_PreetiSingh_22.08.23_20_02_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230719051815_PreetiSingh_23.08.23_04_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230825065814_PreetiSingh_30.08.23_09_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826051434_PreetiSingh_04.09.23_15_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826152455_PreetiSingh_06.09.23_10_18A_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230719024319_PreetiSingh_23.08.23_03_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230824162358_PreetiSingh_26.08.23_06_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230719085552_PreetiSingh_24.08.23_05_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230825142415_PreetiSingh_31.08.23_11_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230825005010_PreetiSingh_29.08.23_07_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230825110438_PreetiSingh_30.08.23_10_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230825135814_PreetiSingh_31.08.23_11_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230825210203_PreetiSingh_01.09.23_13_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230719001503_PreetiSingh_22.08.23_20_02_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230825012546_PreetiSingh_29.08.23_07A_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826092255_PreetiSingh_05.09.23_16_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230825170956_PreetiSingh_01.09.23_12_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826194417_PreetiSingh_06.09.23_19_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826124131_Preetisingh_05.09.23_17_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826054035_PreetiSingh_04.09.23_15_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230826010537_PreetiSingh_04.09.23_14_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230825051208_Preetisingh_29.08.23_08_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230825005945_PreetiSingh_29.08.23_07A_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230825203602_PreetiSingh_01.09.23_13_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/3TDCS/Preeti/20230719082951_PreetiSingh_24.08.23_05_Rest_Eye Close.easy', '/home/vishwani/Downloads/IITD/Depression-IITD/Depression-Sample-dataset-AIIMS/32electrodes/Active/4Post-TDCS/Preeti/20230826225729_PreetiSingh_08.09.23_20_Eye Close.easy']\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=149999\n",
      "    Range : 0 ... 149998 =      0.000 ...   299.996 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, non-linear phase, causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hann window with 0.0546 passband ripple and 44 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.01 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz\n",
      "- Filter length: 155001 samples (310.002 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwani/Downloads/IITD/Depression-IITD/common.ipynb:251: RuntimeWarning: filter_length (155001) is longer than the signal (50001), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  ]\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "SSP projectors applied...\n",
      "Creating RawArray with float64 data, n_channels=32, n_times=149999\n",
      "    Range : 0 ... 149998 =      0.000 ...   299.996 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, non-linear phase, causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hann window with 0.0546 passband ripple and 44 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.01 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz\n",
      "- Filter length: 155001 samples (310.002 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwani/Downloads/IITD/Depression-IITD/common.ipynb:251: RuntimeWarning: filter_length (155001) is longer than the signal (50001), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "SSP projectors applied...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    }
   ],
   "source": [
    "# 2Pre-TDCS : .easy, # 3TDCS : .easy, # 4Post-TDCS : .easy\n",
    "import glob\n",
    "folder_path = os.path.join(os.getcwd(), 'Depression-Sample-dataset-AIIMS', '32electrodes', ACTIVE_SHAM)\n",
    "# folders = ['1Pre-BML', '2Pre-TDCS', '3TDCS', '4Post-TDCS', '5Post-BML']\n",
    "folders = ['2Pre-TDCS', '3TDCS', '4Post-TDCS']\n",
    "all_files = []\n",
    "for folder in folders:\n",
    "    ext = '.eeg' if folder[0] in ['1', '5'] else 'Close.easy'\n",
    "    for _ in glob.glob(os.path.join(folder_path, folder, SAMPLE) + '/*' + ext):\n",
    "        all_files.append(_)\n",
    "print(len(all_files), all_files)\n",
    "GROUP1 = RANGE\n",
    "raw_1 = data_transformation_easy(all_files[RANGE])\n",
    "raw_1 = g1_preprocess(raw_1)\n",
    "GROUP2 = RANGE+1\n",
    "raw_2 = data_transformation_easy(all_files[RANGE+1])\n",
    "raw_2 = g1_preprocess(raw_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">swi</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">links</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>delta-g1</th>\n",
       "      <th>delta-g2</th>\n",
       "      <th>theta-g1</th>\n",
       "      <th>theta-g2</th>\n",
       "      <th>alpha1-g1</th>\n",
       "      <th>alpha1-g2</th>\n",
       "      <th>alpha2-g1</th>\n",
       "      <th>alpha2-g2</th>\n",
       "      <th>beta1-g1</th>\n",
       "      <th>beta1-g2</th>\n",
       "      <th>...</th>\n",
       "      <th>alpha2-g1</th>\n",
       "      <th>alpha2-g2</th>\n",
       "      <th>beta1-g1</th>\n",
       "      <th>beta1-g2</th>\n",
       "      <th>beta2-g1</th>\n",
       "      <th>beta2-g2</th>\n",
       "      <th>beta3-g1</th>\n",
       "      <th>beta3-g2</th>\n",
       "      <th>gamma-g1</th>\n",
       "      <th>gamma-g2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [(swi, delta-g1), (swi, delta-g2), (swi, theta-g1), (swi, theta-g2), (swi, alpha1-g1), (swi, alpha1-g2), (swi, alpha2-g1), (swi, alpha2-g2), (swi, beta1-g1), (swi, beta1-g2), (swi, beta2-g1), (swi, beta2-g2), (swi, beta3-g1), (swi, beta3-g2), (swi, gamma-g1), (swi, gamma-g2), (links, delta-g1), (links, delta-g2), (links, theta-g1), (links, theta-g2), (links, alpha1-g1), (links, alpha1-g2), (links, alpha2-g1), (links, alpha2-g2), (links, beta1-g1), (links, beta1-g2), (links, beta2-g1), (links, beta2-g2), (links, beta3-g1), (links, beta3-g2), (links, gamma-g1), (links, gamma-g2)]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"comparison-results/output.xlsx\")\n",
    "main_column_names = ['swi', 'links']\n",
    "subcols = ('delta-g1', 'delta-g2', 'theta-g1', 'theta-g2', 'alpha1-g1', 'alpha1-g2', 'alpha2-g1', 'alpha2-g2', \n",
    "           'beta1-g1', 'beta1-g2', 'beta2-g1', 'beta2-g2', 'beta3-g1', 'beta3-g2', 'gamma-g1', 'gamma-g2')\n",
    "\n",
    "subcolumn_names = {\n",
    "    'swi': subcols,\n",
    "    'links': subcols,\n",
    "    'asymmetry': subcols,\n",
    "    'regions': tuple(mapping.values())\n",
    "}\n",
    "\n",
    "columns_tuples = [(main_col, sub_col) for main_col in main_column_names for sub_col in subcolumn_names[main_col]]\n",
    "columns = pd.MultiIndex.from_tuples(columns_tuples)\n",
    "df = pd.DataFrame(columns=columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 4.0\n",
    "overlap = 2.0 \n",
    "\n",
    "samples_per_epoch = int(duration * SFREQ)\n",
    "samples_per_overlap = int(overlap * SFREQ)\n",
    "\n",
    "# Manually created events\n",
    "start, stop = 0, samples_per_epoch\n",
    "events = []\n",
    "while stop <= len(raw_1):\n",
    "    events.append([start, 0, 1]) \n",
    "    start += samples_per_overlap\n",
    "    stop += samples_per_overlap\n",
    "\n",
    "events = np.array(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Segmenting epochs for Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "49 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Using data from preloaded Raw for 49 events and 2001 original time points ...\n",
      "15 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs_1 = mne.Epochs(raw_1, events, tmin=0, tmax=duration, baseline=None, detrend=1,\n",
    "                    picks=None, preload=True, reject=None)\n",
    "# raw_1.plot(n_channels=len(raw_1.info['ch_names']), events=events, event_color={1:'r'}, scalings=SCALINGS)\n",
    "# epochs_1.plot(n_channels=len(raw_1.info['ch_names']), event_color={1:'r'}, events=events, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Segmenting epochs for Group 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "49 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Using data from preloaded Raw for 49 events and 2001 original time points ...\n",
      "15 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs_2 = mne.Epochs(raw_2, events, tmin=0, tmax=duration, baseline=None, detrend=1,\n",
    "                    picks=None, preload=True, reject=None)\n",
    "# raw_2.plot(n_channels=len(raw_1.info['ch_names']), events=events, event_color={1:'r'}, scalings=SCALINGS)\n",
    "# epochs_2.plot(n_channels=len(raw_1.info['ch_names']), event_color={1:'r'}, events=events, scalings=SCALINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. PSD graph plot between MDD and Control group\n",
    "\n",
    "For resting state EEG channel, analyzing the overall average power across channels provides a holistic view of the brain's activity without emphasizing the specificity of individual channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amplitude plots between both groups\n",
    "epochs_1_avg = epochs_1['1'].average()\n",
    "epochs_2_avg = epochs_2['1'].average()\n",
    "# evokeds = dict(epochs_1=epochs_1)\n",
    "# fig_MDD = epochs_1_avg.plot(titles=GROUP1, time_unit = 'ms')\n",
    "# fig_control = epochs_2_avg.plot(titles=GROUP2, time_unit = 'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 PSD using plot_psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().\n",
      "Effective window size : 4.096 (s)\n",
      "NOTE: plot_psd() is a legacy function. New code should use .compute_psd().plot().\n",
      "Effective window size : 4.096 (s)\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "#plot_psd uses welch method for continuous data\n",
    "raw_1.plot_psd(picks=raw_1.info['ch_names'], average=True, fmin=FMIN, fmax=FMAX, ax=ax, show=False, color='blue', dB=False)\n",
    "raw_2.plot_psd(picks=raw_2.info['ch_names'], average=True, fmin=FMIN, fmax=FMAX, ax=ax, show=False, color='red', dB=False)\n",
    "\n",
    "# dB = True plots PSD in decibels (logarithmic)\n",
    "# different n_fft compared to psd_array_welch\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Power/Frequency (microV^2/Hz)')\n",
    "ax.set_title('Power Spectral Density Comparison')\n",
    "\n",
    "ax.text(0.8, 0.9, GROUP1, color='blue', transform=ax.transAxes)\n",
    "ax.text(0.8, 0.85, GROUP2, color='red', transform=ax.transAxes)\n",
    "\n",
    "plt.ylim(0, 8)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(f'comparison-results/PSD - {GROUP1} vs {GROUP2}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Statistical testing between psds of raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.1 Plotting Histogram\n",
    "\n",
    "Shows if the data is bell shaped, skewed (positive or negative), uniform etc. Central tendency - highest peak in histogram. Spread - width of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g1_avg = np.mean(raw_1.get_data(), axis=0)\n",
    "# plt.hist(g1_avg, bins='auto', alpha=0.7, edgecolor='black')\n",
    "# plt.title(f'Histogram of {GROUP1} Data - averaged across all channels')\n",
    "# plt.xlabel('Values')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g2_avg = np.mean(raw_2.get_data(), axis=0)\n",
    "# plt.hist(g2_avg, bins='auto', alpha=0.7, edgecolor='black')\n",
    "# plt.title(f'Histogram of {GROUP2} Data - averaged across all channels')\n",
    "# plt.xlabel('Values')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{GROUP1} mean: \", np.mean(g1_avg, axis=0))\n",
    "# print(f\"{GROUP2} mean: \", np.mean(g2_avg, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.2 Calculate variance of both groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance_1 = np.var(psd_1, ddof=1) \n",
    "# variance_2 = np.var(psd_2, ddof=1)\n",
    "# print(f\"{GROUP1} variance: \", variance_1)\n",
    "# print(f\"{GROUP2} variance: \", variance_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.3 Find differences between the means of two independent groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, null hypothesis: there is no significant difference between groups (ie means are equal).\n",
    "alternative hypothesis: there is a significant difference between groups\n",
    "t-test : compares the differences between group means to expected variability in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_values = np.zeros(32)\n",
    "# t = np.zeros(32)\n",
    "# for i in range(32):\n",
    "#     t[i], p_values[i] = ttest_ind(psd_1[i, :], psd_2[i, :])\n",
    "# # independent t-test comparison : equal_var = True\n",
    "# # welch's t-test comparison: equal_var = False\n",
    "# print(\"Raw Data PSD Comparison Results:\")\n",
    "# print(\"T-statistic:\", t)\n",
    "# print(\"P-values:\", p_values) # probability of getting t-statistic >= what we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_statistic, p_values = ttest_ind(np.mean(psd_1, axis=0), np.mean(psd_2, axis=0), equal_var=False)\n",
    "# # independent t-test comparison : equal_var = True\n",
    "# # welch's t-test comparison: equal_var = False\n",
    "# print(\"Raw Data PSD Comparison Results:\")\n",
    "# print(\"T-statistic:\", t_statistic)\n",
    "# print(\"P-values:\", p_values) # probability of getting t-statistic >= what we got"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If p value < 0.005, we reject the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PLI and construction of brain function matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pli method always gives positive correlations\n",
    "connectivity = {}\n",
    "def connectivity_matrix(epochs, i):\n",
    "    return spectral_connectivity_epochs(\n",
    "    epochs, method='pli', mode='multitaper', sfreq=SFREQ,\n",
    "    fmin=FREQ_BANDS[mapping[i]][0], fmax=FREQ_BANDS[mapping[i]][1], faverage=True, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 0.2Hz..4.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25904/203938963.py:4: RuntimeWarning: fmin=0.010 Hz corresponds to 0.040 < 5 cycles based on the epoch length 4.002 sec, need at least 500.000 sec epochs or fmin=1.249. Spectrum estimate will be unreliable.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Adding metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 0.2Hz..4.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25904/203938963.py:4: RuntimeWarning: fmin=0.010 Hz corresponds to 0.040 < 5 cycles based on the epoch length 4.002 sec, need at least 500.000 sec epochs or fmin=1.249. Spectrum estimate will be unreliable.\n",
      "  return spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 4.2Hz..8.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 4.2Hz..8.0Hz (16 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 8.2Hz..10.0Hz (8 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 8.2Hz..10.0Hz (8 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 10.2Hz..13.0Hz (12 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n",
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 496 connections\n",
      "    using t=0.000s..4.000s for estimation (2001 points)\n",
      "    frequencies: 10.2Hz..13.0Hz (12 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    computing connectivity for epoch 4\n",
      "    computing connectivity for epoch 5\n",
      "    computing connectivity for epoch 6\n",
      "    computing connectivity for epoch 7\n",
      "    computing connectivity for epoch 8\n",
      "    computing connectivity for epoch 9\n",
      "    computing connectivity for epoch 10\n",
      "    computing connectivity for epoch 11\n",
      "    computing connectivity for epoch 12\n",
      "    computing connectivity for epoch 13\n",
      "    computing connectivity for epoch 14\n",
      "    computing connectivity for epoch 15\n",
      "    computing connectivity for epoch 16\n",
      "    computing connectivity for epoch 17\n",
      "    computing connectivity for epoch 18\n",
      "    computing connectivity for epoch 19\n",
      "    computing connectivity for epoch 20\n",
      "    computing connectivity for epoch 21\n",
      "    computing connectivity for epoch 22\n",
      "    computing connectivity for epoch 23\n",
      "    computing connectivity for epoch 24\n",
      "    computing connectivity for epoch 25\n",
      "    computing connectivity for epoch 26\n",
      "    computing connectivity for epoch 27\n",
      "    computing connectivity for epoch 28\n",
      "    computing connectivity for epoch 29\n",
      "    computing connectivity for epoch 30\n",
      "    computing connectivity for epoch 31\n",
      "    computing connectivity for epoch 32\n",
      "    computing connectivity for epoch 33\n",
      "    computing connectivity for epoch 34\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'beta1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m n_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(raw_1\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mch_names\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m mapping:\n\u001b[0;32m----> 3\u001b[0m     con \u001b[38;5;241m=\u001b[39m \u001b[43mconnectivity_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     connectivity[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mGROUP1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m con\u001b[38;5;241m.\u001b[39mget_data()\u001b[38;5;241m.\u001b[39mreshape((n_channels, n_channels))\n\u001b[1;32m      6\u001b[0m     con \u001b[38;5;241m=\u001b[39m connectivity_matrix(epochs_2, i)\n",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m, in \u001b[0;36mconnectivity_matrix\u001b[0;34m(epochs, i)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnectivity_matrix\u001b[39m(epochs, i):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spectral_connectivity_epochs(\n\u001b[1;32m      5\u001b[0m     epochs, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpli\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultitaper\u001b[39m\u001b[38;5;124m'\u001b[39m, sfreq\u001b[38;5;241m=\u001b[39mSFREQ,\n\u001b[0;32m----> 6\u001b[0m     fmin\u001b[38;5;241m=\u001b[39m\u001b[43mFREQ_BANDS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m], fmax\u001b[38;5;241m=\u001b[39mFREQ_BANDS[mapping[i]][\u001b[38;5;241m1\u001b[39m], faverage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'beta1'"
     ]
    }
   ],
   "source": [
    "n_channels = len(raw_1.info['ch_names'])\n",
    "for i in mapping:\n",
    "    con = connectivity_matrix(epochs_1, i)\n",
    "    connectivity[f'{GROUP1}-{mapping[i]}'] = con.get_data().reshape((n_channels, n_channels))\n",
    "\n",
    "    con = connectivity_matrix(epochs_2, i)\n",
    "    connectivity[f'{GROUP2}-{mapping[i]}'] = con.get_data().reshape((n_channels, n_channels))\n",
    "\n",
    "    # Make matrix symmetric\n",
    "    for row in range(n_channels):\n",
    "        for col in range(n_channels):\n",
    "            connectivity[f'{GROUP1}-{mapping[i]}'][row][col] = connectivity[f'{GROUP1}-{mapping[i]}'][col][row]\n",
    "            connectivity[f'{GROUP2}-{mapping[i]}'][row][col] = connectivity[f'{GROUP2}-{mapping[i]}'][col][row]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((connectivity.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Thresholding - M1 -  Small World Index\n",
    "\n",
    "Preserves small-world properties in both groups to ensure that any observed differences in connectivity are not biased by the thresholding method.\n",
    "Preserving these properties ensures that information can be transmitted quickly and effectively across the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold = {}\n",
    "edges_1 = {}\n",
    "edges_2 = {}\n",
    "# Generating 50 random networks with same number of vertices and edges \n",
    "random_networks = [nx.gnm_random_graph(n_channels, 496) for _ in range(50)]\n",
    "thresholds = np.arange(0.1, 0.9, 0.002)\n",
    "\n",
    "for i in mapping:\n",
    "    edges_1[mapping[i]] = []\n",
    "    edges_2[mapping[i]] = []\n",
    "    ratios = []\n",
    "    for threshold in thresholds:\n",
    "        # TODO: Cross check should we ignore thresholds which result in matrix to be not connected ?\n",
    "        g1 = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] > threshold))\n",
    "        Lw_1_binarized, CC_1_binarized = g1[0], g1[3]\n",
    "\n",
    "        g2 = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP2}-{mapping[i]}'] > threshold))\n",
    "        Lw_2_binarized, CC_2_binarized = g2[0], g2[3]\n",
    "\n",
    "        swi_ratio_binarized =  (CC_1_binarized*Lw_2_binarized)/(Lw_1_binarized*CC_2_binarized) if Lw_1_binarized and CC_2_binarized else 0\n",
    "        ratios.append(swi_ratio_binarized)\n",
    "        \n",
    "    optimal_threshold[mapping[i]] = thresholds[np.argmax(np.abs(ratios))] #TODO: ratios - swi_ratio ? OR remove swi_ratio and related code above\n",
    "    t_stat, p_value = ttest_ind(np.mean(connectivity[f'{GROUP1}-{mapping[i]}'], axis=0), np.mean(connectivity[f'{GROUP2}-{mapping[i]}'], axis=0)) \n",
    "    if p_value < 0.005: # Reject the null hypotheses\n",
    "        Crand = np.mean([calculate_avergae_components(nx.from_numpy_array((nx.to_numpy_array(G) > optimal_threshold[mapping[i]])))[3] for G in random_networks])\n",
    "        Lrand = np.mean([calculate_avergae_components(nx.from_numpy_array((nx.to_numpy_array(G) > optimal_threshold[mapping[i]])))[0] for G in random_networks])\n",
    "\n",
    "        graph1 = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] > optimal_threshold[mapping[i]]))\n",
    "        Lw_1_binarized, CC_1_binarized = graph1[0], graph1[3]\n",
    "\n",
    "        graph2 = calculate_avergae_components(nx.from_numpy_array(connectivity[f'{GROUP2}-{mapping[i]}'] > optimal_threshold[mapping[i]]))\n",
    "        Lw_2_binarized, CC_2_binarized = graph2[0], graph2[3]\n",
    "\n",
    "        swi_binarized_1 =  (CC_1_binarized/Crand)/(Lw_1_binarized/Lrand)\n",
    "        swi_binarized_2 = (CC_2_binarized/Crand)/(Lw_2_binarized/Lrand)\n",
    "        print(swi_binarized_1, \"Cc1 \", CC_1_binarized, \"Lw1 \", Lw_1_binarized)\n",
    "        print(swi_binarized_2, \"Cc2 \", CC_2_binarized, \"Lw2 \", Lw_2_binarized)  \n",
    "\n",
    "        edges_1[mapping[i]].append(nx.from_numpy_array(connectivity[f'{GROUP1}-{mapping[i]}'] > optimal_threshold[mapping[i]]).number_of_edges())\n",
    "        edges_2[mapping[i]].append(nx.from_numpy_array(connectivity[f'{GROUP2}-{mapping[i]}'] > optimal_threshold[mapping[i]]).number_of_edges())\n",
    "\n",
    "        print(f\"{mapping[i]} - Optimal Threshold: {optimal_threshold[mapping[i]]} (Significant)\", p_value)\n",
    "        df.at[GROUP1, ('swi', f'{mapping[i]}-g1')] = swi_binarized_1\n",
    "        df.at[GROUP1, ('swi', f'{mapping[i]}-g2')] = swi_binarized_2\n",
    "    else:\n",
    "        df.at[GROUP1, ('swi', f'{mapping[i]}-g1')] = None\n",
    "        df.at[GROUP1, ('swi', f'{mapping[i]}-g2')] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Binarization of functional connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_matrix = {}\n",
    "for i in mapping:\n",
    "    binarized_matrix[f'{GROUP1}-{mapping[i]}'] = connectivity[f'{GROUP1}-{mapping[i]}'] > optimal_threshold[mapping[i]]\n",
    "    binarized_matrix[f'{GROUP2}-{mapping[i]}'] = connectivity[f'{GROUP2}-{mapping[i]}'] > optimal_threshold[mapping[i]]\n",
    "print(binarized_matrix.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find number of links in each graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mapping:\n",
    "    links_1 = 0\n",
    "    links_2 = 0\n",
    "\n",
    "    for row in range(n_channels):\n",
    "        for col in range(row+1):\n",
    "            if binarized_matrix[f'{GROUP1}-{mapping[i]}'][row][col] == 1:\n",
    "                links_1+=1\n",
    "            if binarized_matrix[f'{GROUP2}-{mapping[i]}'][row][col] == 1:\n",
    "                links_2+=1\n",
    "\n",
    "    print(f'{GROUP1}-{mapping[i]}-number of links: K=', links_1)\n",
    "    print(f'{GROUP2}-{mapping[i]}-number of links: K=', links_2)\n",
    "\n",
    "    df.at[GROUP1, ('links', f'{mapping[i]}-g1')] = links_1\n",
    "    df.at[GROUP1, ('links', f'{mapping[i]}-g2')] = links_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Asymmetry in  each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_region = ['Fp1', 'AF3', 'PO3','O1', 'CP1', 'FC1', 'P3', 'C3', 'F3', 'F7', 'FC5', 'CP5', 'T7', 'P7']\n",
    "right_region = ['P8', 'T8', 'CP6', 'FC6', 'F8', 'F4', 'C4', 'P4', 'AF4', 'Fp2', 'FC2', 'CP2', 'O2', 'PO4']\n",
    "\n",
    "for i in mapping:\n",
    "    lr = 1\n",
    "    rr = 1\n",
    "    lrc = 1\n",
    "    rrc = 1\n",
    "    for row in range(n_channels):\n",
    "        for col in range(row+1):\n",
    "            if binarized_matrix[f'{GROUP1}-{mapping[i]}'][row][col] == 1:\n",
    "                if raw_1.info['ch_names'][row] in left_region or raw_1.info['ch_names'][col] in left_region:\n",
    "                    lr += 1\n",
    "                if raw_1.info['ch_names'][row] in right_region or raw_1.info['ch_names'][col] in right_region:\n",
    "                    rr += 1\n",
    "                # print(raw_1.info['ch_names'][row], raw_1.info['ch_names'][col])\n",
    "\n",
    "            if binarized_matrix[f'{GROUP2}-{mapping[i]}'][row][col] == 1:\n",
    "                if raw_1.info['ch_names'][row] in left_region or raw_1.info['ch_names'][col] in left_region:\n",
    "                    lrc += 1\n",
    "                if raw_1.info['ch_names'][row] in right_region or raw_1.info['ch_names'][col] in right_region:\n",
    "                    rrc += 1\n",
    "                # print(raw_1.info['ch_names'][row], raw_1.info['ch_names'][col])\n",
    "\n",
    "    print(f\"{GROUP1}: \",mapping[i], \"left region: \", lr, \"right region: \", rr, \"proportion: \", lr/rr)\n",
    "    print(f\"{GROUP2}: \", mapping[i], \"left region: \", lrc, \"right region: \", rrc, \"proportion: \", lrc/rrc)\n",
    "\n",
    "    df.at[GROUP1, ('asymmetry', f'{mapping[i]}-g1')] = lr/rr\n",
    "    df.at[GROUP1, ('asymmetry', f'{mapping[i]}-g2')] = lrc/rrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Difference matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_index(channels_list, raw):\n",
    "    indexes = []\n",
    "    for channel in channels_list:\n",
    "        for i in range(len(raw.info['ch_names'])):\n",
    "            if raw.info['ch_names'][i]==channel:\n",
    "                indexes.append(i)\n",
    "    return(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_channels = return_index(['Pz', 'Oz', 'Fz', 'Cz'], raw_1)\n",
    "central_channels\n",
    "raw_1.info['bads'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_matrix = {}\n",
    "for i in mapping:\n",
    "    difference_matrix[mapping[i]] = binarized_matrix[f'{GROUP2}-{mapping[i]}'].astype(int) - binarized_matrix[f'{GROUP1}-{mapping[i]}'].astype(int) \n",
    "    # difference_matrix[mapping[i]] = binarized_matrix[f'{GROUP1}-{mapping[i]}'].astype(int) - binarized_matrix[f'{GROUP2}-{mapping[i]}'].astype(int)\n",
    "    for k in range(n_channels):\n",
    "        for l in range(n_channels):\n",
    "            if difference_matrix[mapping[i]][k][l] == -1 or k in central_channels or l in central_channels:\n",
    "                difference_matrix[mapping[i]][k][l] = 0\n",
    "\n",
    "    # plot_sensors_connectivity(\n",
    "    #     raw_1.info,\n",
    "    #     difference_matrix[mapping[i]],\n",
    "    #     cbar_label=f'{mapping[i]}-Connectivity',\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels = {}\n",
    "for i in mapping:\n",
    "    selected_channels[mapping[i]] = []\n",
    "    for ch in range(32):\n",
    "        # TODO: instead of number of edges wise, we can explore other algorithm\n",
    "        if len(nx.from_numpy_array(difference_matrix[mapping[i]]).edges(ch)) > 6:\n",
    "            selected_channels[mapping[i]].append(raw_1.info['ch_names'][ch])\n",
    "print(selected_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary of Regions in brain vs channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionvschannel = {\n",
    "    'LC': ['C3', 'CP1', 'CP5', 'FC1', 'FC5'], # Left central \n",
    "    'LF': ['FP1', 'AF3', 'F3', 'F7'], # Left frontal\n",
    "    'LT': ['T7'], # Left temporal\n",
    "    'LPO': ['PO3',  'P3', 'P7', 'O1'], # Left parietal-occipital\n",
    "    'RC': ['CP6', 'FC6', 'C4', 'FC2', 'CP2',], # Right central \n",
    "    'RF': ['F8', 'F4', 'AF4', 'FP2'], # Right frontal\n",
    "    'RT': ['T8'], # Right temporal\n",
    "    'RPO': ['P8', 'P4', 'PO4', 'O2'] , # Right parietal-occipital\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse mapping\n",
    "channel_to_region = {}\n",
    "for region, region_channels in regionvschannel.items():\n",
    "    for channel in region_channels:\n",
    "        channel_to_region[channel] = region\n",
    "\n",
    "selected_regions = {}\n",
    "for band, channels in selected_channels.items():\n",
    "    regions = set()\n",
    "    for channel in channels:\n",
    "        if channel in channel_to_region:\n",
    "            regions.add(channel_to_region[channel])\n",
    "    selected_regions[band] = list(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mapping:\n",
    "    df.at[GROUP1, ('regions', mapping[i])] = selected_regions[mapping[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"comparison-results/output.xlsx\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
